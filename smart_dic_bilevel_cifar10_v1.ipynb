{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "smart_dic_bilevel_cifar10_v1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO23oNhZhBPd7u5JbPq5qaz"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "090347a3da0d486e8353b0111c07093e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_77a0336106c44693a96b871195014c04",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fa3efdce137b4ca1a0cd65b550a9933b",
              "IPY_MODEL_40b5090ccd224365b20af533df4293fd",
              "IPY_MODEL_42f2cf20bdae48ae9aed28384335e577"
            ]
          }
        },
        "77a0336106c44693a96b871195014c04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fa3efdce137b4ca1a0cd65b550a9933b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c64ffa124efa4e8692b25d6bc118297d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_666eddd579754735bc7b8115eb426332"
          }
        },
        "40b5090ccd224365b20af533df4293fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ebc5262d3c5d4bd288a9d68aebb88f0f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_32379ee3f9024382bbd2624a3103d297"
          }
        },
        "42f2cf20bdae48ae9aed28384335e577": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_12c158d0bde843b7a5ad3e266e048384",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:03&lt;00:00, 49115961.35it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b46723c939a14dc8a7bdc8ff99b9e3fd"
          }
        },
        "c64ffa124efa4e8692b25d6bc118297d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "666eddd579754735bc7b8115eb426332": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ebc5262d3c5d4bd288a9d68aebb88f0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "32379ee3f9024382bbd2624a3103d297": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "12c158d0bde843b7a5ad3e266e048384": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b46723c939a14dc8a7bdc8ff99b9e3fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5AeafWLRSJx",
        "outputId": "30288a5d-f352-45a2-99b6-b9eff6d8134d"
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    print(\"Gen RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available), \" |     Proc size: \" + humanize.naturalsize(process.memory_info().rss))\n",
        "    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total     {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gputil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=178a288762fce726adcd416002cfb4288e4f4d8371d4fe27f08909191b82f285\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.7 GB  |     Proc size: 118.2 MB\n",
            "GPU RAM Free: 16280MB | Used: 0MB | Util   0% | Total     16280MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4XKoh-NRZdJ"
      },
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader,TensorDataset\n",
        "from torchvision.transforms import Compose, RandomCrop, Pad, RandomHorizontalFlip, Resize, RandomAffine,RandomResizedCrop,CenterCrop\n",
        "from torchvision.transforms import ToTensor, Normalize,transforms\n",
        "from PIL.Image import BICUBIC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B95CJLKRSVsq"
      },
      "source": [
        "from PIL.Image import BICUBIC\n",
        "from PIL import Image\n",
        "from torchvision.datasets.cifar import CIFAR100, CIFAR10\n",
        "from torchvision.transforms import Compose, RandomCrop, Pad, RandomHorizontalFlip, Resize, RandomAffine\n",
        "from torchvision.transforms import ToTensor, Normalize\n",
        "\n",
        "from torch.utils.data import Subset,Dataset\n",
        "import torchvision.utils as vutils\n",
        "import random\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XU6tL4_KSLG4"
      },
      "source": [
        "from torch.utils.data import Subset,Dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dxnji7lxRzwz"
      },
      "source": [
        "def load_cifar10(train_size=4000,train_rho=0.01,val_size=1000,val_rho=1,image_size=224,batch_size=128,num_workers=4,path='./data',num_classes=10):\n",
        "    train_transform = Compose([\n",
        "        RandomCrop(32,padding=4),\n",
        "        Resize(image_size, BICUBIC),\n",
        "        #RandomAffine(degrees=2, translate=(0.02, 0.02), scale=(0.98, 1.02), shear=2, fillcolor=(124,117,104)),\n",
        "        RandomHorizontalFlip(),\n",
        "        ToTensor(),\n",
        "        Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2470, 0.2435, 0.2616])\n",
        "    ])\n",
        "\n",
        "    test_transform = Compose([\n",
        "        Resize(image_size, BICUBIC),    \n",
        "        ToTensor(),\n",
        "        Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2470, 0.2435, 0.2616])\n",
        "    ])\n",
        "\n",
        "    train_dataset = CIFAR10(root=path, train=True, transform=train_transform, download=True)\n",
        "    test_dataset = CIFAR10(root=path, train=False, transform=test_transform, download=True)\n",
        "    train_x,train_y = np.array(train_dataset.data), np.array(train_dataset.targets)\n",
        "    #test_x, test_y = test_dataset.data, test_dataset.targets\n",
        "    num_train_samples=[]\n",
        "    num_val_samples=[]\n",
        "    pi = []\n",
        "    train_mu=train_rho**(1./9.)\n",
        "    val_mu=val_rho**(1./9.)\n",
        "    for i in range(num_classes):\n",
        "        num_train_samples.append(round(train_size*(train_mu**i)))\n",
        "        num_val_samples.append(round(val_size*(val_mu**i)))\n",
        "        pi.append(train_mu**i)\n",
        "    train_index=[]\n",
        "    val_index=[]\n",
        "    #print(train_x,train_y)\n",
        "    print(num_train_samples,num_val_samples)\n",
        "    for i in range(num_classes):\n",
        "        train_index.extend(np.where(train_y==i)[0][:num_train_samples[i]])\n",
        "        val_index.extend(np.where(train_y==i)[0][-num_val_samples[i]:])\n",
        "        #index.extend()\n",
        "    random.shuffle(train_index)\n",
        "    random.shuffle(val_index)\n",
        "    \n",
        "    train_data,train_targets=train_x[train_index],train_y[train_index]\n",
        "    val_data,val_targets=train_x[val_index],train_y[val_index]\n",
        "    \n",
        "    train_dataset = CustomDataset(train_data,train_targets,train_transform)\n",
        "    val_dataset = CustomDataset(val_data,val_targets,train_transform)\n",
        "    train_eval_dataset = CustomDataset(train_data,train_targets,test_transform)\n",
        "    val_eval_dataset = CustomDataset(val_data,val_targets,test_transform)\n",
        "    \n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, \n",
        "                            shuffle=True, drop_last=False, pin_memory=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=num_workers, \n",
        "                            shuffle=True, drop_last=False, pin_memory=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers, \n",
        "                            shuffle=False, drop_last=False, pin_memory=True)\n",
        "\n",
        "    eval_train_loader = DataLoader(train_eval_dataset, batch_size=batch_size, num_workers=num_workers, \n",
        "                                shuffle=False, drop_last=False, pin_memory=True)\n",
        "    eval_val_loader = DataLoader(train_eval_dataset, batch_size=batch_size, num_workers=num_workers, \n",
        "                                shuffle=False, drop_last=False, pin_memory=True)\n",
        "\n",
        "    return train_loader,val_loader,test_loader,eval_train_loader,eval_val_loader,num_train_samples,num_val_samples,pi\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    \"\"\"CustomDataset with support of transforms.\n",
        "    \"\"\"\n",
        "    def __init__(self, data, targets, transform=None):\n",
        "        self.data = data\n",
        "        self.targets = targets\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img, target = self.data[index], self.targets[index]\n",
        "        img = Image.fromarray(img)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, target\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "#load_cifar10()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvYfM9-IRj9O"
      },
      "source": [
        "num_classes=10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtyoLrvJTJl_"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1,BN=True):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        if BN:\n",
        "            self.bn1 = nn.BatchNorm2d(planes)\n",
        "            self.bn2 = nn.BatchNorm2d(planes)\n",
        "        else:\n",
        "            self.bn1 = nn.Sequential()\n",
        "            self.bn2 = nn.Sequential()\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            if BN:\n",
        "                self.shortcut = nn.Sequential(\n",
        "                    nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                              kernel_size=1, stride=stride, bias=False),\n",
        "                    nn.BatchNorm2d(self.expansion*planes)\n",
        "                )\n",
        "            else:\n",
        "                self.shortcut = nn.Sequential(\n",
        "                    nn.Conv2d(in_planes, self.expansion * planes,\n",
        "                              kernel_size=1, stride=stride, bias=False)\n",
        "                )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10,in_planes=16,BN=True):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = in_planes\n",
        "        self.conv1 = nn.Conv2d(3, in_planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        if BN:\n",
        "            self.bn1 = nn.BatchNorm2d(in_planes)\n",
        "        else:\n",
        "            self.bn1 = nn.Sequential()\n",
        "        self.layer1 = self._make_layer(block, in_planes, num_blocks[0], stride=1,BN=BN)\n",
        "        self.layer2 = self._make_layer(block, in_planes*2, num_blocks[1], stride=2,BN=BN)\n",
        "        self.layer3 = self._make_layer(block, in_planes*4, num_blocks[2], stride=2,BN=BN)\n",
        "        self.avg_pool=nn.AvgPool2d(8)\n",
        "        self.linear = nn.Linear(in_planes*4, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride,BN):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride,BN=BN))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        #out = self.layer4(out)\n",
        "        out=self.avg_pool(out)\n",
        "        feature = out.view(out.size(0), -1)\n",
        "        logits = self.linear(feature)\n",
        "        return logits\n",
        "\n",
        "def ResNet20(num_classes=10,BN=True):\n",
        "    num_res_blocks = int((20 - 2) / 6)\n",
        "    return ResNet(BasicBlock, [num_res_blocks, num_res_blocks, num_res_blocks],num_classes=num_classes,BN=BN)\n",
        "def test():\n",
        "    net = ResNet20(BN=True)\n",
        "    print(sum(p.numel() for p in net.parameters() if p.requires_grad))\n",
        "    x = torch.randn(2,3,32,32)\n",
        "    y = net(x)\n",
        "    print(y)\n",
        "    print(y[0].size(),y[1].size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ca6fcLd-T1ih"
      },
      "source": [
        "batch_size = 64\n",
        "ARCH_EPOCH = 120\n",
        "lr = 0.1\n",
        "arch_lr = 0.01 \n",
        "train_rho = 0.01"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205,
          "referenced_widgets": [
            "090347a3da0d486e8353b0111c07093e",
            "77a0336106c44693a96b871195014c04",
            "fa3efdce137b4ca1a0cd65b550a9933b",
            "40b5090ccd224365b20af533df4293fd",
            "42f2cf20bdae48ae9aed28384335e577",
            "c64ffa124efa4e8692b25d6bc118297d",
            "666eddd579754735bc7b8115eb426332",
            "ebc5262d3c5d4bd288a9d68aebb88f0f",
            "32379ee3f9024382bbd2624a3103d297",
            "12c158d0bde843b7a5ad3e266e048384",
            "b46723c939a14dc8a7bdc8ff99b9e3fd"
          ]
        },
        "id": "z8MGvMr3Rpbs",
        "outputId": "36dd2fd4-0092-40d8-bf71-99a417039ba6"
      },
      "source": [
        "network_model ='ResNet20'\n",
        "model=ResNet20(num_classes=num_classes)\n",
        "train_loader,val_loader,test_loader,eval_train_loader,eval_val_loader,num_train_samples,num_val_samples,pi=load_cifar10(batch_size=batch_size,train_rho=train_rho,image_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:281: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "090347a3da0d486e8353b0111c07093e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "[4000, 2398, 1438, 862, 517, 310, 186, 111, 67, 40] [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnzYPOM0xe2V"
      },
      "source": [
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYt8gawTyduP",
        "outputId": "b64ef2ad-0dcc-4b38-a66a-2f4c69a2b0a8"
      },
      "source": [
        "-np.log10(pi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.        ,  0.22222222,  0.44444444,  0.66666667,  0.88888889,\n",
              "        1.11111111,  1.33333333,  1.55555556,  1.77777778,  2.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0wdv8-qyUwt",
        "outputId": "8e750d1d-572b-42f7-a443-004e72881fb2"
      },
      "source": [
        "np.square(np.log10(pi))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.04938272, 0.19753086, 0.44444444, 0.79012346,\n",
              "       1.2345679 , 1.77777778, 2.41975309, 3.16049383, 4.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MV9e96tIyr9t",
        "outputId": "e5998467-a59f-41f3-83fd-ca4a7df02474"
      },
      "source": [
        "np.sqrt(-np.log10(pi))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.        ,  0.47140452,  0.66666667,  0.81649658,  0.94280904,\n",
              "        1.05409255,  1.15470054,  1.24721913,  1.33333333,  1.41421356])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLR6AgpRy-bb",
        "outputId": "45f9a86e-24be-45fe-a812-21e5babe16fb"
      },
      "source": [
        "np.ones([num_classes])/pi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  1.        ,   1.66810054,   2.7825594 ,   4.64158883,\n",
              "         7.74263683,  12.91549665,  21.5443469 ,  35.93813664,\n",
              "        59.94842503, 100.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EctLLKYQzb4L",
        "outputId": "0f4b16f9-0d96-4c79-c56e-215111ba4fc4"
      },
      "source": [
        "(np.ones([num_classes])/pi)**0.15"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.        , 1.07977516, 1.1659144 , 1.25892541, 1.35935639,\n",
              "       1.46779927, 1.58489319, 1.7113283 , 1.8478498 , 1.99526231])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2wNBxvJzfQs",
        "outputId": "7aa23a1b-9781-4917-c74b-78123111462b"
      },
      "source": [
        "(np.ones([num_classes])/pi)**0.3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.        , 1.1659144 , 1.35935639, 1.58489319, 1.8478498 ,\n",
              "       2.15443469, 2.51188643, 2.92864456, 3.41454887, 3.98107171])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mSg0gfAzwzm",
        "outputId": "3a53b763-21ff-42be-c772-cf3767b8cf07"
      },
      "source": [
        "np.ones([num_classes])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-yysg_jxIj2"
      },
      "source": [
        "dic = []\n",
        "dic.append(-np.log10(pi)/max(-np.log10(pi)))\n",
        "dic.append(np.square(np.log10(pi))/max(np.square(np.log10(pi))))\n",
        "dic.append(np.sqrt(-np.log10(pi))/max(np.sqrt(-np.log10(pi))))\n",
        "dic.append((np.ones([num_classes])/pi)/max(np.ones([num_classes])/pi))\n",
        "dic.append(np.sqrt(np.ones([num_classes])/pi)/max(np.sqrt(np.ones([num_classes])/pi)))\n",
        "dic.append(((np.ones([num_classes])/pi)**0.3)/max((np.ones([num_classes])/pi)**0.3))\n",
        "dic.append(((np.ones([num_classes])/pi)**2)/max((np.ones([num_classes])/pi)**2))\n",
        "dic.append(np.ones([num_classes]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BshuC6-f0Jis"
      },
      "source": [
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "IxoIDLnI0EGe",
        "outputId": "ac419620-238d-4326-97b2-5f2a00377d20"
      },
      "source": [
        "for i in range(np.shape(dic)[0]):\n",
        "  plt.plot(dic[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIQuEqN0UqX9"
      },
      "source": [
        "def print_num_params(model, display_all_modules=False):\n",
        "    total_num_params = 0\n",
        "    for n, p in model.named_parameters():\n",
        "        num_params = 1\n",
        "        for s in p.shape:\n",
        "            num_params *= s\n",
        "        if display_all_modules: print(\"{}: {}\".format(n, num_params))\n",
        "        total_num_params += num_params \n",
        "    print(\"-\" * 50)\n",
        "    print(\"Total number of parameters: {:.2e}\".format(total_num_params))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZV9LhagU3ei",
        "outputId": "9a31663b-6fad-4175-e4a7-e9e628f262a8"
      },
      "source": [
        "!pip install ignite"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ignite\n",
            "  Downloading ignite-1.1.0-py2.py3-none-any.whl (4.5 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ignite) (2.23.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.7/dist-packages (from ignite) (1.12.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ignite) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ignite) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ignite) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ignite) (3.0.4)\n",
            "Installing collected packages: ignite\n",
            "Successfully installed ignite-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eliLMK4_U0Ix"
      },
      "source": [
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "from numpy.lib.scimath import log\n",
        "import torch\n",
        "import ignite\n",
        "from torch._C import dtype\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.utils as vutils\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "assert torch.cuda.is_available()\n",
        "assert torch.backends.cudnn.enabled\n",
        "torch.backends.cudnn.benchmark = True\n",
        "device = \"cuda\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5v43dtoTNMB",
        "outputId": "6e699d64-888c-4c65-cdda-18e1d9825ba7"
      },
      "source": [
        "print_num_params(model)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "Total number of parameters: 2.72e+05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFVWq21OuJG4"
      },
      "source": [
        "num_w = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFZJ6wiwUq6A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46b5f5ea-6470-4f0d-d4e8-58ad854a2102"
      },
      "source": [
        "dy_w= torch.zeros([num_w],dtype=torch.float32,device=device)\n",
        "ly_w= torch.zeros([num_w],dtype=torch.float32,device=device)\n",
        "dy_w[-1] = 1\n",
        "ly_w[0] = 1\n",
        "ly_w=torch.tensor(ly_w).cuda()\n",
        "dy_w=torch.tensor(dy_w).cuda()\n",
        "#wy=torch.from_numpy(np.ones(([num_classes]))/np.array(pi)).float().to(device)\n",
        "wy=torch.ones([num_w],dtype=torch.float32,device=device)\n",
        "dy_w.requires_grad=True\n",
        "ly_w.requires_grad=True\n",
        "#wy.requires_grad=False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kP_z9xvpVSeS"
      },
      "source": [
        "train_optimizer = optim.SGD(params=model.parameters(),lr=lr,momentum=0.9,weight_decay=1e-4)\n",
        "val_optimizer = optim.SGD(params=[{'params':dy_w},{'params':ly_w},{'params':wy}],lr=arch_lr)\n",
        "train_lr_scheduler=optim.lr_scheduler.MultiStepLR(train_optimizer,milestones=[160,180],gamma=0.1)\n",
        "val_lr_scheduler=optim.lr_scheduler.MultiStepLR(val_optimizer,milestones=[40,60,100,150],gamma=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4G-B4ICVYmq"
      },
      "source": [
        "import time\n",
        "save_path=f'./results/{int(time.time())}'\n",
        "os.makedirs(save_path)\n",
        "logfile=open(f'{save_path}/logs.txt',mode='w')\n",
        "dy_log=open(f'{save_path}/dy.txt',mode='w')\n",
        "ly_log=open(f'{save_path}/ly.txt',mode='w')\n",
        "acc_log=open(f'{save_path}/acc.txt',mode='w')\n",
        "config_log=open(f'{save_path}/config.txt',mode='w')\n",
        "torch.save(model,f'{save_path}/init_model.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCxf__JqWN4F"
      },
      "source": [
        "checkpoint_interval = 30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5W9dofNWxRO"
      },
      "source": [
        "def topk_corrects(preds, labels, ks):\n",
        "    \"\"\"Computes the top-k error for each k.\"\"\"\n",
        "    err_str = \"Batch dim of predictions and labels must match\"\n",
        "    assert preds.size(0) == labels.size(0), err_str\n",
        "    # Find the top max_k predictions for each sample\n",
        "    _top_max_k_vals, top_max_k_inds = torch.topk(\n",
        "        preds, max(ks), dim=1, largest=True, sorted=True\n",
        "    )\n",
        "    # (batch_size, max_k) -> (max_k, batch_size)\n",
        "    top_max_k_inds = top_max_k_inds.t()\n",
        "    # (batch_size, ) -> (max_k, batch_size)\n",
        "    rep_max_k_labels = labels.view(1, -1).expand_as(top_max_k_inds)\n",
        "    # (i, j) = 1 if top i-th prediction for the j-th sample is correct\n",
        "    top_max_k_correct = top_max_k_inds.eq(rep_max_k_labels)\n",
        "    # Compute the number of topk correct predictions for each k\n",
        "    topks_correct = [top_max_k_correct[:k, :].view(-1).float().sum() for k in ks]\n",
        "    return topks_correct"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuoI-E85WmCy"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "import torch\n",
        "from torch.autograd import grad\n",
        "import numpy as np\n",
        "def gather_flat_grad(loss_grad):\n",
        "    #cnt = 0\n",
        "    #for g in loss_grad:\n",
        "    #    g_vector = g.contiguous().view(-1) if cnt == 0 else torch.cat([g_vector, g.contiguous().view(-1)])\n",
        "    #    cnt = 1\n",
        "    return torch.cat([p.contiguous().view(-1) for p in loss_grad if not p is None]) #g_vector\n",
        "\n",
        "def neumann_hyperstep_preconditioner(d_val_loss_d_theta, d_train_loss_d_w, elementary_lr, num_neumann_terms, model):\n",
        "    preconditioner = d_val_loss_d_theta.detach()\n",
        "    counter = preconditioner\n",
        "\n",
        "    # Do the fixed point iteration to approximate the vector-inverseHessian product\n",
        "    i = 0\n",
        "    while i < num_neumann_terms:  # for i in range(num_neumann_terms):\n",
        "        old_counter = counter\n",
        "\n",
        "        # This increments counter to counter * (I - hessian) = counter - counter * hessian\n",
        "        #gradient=grad(d_train_loss_d_w, model.parameters(), grad_outputs=counter.view(-1), retain_graph=True)\n",
        "        #print(gradient)\n",
        "        #print(d_train_loss_d_w)\n",
        "        hessian_term = gather_flat_grad(\n",
        "            grad(d_train_loss_d_w, model.parameters(), grad_outputs=counter.view(-1), retain_graph=True))\n",
        "        \n",
        "        counter = old_counter - elementary_lr * hessian_term\n",
        "\n",
        "        preconditioner = preconditioner + counter\n",
        "        i += 1\n",
        "    return elementary_lr * preconditioner\n",
        "\n",
        "def train_epoch(cur_epoch, model, in_loader, in_criterion , in_optimizer, in_logit_adjust=None, in_params=None,\n",
        "    is_out=False, out_loader=None, out_optimizer=None, out_criterion=None, out_logit_adjust=None, out_params=None,out_posthoc=False,\n",
        "    ITER_LR=None, ARCH_EPOCH=0,num_classes=10,ARCH_INTERVAL=1,ARCH_TRAIN_SAMPLE=1,ARCH_VAL_SAMPLE=1):\n",
        "    \"\"\"Performs one epoch of bilevel optimization.\"\"\"\n",
        "    # Enable training mode\n",
        "    model.train()\n",
        "    if is_out:\n",
        "        print('lr: ',in_optimizer.param_groups[0]['lr'],'  arch lr: ',out_optimizer.param_groups[0]['lr'])\n",
        "        out_iter = iter(out_loader)\n",
        "        in_iter_alt=iter(in_loader)\n",
        "    else:\n",
        "        print('lr: ',in_optimizer.param_groups[0]['lr'])\n",
        "        \n",
        "    total_correct=0.\n",
        "    total_sample=0.\n",
        "    total_loss=0.\n",
        "    arch_interval=20\n",
        "    num_weights, num_hypers = sum(p.numel() for p in model.parameters()), 3*num_classes\n",
        "    use_reg=True\n",
        "    d_train_loss_d_w = torch.zeros(num_weights).cuda()\n",
        "\n",
        "    for cur_iter, (in_data, in_targets) in enumerate(in_loader):\n",
        "        #print(cur_iter)\n",
        "\n",
        "        # Transfer the data to the current GPU device\n",
        "        in_data, in_targets = in_data.cuda(non_blocking=True), in_targets.cuda(non_blocking=True)\n",
        "        # Update architecture\n",
        "        if is_out and not out_posthoc:# and cur_epoch>=ARCH_EPOCH:\n",
        "            model.train()\n",
        "            out_optimizer.zero_grad()\n",
        "\n",
        "            if cur_iter%ARCH_INTERVAL==0:\n",
        "                for cur_iter_alt in range(ARCH_TRAIN_SAMPLE):\n",
        "                    try:\n",
        "                        in_data_alt, in_targets_alt = next(in_iter_alt)\n",
        "                    except StopIteration:\n",
        "                        in_iter_alt = iter(in_loader)\n",
        "                        in_data_alt, in_targets_alt = next(in_iter_alt) \n",
        "                    in_data_alt, in_targets_alt = in_data_alt.cuda(non_blocking=True), in_targets_alt.cuda(non_blocking=True)\n",
        "                    in_optimizer.zero_grad()\n",
        "                    in_preds=model(in_data_alt)\n",
        "                    in_loss=in_criterion(in_preds,in_targets_alt,in_params) \n",
        "                    d_train_loss_d_w+=gather_flat_grad(grad(in_loss,model.parameters(),create_graph=True))\n",
        "                    #print(cur_iter_alt)\n",
        "                d_train_loss_d_w/=ARCH_TRAIN_SAMPLE\n",
        "                d_val_loss_d_theta, direct_grad = torch.zeros(num_weights).cuda(), torch.zeros(num_hypers).cuda()\n",
        "\n",
        "                for _ in range(ARCH_VAL_SAMPLE):\n",
        "                    try:\n",
        "                        out_data, out_targets = next(out_iter)\n",
        "                    except StopIteration:\n",
        "                        out_iter = iter(out_loader)\n",
        "                        out_data, out_targets = next(out_iter) \n",
        "                #for _,(out_data,out_targets) in enumerate(out_loader):\n",
        "                    out_data, out_targets = out_data.cuda(non_blocking=True), out_targets.cuda(non_blocking=True)\n",
        "                    model.zero_grad()\n",
        "                    in_optimizer.zero_grad()\n",
        "                    out_preds = model(out_data)\n",
        "                    out_loss = out_criterion(out_preds,out_targets,out_params)\n",
        "                    d_val_loss_d_theta += gather_flat_grad(grad(out_loss, model.parameters(), retain_graph=use_reg))\n",
        "                    # if use_reg:\n",
        "                    #     direct_grad+=gather_flat_grad(grad(out_loss, get_trainable_hyper_params(out_params), allow_unused=True))\n",
        "                    #     direct_grad[direct_grad != direct_grad] = 0\n",
        "                d_val_loss_d_theta/=ARCH_VAL_SAMPLE\n",
        "                direct_grad/=ARCH_VAL_SAMPLE\n",
        "                preconditioner = d_val_loss_d_theta\n",
        "                \n",
        "                preconditioner = neumann_hyperstep_preconditioner(d_val_loss_d_theta, d_train_loss_d_w, 1.0,\n",
        "                                                                5, model)\n",
        "                indirect_grad = gather_flat_grad(\n",
        "                    grad(d_train_loss_d_w, get_trainable_hyper_params(out_params), grad_outputs=preconditioner.view(-1),allow_unused=True))\n",
        "                hyper_grad=indirect_grad#+direct_grad\n",
        "                out_optimizer.zero_grad()\n",
        "                assign_hyper_gradient(out_params,-hyper_grad,num_w)\n",
        "                out_optimizer.step()\n",
        "                d_train_loss_d_w = torch.zeros(num_weights).cuda()\n",
        "        \n",
        "        if is_out and out_posthoc:\n",
        "            try:\n",
        "                out_data, out_targets = next(out_iter)\n",
        "            except StopIteration:\n",
        "                out_iter = iter(out_loader)\n",
        "                out_data, out_targets = next(out_iter) \n",
        "            out_data, out_targets = out_data.cuda(non_blocking=True), out_targets.cuda(non_blocking=True)\n",
        "            out_preds=model(out_data)\n",
        "            out_preds=out_logit_adjust(out_preds,params=out_params)\n",
        "            out_loss=out_criterion(out_preds,out_targets,out_params)\n",
        "            out_optimizer.zero_grad()\n",
        "            out_loss.backward()\n",
        "            out_optimizer.step()\n",
        "\n",
        "\n",
        "        # Perform the forward pass\n",
        "        in_preds = model(in_data)\n",
        "        if not in_logit_adjust is None:\n",
        "            in_preds=in_logit_adjust(in_preds,in_params)\n",
        "        # Compute the loss\n",
        "        loss = in_criterion(in_preds, in_targets, in_params)\n",
        "        # Perform the backward pass\n",
        "        in_optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        # torch.nn.utils.clip_grad_norm(model.parameters(), 5.0)\n",
        "        in_optimizer.step()\n",
        "\n",
        "        # Compute the errors\n",
        "        mb_size = in_data.size(0)\n",
        "        ks = [1] \n",
        "        top1_correct = topk_corrects(in_preds, in_targets, ks)[0]\n",
        "        \n",
        "        # Copy the stats from GPU to CPU (sync point)\n",
        "        loss = loss.item()\n",
        "        top1_correct = top1_correct.item()\n",
        "        total_correct+=top1_correct\n",
        "        total_sample+=mb_size\n",
        "        total_loss+=loss*mb_size\n",
        "    # Log epoch stats\n",
        "    print(f'Epoch {cur_epoch} :  Loss = {total_loss/total_sample}   ACC = {total_correct/total_sample*100.}')\n",
        "\n",
        "\n",
        "\n",
        "def train_epoch_DA(cur_epoch, model, in_loader, in_criterion , in_optimizer, in_logit_adjust=None, in_params=None,\n",
        "    is_out=False, out_loader=None, out_optimizer=None, out_criterion=None, out_logit_adjust=None, out_params=None,out_posthoc=False,\n",
        "    ITER_LR=None, ARCH_EPOCH=0,num_classes=10,ARCH_INTERVAL=1,ARCH_TRAIN_SAMPLE=1,ARCH_VAL_SAMPLE=1):\n",
        "    \"\"\"Performs one epoch of bilevel optimization.\"\"\"\n",
        "    # Enable training mode\n",
        "    model.train()\n",
        "    if is_out:\n",
        "        print('lr: ',in_optimizer.param_groups[0]['lr'],'  arch lr: ',out_optimizer.param_groups[0]['lr'])\n",
        "        out_iter = iter(out_loader)\n",
        "        in_iter_alt=iter(in_loader)\n",
        "    else:\n",
        "        print('lr: ',in_optimizer.param_groups[0]['lr'])\n",
        "        \n",
        "    total_correct=0.\n",
        "    total_sample=0.\n",
        "    total_loss=0.\n",
        "    arch_interval=20\n",
        "    num_weights, num_hypers = sum(p.numel() for p in model.parameters()), 3*num_w\n",
        "    use_reg=True\n",
        "    d_train_loss_d_w = torch.zeros(num_weights).cuda()\n",
        "\n",
        "    for cur_iter, (in_data, in_targets) in enumerate(in_loader):\n",
        "        #print(cur_iter)\n",
        "\n",
        "        # Transfer the data to the current GPU device\n",
        "        in_data, in_targets = in_data.cuda(non_blocking=True), in_targets.cuda(non_blocking=True)\n",
        "        # Update architecture\n",
        "        if is_out and not out_posthoc:# and cur_epoch>=ARCH_EPOCH:\n",
        "            model.train()\n",
        "            out_optimizer.zero_grad()\n",
        "\n",
        "            if cur_iter%ARCH_INTERVAL==0:\n",
        "                for cur_iter_alt in range(ARCH_TRAIN_SAMPLE):\n",
        "                    try:\n",
        "                        in_data_alt, in_targets_alt = next(in_iter_alt)\n",
        "                    except StopIteration:\n",
        "                        in_iter_alt = iter(in_loader)\n",
        "                        in_data_alt, in_targets_alt = next(in_iter_alt) \n",
        "                    in_data_alt, in_targets_alt = in_data_alt.cuda(non_blocking=True), in_targets_alt.cuda(non_blocking=True)\n",
        "                    in_optimizer.zero_grad()\n",
        "                    in_preds=model(in_data_alt)\n",
        "                    in_loss=in_criterion(in_preds,in_targets_alt,in_params) \n",
        "                    d_train_loss_d_w+=gather_flat_grad(grad(in_loss,model.parameters(),create_graph=True))\n",
        "                    #print(cur_iter_alt)\n",
        "                d_train_loss_d_w/=ARCH_TRAIN_SAMPLE\n",
        "                d_val_loss_d_theta, direct_grad = torch.zeros(num_weights).cuda(), torch.zeros(num_hypers).cuda()\n",
        "\n",
        "                for _ in range(ARCH_VAL_SAMPLE):\n",
        "                    try:\n",
        "                        out_data, out_targets = next(out_iter)\n",
        "                    except StopIteration:\n",
        "                        out_iter = iter(out_loader)\n",
        "                        out_data, out_targets = next(out_iter) \n",
        "                #for _,(out_data,out_targets) in enumerate(out_loader):\n",
        "                    out_data, out_targets = out_data.cuda(non_blocking=True), out_targets.cuda(non_blocking=True)\n",
        "                    model.zero_grad()\n",
        "                    in_optimizer.zero_grad()\n",
        "                    out_preds = model(out_data)\n",
        "                    out_loss = out_criterion(out_preds,out_targets,out_params)\n",
        "                    d_val_loss_d_theta += gather_flat_grad(grad(out_loss, model.parameters(), retain_graph=use_reg))\n",
        "                    # if use_reg:\n",
        "                    #     direct_grad+=gather_flat_grad(grad(out_loss, get_trainable_hyper_params(out_params), allow_unused=True))\n",
        "                    #     direct_grad[direct_grad != direct_grad] = 0\n",
        "                d_val_loss_d_theta/=ARCH_VAL_SAMPLE\n",
        "                direct_grad/=ARCH_VAL_SAMPLE\n",
        "                preconditioner = d_val_loss_d_theta\n",
        "                \n",
        "                preconditioner = neumann_hyperstep_preconditioner(d_val_loss_d_theta, d_train_loss_d_w, 1.0,\n",
        "                                                                5, model)\n",
        "                indirect_grad = gather_flat_grad(\n",
        "                    grad(d_train_loss_d_w, get_trainable_hyper_params(out_params), grad_outputs=preconditioner.view(-1),allow_unused=True))\n",
        "                hyper_grad=indirect_grad#+direct_grad\n",
        "                out_optimizer.zero_grad()\n",
        "                assign_hyper_gradient(out_params,-hyper_grad,num_classes)\n",
        "                out_optimizer.step()\n",
        "                d_train_loss_d_w = torch.zeros(num_weights).cuda()\n",
        "        \n",
        "        if is_out and out_posthoc:\n",
        "            try:\n",
        "                out_data, out_targets = next(out_iter)\n",
        "            except StopIteration:\n",
        "                out_iter = iter(out_loader)\n",
        "                out_data, out_targets = next(out_iter) \n",
        "            out_data, out_targets = out_data.cuda(non_blocking=True), out_targets.cuda(non_blocking=True)\n",
        "            out_preds=model(out_data)\n",
        "            out_preds=out_logit_adjust(out_preds,params=out_params)\n",
        "            out_loss=out_criterion(out_preds,out_targets,out_params)\n",
        "            out_optimizer.zero_grad()\n",
        "            out_loss.backward()\n",
        "            out_optimizer.step()\n",
        "\n",
        "\n",
        "        # Perform the forward pass\n",
        "        in_preds = model(in_data)\n",
        "        if not in_logit_adjust is None:\n",
        "            in_preds=in_logit_adjust(in_preds,in_params)\n",
        "        # Compute the loss\n",
        "        loss = in_criterion(in_preds, in_targets, in_params)\n",
        "        # Perform the backward pass\n",
        "        in_optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        # torch.nn.utils.clip_grad_norm(model.parameters(), 5.0)\n",
        "        in_optimizer.step()\n",
        "\n",
        "        # Compute the errors\n",
        "        mb_size = in_data.size(0)\n",
        "        ks = [1] \n",
        "        top1_correct = topk_corrects(in_preds, in_targets, ks)[0]\n",
        "        \n",
        "        # Copy the stats from GPU to CPU (sync point)\n",
        "        loss = loss.item()\n",
        "        top1_correct = top1_correct.item()\n",
        "        total_correct+=top1_correct\n",
        "        total_sample+=mb_size\n",
        "        total_loss+=loss*mb_size\n",
        "    # Log epoch stats\n",
        "    print(f'Epoch {cur_epoch} :  Loss = {total_loss/total_sample}   ACC = {total_correct/total_sample*100.}')\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_epoch(data_loader, model, criterion, cur_epoch, text, params=None, logit_adjust=None, num_classes=10,class_wise=False):\n",
        "    model.eval()\n",
        "    correct=0.\n",
        "    total=0.\n",
        "    loss=0.\n",
        "    class_correct=np.zeros(num_classes,dtype=float)\n",
        "    class_total=np.zeros(num_classes,dtype=float)\n",
        "\n",
        "    for cur_iter, (data, targets) in enumerate(data_loader):\n",
        "        data, targets = data.cuda(), targets.cuda(non_blocking=True)\n",
        "        logits = model(data)\n",
        "        if not logit_adjust is None:\n",
        "            logits=logit_adjust(logits,params)\n",
        "            \n",
        "        preds = logits.data.max(1)[1]\n",
        "        mb_size = data.size(0)\n",
        "        loss+=criterion(logits,targets,params).item()*mb_size\n",
        "\n",
        "        total+=mb_size\n",
        "        correct+=preds.eq(targets.data.view_as(preds)).sum().item()\n",
        "\n",
        "        #preds=preds.cpu().numpy()\n",
        "        #targets=targets.cpu().numpy()\n",
        "        if class_wise:\n",
        "            for i in range(num_classes):\n",
        "                indexes=np.where(targets.cpu().numpy()==i)[0]\n",
        "                class_total[i]+=indexes.size\n",
        "                class_correct[i]+=preds[indexes].eq(targets[indexes].data.view_as(preds[indexes])).sum().item()\n",
        "            #print(class_total,class_correct)\n",
        "    text=f'TEST {text}: Epoch {cur_epoch} :  Loss = {loss/total}   ACC = {correct/total*100.}'\n",
        "    if class_wise:\n",
        "        text=f'TEST {text}: Epoch {cur_epoch} :  Loss = {loss/total}   ACC = {correct/total*100.} Class wise = {class_correct/class_total*100.}'\n",
        "    print(text)\n",
        "    return text,loss/total,correct/total*100.\n",
        "# tag:change\n",
        "def loss_adjust_cross_entropy(logits,targets,params):\n",
        "    #assert(len(params)==2)\n",
        "    dy_w=params[0]\n",
        "    ly_w=params[1]\n",
        "    dy=torch.matmul(torch.tensor(np.array(dic).T,dtype=torch.float32,device=device),params[0])\n",
        "    ly=torch.matmul(torch.tensor(np.array(dic).T,dtype=torch.float32,device=device),params[1])\n",
        "    #wy=params[2]\n",
        "    #x=logits*torch.exp(dy)+ly\n",
        "    #print(F.sigmoid(dy))\n",
        "    x=logits*F.sigmoid(dy)+ly\n",
        "    #x=torch.transpose(torch.transpose(logits,0,1)*dy[targets],0,1)+ly\n",
        "    loss=F.cross_entropy(x,targets)\n",
        "    #loss=torch.mean(wy[targets]*F.cross_entropy(x,targets,reduction='none'))\n",
        "    return loss\n",
        "\n",
        "def cross_entropy(logits,targets,params):\n",
        "    #print(logits.shape,targets)\n",
        "    return F.cross_entropy(logits,targets)\n",
        "\n",
        "def logit_adjust_ly(logits,params):\n",
        "\n",
        "    #assert(len(params)==2)\n",
        "    dy_w=params[0]\n",
        "    ly_w=params[1]\n",
        "    dy=torch.matmul(torch.tensor(np.array(dic).T,dtype=torch.float32,device=device),params[0])\n",
        "    ly=torch.matmul(torch.tensor(np.array(dic).T,dtype=torch.float32,device=device),params[1])\n",
        "    x=logits*dy+ly\n",
        "    return x\n",
        "\n",
        "def get_trainable_hyper_params(params):\n",
        "    return[param for param in params if param.requires_grad]\n",
        "\n",
        "def assign_hyper_gradient(params,gradient,num_w):\n",
        "    i=0\n",
        "    for para in params:\n",
        "        if para.requires_grad:\n",
        "            para.grad=gradient[i:i+num_w].clone()\n",
        "            i+=num_w\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqbrG1N7W6QG"
      },
      "source": [
        "total_epoch = 300"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-WLKgsImxTJ"
      },
      "source": [
        "batch_size = 64\n",
        "ARCH_EPOCH = 120\n",
        "#ARCH_EPOCH = 20\n",
        "ARCH_INTERVAL = 40\n",
        "ARCH_TRAIN_SAMPLE =20\n",
        "ARCH_VAL_SAMPLE = 20\n",
        "ARCH_END = 500\n",
        "ARCH_EPOCH_INTERVAL = 1\n",
        "lr = 0.1\n",
        "arch_lr = 0.01 \n",
        "train_rho = 0.01"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmUJ8NovVeIG"
      },
      "source": [
        "   # dy=torch.matmul(torch.tensor(np.array(dic).T,dtype=torch.float32,device=device),params[0])\n",
        "   # ly=torch.matmul(torch.tensor(np.array(dic).T,dtype=torch.float32,device=device),params[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwNbo4vyVnDx",
        "outputId": "6b83522f-31af-4efe-97a7-76e9a3a00bbf"
      },
      "source": [
        "test_acc_max = 0\n",
        "dy_max = torch.zeros([num_w],dtype=torch.float32,device=device)\n",
        "ly_max = torch.zeros([num_w],dtype=torch.float32,device=device)\n",
        "for i in range(total_epoch+1):\n",
        "        \n",
        "        text,loss,train_acc=eval_epoch(eval_train_loader,model,cross_entropy,i,' train_dataset',params=[dy_w,ly_w,wy],num_classes=num_classes,class_wise=num_classes==10)\n",
        "        logfile.write(text+'\\n')\n",
        "        text,loss,val_acc=eval_epoch(val_loader,model,cross_entropy,i,' val_dataset',params=[dy_w,ly_w,wy],logit_adjust=None,num_classes=num_classes,class_wise=num_classes==10)\n",
        "        logfile.write(text+'\\n')\n",
        "        text,loss,test_acc=eval_epoch(test_loader,model,cross_entropy,i,' test_dataset',params=[dy_w,ly_w,wy],logit_adjust=None,num_classes=num_classes,class_wise=num_classes==10)\n",
        "        logfile.write(text+'\\n')\n",
        "        print(dy_w,ly_w,'\\n')\n",
        "        if test_acc>test_acc_max and i>ARCH_EPOCH:\n",
        "          dy_max = torch.matmul(torch.tensor(np.array(dic).T,dtype=torch.float32,device=device),dy_w)\n",
        "          ly_max = torch.matmul(torch.tensor(np.array(dic).T,dtype=torch.float32,device=device),ly_w)\n",
        "          test_acc_max = test_acc\n",
        "\n",
        "\n",
        "        train_epoch(i, model, \n",
        "                in_loader=train_loader, in_criterion=loss_adjust_cross_entropy, \n",
        "                in_optimizer=train_optimizer,in_params=[dy_w,ly_w],\n",
        "                is_out=(i>=ARCH_EPOCH) and (i<=ARCH_END) and ((i+1)%ARCH_EPOCH_INTERVAL)==0, \n",
        "                out_loader=val_loader, out_optimizer=val_optimizer,\n",
        "                out_criterion=cross_entropy, out_logit_adjust=None, out_params=[dy_w,ly_w],\n",
        "                num_classes=num_classes,\n",
        "                ARCH_EPOCH=ARCH_EPOCH,ARCH_INTERVAL=ARCH_INTERVAL,\n",
        "                ARCH_TRAIN_SAMPLE=ARCH_TRAIN_SAMPLE,ARCH_VAL_SAMPLE=ARCH_VAL_SAMPLE)\n",
        "        logfile.write(str(dy_w)+str(ly_w)+'\\n\\n')\n",
        "        dy_log.write(f'{dy_w.detach().cpu().numpy()}\\n')\n",
        "        ly_log.write(f'{ly_w.detach().cpu().numpy()}\\n')\n",
        "        acc_log.write(f'{train_acc} {val_acc} {test_acc}\\n')\n",
        "        logfile.flush()\n",
        "        dy_log.flush()\n",
        "        ly_log.flush()\n",
        "        acc_log.flush()\n",
        "        train_lr_scheduler.step()\n",
        "        if i%checkpoint_interval==0:\n",
        "          print('dy',torch.matmul(torch.tensor(np.array(dic).T,dtype=torch.float32,device=device),dy_w))\n",
        "          print('ly',torch.matmul(torch.tensor(np.array(dic).T,dtype=torch.float32,device=device),ly_w))\n",
        "        if i%checkpoint_interval==0:\n",
        "                torch.save(model,f'{save_path}/epoch_{i}.pth')\n",
        "logfile.close()\n",
        "dy_log.close()\n",
        "ly_log.close()\n",
        "acc_log.close()\n",
        "torch.save(model,f'{save_path}/loss_adjustment.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST TEST  train_dataset: Epoch 0 :  Loss = 2.275170895109389   ACC = 7.029912377882969: Epoch 0 :  Loss = 2.275170895109389   ACC = 7.029912377882969 Class wise = [ 5.625       0.          0.          0.         90.90909091  0.\n",
            "  0.          0.          4.47761194  0.        ]\n",
            "TEST TEST  val_dataset: Epoch 0 :  Loss = 2.3021326625823977   ACC = 10.040000000000001: Epoch 0 :  Loss = 2.3021326625823977   ACC = 10.040000000000001 Class wise = [ 7.3  0.   0.   0.  89.8  0.   0.   0.   3.3  0. ]\n",
            "TEST TEST  test_dataset: Epoch 0 :  Loss = 2.301785810470581   ACC = 10.09: Epoch 0 :  Loss = 2.301785810470581   ACC = 10.09 Class wise = [ 5.6  0.   0.   0.  91.4  0.2  0.   0.   3.7  0. ]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 :  Loss = 1.3702065532379657   ACC = 51.9488367408601\n",
            "dy tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
            "       grad_fn=<MvBackward>)\n",
            "ly tensor([0.0000, 0.1111, 0.2222, 0.3333, 0.4444, 0.5556, 0.6667, 0.7778, 0.8889,\n",
            "        1.0000], device='cuda:0', grad_fn=<MvBackward>)\n",
            "TEST TEST  train_dataset: Epoch 1 :  Loss = 1.42921111848806   ACC = 53.63077852754557: Epoch 1 :  Loss = 1.42921111848806   ACC = 53.63077852754557 Class wise = [66.3        70.39199333 67.24617524  2.08816705  0.          0.\n",
            "  0.          0.          0.          0.        ]\n",
            "TEST TEST  val_dataset: Epoch 1 :  Loss = 3.914460259628296   ACC = 20.14: Epoch 1 :  Loss = 3.914460259628296   ACC = 20.14 Class wise = [62.9 74.  63.7  0.8  0.   0.   0.   0.   0.   0. ]\n",
            "TEST TEST  test_dataset: Epoch 1 :  Loss = 4.005502912139892   ACC = 20.32: Epoch 1 :  Loss = 4.005502912139892   ACC = 20.32 Class wise = [67.1 68.6 66.2  1.3  0.   0.   0.   0.   0.   0. ]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 1 :  Loss = 1.178038041029035   ACC = 58.65646087219256\n",
            "TEST TEST  train_dataset: Epoch 2 :  Loss = 1.2988968681551945   ACC = 58.616174841373756: Epoch 2 :  Loss = 1.2988968681551945   ACC = 58.616174841373756 Class wise = [90.225      61.2176814  46.87065369  8.00464037  0.          0.\n",
            "  0.          0.          0.          0.        ]\n",
            "TEST TEST  val_dataset: Epoch 2 :  Loss = 3.6556084327697755   ACC = 21.89: Epoch 2 :  Loss = 3.6556084327697755   ACC = 21.89 Class wise = [87.2 75.1 47.1  9.5  0.   0.   0.   0.   0.   0. ]\n",
            "TEST TEST  test_dataset: Epoch 2 :  Loss = 3.9042764854431153   ACC = 20.84: Epoch 2 :  Loss = 3.9042764854431153   ACC = 20.84 Class wise = [93.  63.5 45.4  6.5  0.   0.   0.   0.   0.   0. ]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 2 :  Loss = 1.1197907998850247   ACC = 60.99305065968375\n",
            "TEST TEST  train_dataset: Epoch 3 :  Loss = 1.3275320056054105   ACC = 62.3124181689999: Epoch 3 :  Loss = 1.3275320056054105   ACC = 62.3124181689999 Class wise = [92.75       69.59966639 43.3240612  21.46171694  0.          0.\n",
            "  0.          0.          0.          0.        ]\n",
            "TEST TEST  val_dataset: Epoch 3 :  Loss = 3.8583049221038817   ACC = 22.86: Epoch 3 :  Loss = 3.8583049221038817   ACC = 22.86 Class wise = [89.9 73.4 39.  26.3  0.   0.   0.   0.   0.   0. ]\n",
            "TEST TEST  test_dataset: Epoch 3 :  Loss = 4.052889794540405   ACC = 22.08: Epoch 3 :  Loss = 4.052889794540405   ACC = 22.08 Class wise = [94.2 67.7 42.2 16.7  0.   0.   0.   0.   0.   0. ]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 3 :  Loss = 1.063368505213073   ACC = 63.531070601269015\n",
            "TEST TEST  train_dataset: Epoch 4 :  Loss = 1.4248355715905614   ACC = 57.780239701883374: Epoch 4 :  Loss = 1.4248355715905614   ACC = 57.780239701883374 Class wise = [96.         36.40533778 35.04867872 60.32482599  0.          0.\n",
            "  0.          0.          0.          0.        ]\n",
            "TEST TEST  val_dataset: Epoch 4 :  Loss = 3.9849653800964355   ACC = 22.5: Epoch 4 :  Loss = 3.9849653800964355   ACC = 22.5 Class wise = [95.1 38.4 23.4 68.1  0.   0.   0.   0.   0.   0. ]\n",
            "TEST TEST  test_dataset: Epoch 4 :  Loss = 4.157501267242432   ACC = 22.5: Epoch 4 :  Loss = 4.157501267242432   ACC = 22.5 Class wise = [96.6 36.8 35.  56.6  0.   0.   0.   0.   0.   0. ]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 4 :  Loss = 1.0325841803915228   ACC = 64.64900795649109\n",
            "TEST TEST  train_dataset: Epoch 5 :  Loss = 1.0838200272912524   ACC = 66.58273743579414: Epoch 5 :  Loss = 1.0838200272912524   ACC = 66.58273743579414 Class wise = [84.7        83.36113428 66.48122392 31.09048724  0.          0.\n",
            "  0.          0.          0.          0.        ]\n",
            "TEST TEST  val_dataset: Epoch 5 :  Loss = 3.3737738079071047   ACC = 26.790000000000003: Epoch 5 :  Loss = 3.3737738079071047   ACC = 26.790000000000003 Class wise = [84.5 82.6 60.4 40.4  0.   0.   0.   0.   0.   0. ]\n",
            "TEST TEST  test_dataset: Epoch 5 :  Loss = 3.6300186279296875   ACC = 26.090000000000003: Epoch 5 :  Loss = 3.6300186279296875   ACC = 26.090000000000003 Class wise = [85.6 82.6 62.9 29.8  0.   0.   0.   0.   0.   0. ]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 5 :  Loss = 0.9646346235769923   ACC = 66.62302346661295\n",
            "TEST TEST  train_dataset: Epoch 6 :  Loss = 1.150744868604687   ACC = 64.74972303353812: Epoch 6 :  Loss = 1.150744868604687   ACC = 64.74972303353812 Class wise = [95.875      63.13594662 57.8581363  19.83758701 14.89361702  0.\n",
            "  0.          0.          0.          0.        ]\n",
            "TEST TEST  val_dataset: Epoch 6 :  Loss = 3.4018098625183106   ACC = 24.52: Epoch 6 :  Loss = 3.4018098625183106   ACC = 24.52 Class wise = [97.5 57.4 52.3 26.  12.   0.   0.   0.   0.   0. ]\n",
            "TEST TEST  test_dataset: Epoch 6 :  Loss = 3.670135796737671   ACC = 24.73: Epoch 6 :  Loss = 3.670135796737671   ACC = 24.73 Class wise = [95.9 62.7 55.4 18.3 15.   0.   0.   0.   0.   0. ]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 6 :  Loss = 0.956286081897731   ACC = 67.0460267902105\n",
            "TEST TEST  train_dataset: Epoch 7 :  Loss = 1.233381657240698   ACC = 61.55705509114714: Epoch 7 :  Loss = 1.233381657240698   ACC = 61.55705509114714 Class wise = [92.95       53.75312761 71.418637    3.94431555  8.5106383   0.\n",
            "  0.          0.          0.          0.        ]\n",
            "TEST TEST  val_dataset: Epoch 7 :  Loss = 3.58610545463562   ACC = 22.16: Epoch 7 :  Loss = 3.58610545463562   ACC = 22.16 Class wise = [95.8 46.9 68.1  4.7  6.1  0.   0.   0.   0.   0. ]\n",
            "TEST TEST  test_dataset: Epoch 7 :  Loss = 3.790796742630005   ACC = 22.939999999999998: Epoch 7 :  Loss = 3.790796742630005   ACC = 22.939999999999998 Class wise = [92.4 51.7 72.8  3.9  8.6  0.   0.   0.   0.   0. ]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 7 :  Loss = 0.911767400317183   ACC = 68.43589485345957\n",
            "TEST TEST  train_dataset: Epoch 8 :  Loss = 1.0224615170499665   ACC = 70.95377177963542: Epoch 8 :  Loss = 1.0224615170499665   ACC = 70.95377177963542 Class wise = [87.275      91.70141785 59.0403338  57.54060325  1.93423598  0.\n",
            "  0.          0.          0.          0.        ]\n",
            "TEST TEST  val_dataset: Epoch 8 :  Loss = 3.6535632469177246   ACC = 28.970000000000002: Epoch 8 :  Loss = 3.6535632469177246   ACC = 28.970000000000002 Class wise = [88.8 92.5 49.  59.1  0.3  0.   0.   0.   0.   0. ]\n",
            "TEST TEST  test_dataset: Epoch 8 :  Loss = 3.8888085506439207   ACC = 29.14: Epoch 8 :  Loss = 3.8888085506439207   ACC = 29.14 Class wise = [89.  91.1 56.  54.   1.3  0.   0.   0.   0.   0. ]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 8 :  Loss = 0.8943353947201385   ACC = 69.50347467015813\n",
            "TEST TEST  train_dataset: Epoch 9 :  Loss = 1.0200851199033578   ACC = 68.44596636116427: Epoch 9 :  Loss = 1.0200851199033578   ACC = 68.44596636116427 Class wise = [81.3        83.69474562 75.31293463 46.51972158 10.25145068  0.\n",
            "  0.          0.          0.          0.        ]\n",
            "TEST TEST  val_dataset: Epoch 9 :  Loss = 3.118630828857422   ACC = 29.220000000000002: Epoch 9 :  Loss = 3.118630828857422   ACC = 29.220000000000002 Class wise = [82.2 83.2 66.7 52.5  7.6  0.   0.   0.   0.   0. ]\n",
            "TEST TEST  test_dataset: Epoch 9 :  Loss = 3.401958818054199   ACC = 28.689999999999998: Epoch 9 :  Loss = 3.401958818054199   ACC = 28.689999999999998 Class wise = [79.  82.4 72.9 42.9  9.7  0.   0.   0.   0.   0. ]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 9 :  Loss = 0.8618866464548787   ACC = 70.61134051767549\n",
            "TEST TEST  train_dataset: Epoch 10 :  Loss = 0.9958949015332392   ACC = 72.14220968879042: Epoch 10 :  Loss = 0.9958949015332392   ACC = 72.14220968879042 Class wise = [93.625      91.57631359 47.49652295 37.47099768 41.7794971   0.\n",
            "  0.          0.          0.          0.        ]\n",
            "TEST TEST  val_dataset: Epoch 10 :  Loss = 3.5436940284729004   ACC = 29.65: Epoch 10 :  Loss = 3.5436940284729004   ACC = 29.65 Class wise = [92.9 91.9 40.2 40.  31.5  0.   0.   0.   0.   0. ]\n",
            "TEST TEST  test_dataset: Epoch 10 :  Loss = 3.8173381317138673   ACC = 30.5: Epoch 10 :  Loss = 3.8173381317138673   ACC = 30.5 Class wise = [93.7 90.2 46.  36.1 39.   0.   0.   0.   0.   0. ]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 10 :  Loss = 0.834435000359826   ACC = 71.42713264175647\n",
            "TEST TEST  train_dataset: Epoch 11 :  Loss = 0.8667187334991964   ACC = 72.9479303051667: Epoch 11 :  Loss = 0.8667187334991964   ACC = 72.9479303051667 Class wise = [86.35       94.91242702 69.26286509 47.21577726 20.30947776  0.\n",
            "  2.68817204  0.          0.          0.        ]\n",
            "TEST TEST  val_dataset: Epoch 11 :  Loss = 3.0607719482421873   ACC = 30.620000000000005: Epoch 11 :  Loss = 3.0607719482421873   ACC = 30.620000000000005 Class wise = [87.  92.5 62.1 49.8 13.5  0.   1.3  0.   0.   0. ]\n",
            "TEST TEST  test_dataset: Epoch 11 :  Loss = 3.2358385246276855   ACC = 31.130000000000003: Epoch 11 :  Loss = 3.2358385246276855   ACC = 31.130000000000003 Class wise = [85.1 94.4 66.5 44.1 18.5  0.   2.7  0.   0.   0. ]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 11 :  Loss = 0.8274262575647456   ACC = 71.43720414946118\n",
            "TEST TEST  train_dataset: Epoch 12 :  Loss = 0.9716736162185476   ACC = 70.94370027193071: Epoch 12 :  Loss = 0.9716736162185476   ACC = 70.94370027193071 Class wise = [93.525      73.64470392 58.27538248 53.71229698 44.48742747  1.61290323\n",
            "  0.53763441  0.          0.          0.        ]\n",
            "TEST TEST  val_dataset: Epoch 12 :  Loss = 3.1200170024871827   ACC = 31.71: Epoch 12 :  Loss = 3.1200170024871827   ACC = 31.71 Class wise = [90.9 78.3 55.7 56.1 33.1  1.8  1.2  0.   0.   0. ]\n",
            "TEST TEST  test_dataset: Epoch 12 :  Loss = 3.47564352722168   ACC = 31.75: Epoch 12 :  Loss = 3.47564352722168   ACC = 31.75 Class wise = [93.3 71.7 55.3 50.3 43.8  0.6  2.5  0.   0.   0. ]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 12 :  Loss = 0.8111827983178093   ACC = 71.93070802699164\n",
            "TEST TEST  train_dataset: Epoch 13 :  Loss = 0.8823134152595581   ACC = 73.26014704401248: Epoch 13 :  Loss = 0.8823134152595581   ACC = 73.26014704401248 Class wise = [86.9        96.24687239 56.46731572 67.74941995 17.40812379  0.\n",
            "  2.15053763  0.          0.          0.        ]\n",
            "TEST TEST  val_dataset: Epoch 13 :  Loss = 2.9480160991668702   ACC = 31.2: Epoch 13 :  Loss = 2.9480160991668702   ACC = 31.2 Class wise = [88.6 94.8 48.1 64.1 15.9  0.1  0.4  0.   0.   0. ]\n",
            "TEST TEST  test_dataset: Epoch 13 :  Loss = 3.153806831359863   ACC = 31.929999999999996: Epoch 13 :  Loss = 3.153806831359863   ACC = 31.929999999999996 Class wise = [86.8 96.  53.9 64.1 16.8  0.   1.7  0.   0.   0. ]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 13 :  Loss = 0.7873283131915717   ACC = 73.21986101319368\n",
            "TEST TEST  train_dataset: Epoch 14 :  Loss = 0.9056685437415587   ACC = 74.1766542451405: Epoch 14 :  Loss = 0.9056685437415587   ACC = 74.1766542451405 Class wise = [93.5        82.36030025 64.0472879  70.06960557 23.59767892  0.64516129\n",
            "  0.53763441  0.          0.          0.        ]\n",
            "TEST TEST  val_dataset: Epoch 14 :  Loss = 3.4271624389648436   ACC = 30.599999999999998: Epoch 14 :  Loss = 3.4271624389648436   ACC = 30.599999999999998 Class wise = [94.1 77.6 52.1 67.4 13.9  0.8  0.1  0.   0.   0. ]\n",
            "TEST TEST  test_dataset: Epoch 14 :  Loss = 3.6089555248260496   ACC = 31.580000000000002: Epoch 14 :  Loss = 3.6089555248260496   ACC = 31.580000000000002 Class wise = [93.  79.4 59.1 63.9 19.8  0.6  0.   0.   0.   0. ]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 14 :  Loss = 0.7659872850030436   ACC = 73.9147950448182\n",
            "TEST TEST  train_dataset: Epoch 15 :  Loss = 0.7892317113192951   ACC = 75.6370228623225: Epoch 15 :  Loss = 0.7892317113192951   ACC = 75.6370228623225 Class wise = [91.375      94.37030859 55.21557719 75.63805104 26.30560928  2.25806452\n",
            "  1.61290323  0.          0.          0.        ]\n",
            "TEST TEST  val_dataset: Epoch 15 :  Loss = 2.984840493774414   ACC = 31.65: Epoch 15 :  Loss = 2.984840493774414   ACC = 31.65 Class wise = [89.1 92.8 48.7 68.7 15.   1.4  0.5  0.3  0.   0. ]\n",
            "TEST TEST  test_dataset: Epoch 15 :  Loss = 3.135464527130127   ACC = 32.98: Epoch 15 :  Loss = 3.135464527130127   ACC = 32.98 Class wise = [90.3 93.5 52.3 69.6 20.8  1.7  1.3  0.3  0.   0. ]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 15 :  Loss = 0.7502433326155749   ACC = 74.20686876825461\n",
            "TEST TEST  train_dataset: Epoch 16 :  Loss = 0.8665623742115679   ACC = 74.97230335381207: Epoch 16 :  Loss = 0.8665623742115679   ACC = 74.97230335381207 Class wise = [96.35       85.77981651 54.31154381 49.76798144 37.33075435 40.96774194\n",
            "  1.61290323  0.          0.          0.        ]\n",
            "TEST TEST  val_dataset: Epoch 16 :  Loss = 3.1339130115509035   ACC = 33.040000000000006: Epoch 16 :  Loss = 3.1339130115509035   ACC = 33.040000000000006 Class wise = [96.7 82.6 48.5 46.  23.5 30.7  2.   0.4  0.   0. ]\n",
            "TEST TEST  test_dataset: Epoch 16 :  Loss = 3.317484415435791   ACC = 34.75: Epoch 16 :  Loss = 3.317484415435791   ACC = 34.75 Class wise = [95.8 84.  51.4 43.7 32.3 37.5  2.7  0.1  0.   0. ]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 16 :  Loss = 0.7327381430501627   ACC = 74.81115923053682\n",
            "TEST TEST  train_dataset: Epoch 17 :  Loss = 0.8328857578435493   ACC = 75.01258938463089: Epoch 17 :  Loss = 0.8328857578435493   ACC = 75.01258938463089 Class wise = [88.15       92.45204337 62.51738526 73.43387471 20.88974855  0.\n",
            " 31.72043011  5.40540541  0.          0.        ]\n",
            "TEST TEST  val_dataset: Epoch 17 :  Loss = 2.8562559970855714   ACC = 35.19: Epoch 17 :  Loss = 2.8562559970855714   ACC = 35.19 Class wise = [88.9 91.5 52.1 72.7 18.5  0.1 21.   7.1  0.   0. ]\n",
            "TEST TEST  test_dataset: Epoch 17 :  Loss = 3.137096786117554   ACC = 35.44: Epoch 17 :  Loss = 3.137096786117554   ACC = 35.44 Class wise = [89.  90.8 57.  68.7 18.5  0.  26.1  4.3  0.   0. ]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 17 :  Loss = 0.7145195691255851   ACC = 75.41544969281901\n",
            "TEST TEST  train_dataset: Epoch 18 :  Loss = 0.7365672305723081   ACC = 77.34917917212206: Epoch 18 :  Loss = 0.7365672305723081   ACC = 77.34917917212206 Class wise = [93.15       97.24770642 52.64255911 70.99767981 39.65183752  1.93548387\n",
            " 15.05376344 12.61261261  0.          0.        ]\n",
            "TEST TEST  val_dataset: Epoch 18 :  Loss = 2.9393703163146974   ACC = 34.58: Epoch 18 :  Loss = 2.9393703163146974   ACC = 34.58 Class wise = [89.3 95.9 44.5 68.6 27.1  3.1  7.9  9.4  0.   0. ]\n",
            "TEST TEST  test_dataset: Epoch 18 :  Loss = 3.0575497211456297   ACC = 36.27: Epoch 18 :  Loss = 3.0575497211456297   ACC = 36.27 Class wise = [93.  96.3 49.4 65.9 34.5  2.9 12.8  7.9  0.   0. ]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 18 :  Loss = 0.6960382468151246   ACC = 75.88881055494008\n",
            "TEST TEST  train_dataset: Epoch 19 :  Loss = 0.7779841587639297   ACC = 76.96646187934334: Epoch 19 :  Loss = 0.7779841587639297   ACC = 76.96646187934334 Class wise = [89.325      93.66138449 82.47566064 48.14385151 28.82011605 13.22580645\n",
            "  4.83870968 20.72072072  0.          0.        ]\n",
            "TEST TEST  val_dataset: Epoch 19 :  Loss = 2.90028830909729   ACC = 36.13: Epoch 19 :  Loss = 2.90028830909729   ACC = 36.13 Class wise = [88.4 92.5 75.5 48.2 22.9  9.3  3.4 21.1  0.   0. ]\n",
            "TEST TEST  test_dataset: Epoch 19 :  Loss = 3.177885022735596   ACC = 35.53: Epoch 19 :  Loss = 3.177885022735596   ACC = 35.53 Class wise = [89.4 93.2 78.  43.5 24.5  8.2  3.9 14.6  0.   0. ]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 19 :  Loss = 0.6944601454995576   ACC = 75.89888206264477\n",
            "TEST TEST  train_dataset: Epoch 20 :  Loss = 0.694562864965129   ACC = 77.7318964649008: Epoch 20 :  Loss = 0.694562864965129   ACC = 77.7318964649008 Class wise = [95.075      92.53544621 46.73157163 73.78190255 69.24564797  0.32258065\n",
            "  3.22580645 20.72072072  0.          0.        ]\n",
            "TEST TEST  val_dataset: Epoch 20 :  Loss = 2.755243491744995   ACC = 37.5: Epoch 20 :  Loss = 2.755243491744995   ACC = 37.5 Class wise = [94.2 91.2 41.5 67.3 57.3  1.   4.2 18.3  0.   0. ]\n",
            "TEST TEST  test_dataset: Epoch 20 :  Loss = 2.9216875843048093   ACC = 38.32: Epoch 20 :  Loss = 2.9216875843048093   ACC = 38.32 Class wise = [94.3 91.5 44.  69.4 61.   1.   4.3 17.7  0.   0. ]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 20 :  Loss = 0.6726813226569058   ACC = 76.61395910967872\n",
            "TEST TEST  train_dataset: Epoch 21 :  Loss = 0.7168176360979867   ACC = 77.66139591096787: Epoch 21 :  Loss = 0.7168176360979867   ACC = 77.66139591096787 Class wise = [88.45       93.86989158 55.49374131 75.40603248 74.46808511 10.\n",
            " 29.56989247  2.7027027   0.          0.        ]\n",
            "TEST TEST  val_dataset: Epoch 21 :  Loss = 2.760181886291504   ACC = 39.97: Epoch 21 :  Loss = 2.760181886291504   ACC = 39.97 Class wise = [86.9 91.7 59.5 69.6 55.7  7.4 24.9  4.   0.   0. ]\n",
            "TEST TEST  test_dataset: Epoch 21 :  Loss = 2.9101354084014894   ACC = 41.11: Epoch 21 :  Loss = 2.9101354084014894   ACC = 41.11 Class wise = [88.4 92.7 52.2 72.9 65.2  8.4 28.6  2.7  0.   0. ]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 21 :  Loss = 0.6388599721911643   ACC = 77.64125289555847\n",
            "TEST TEST  train_dataset: Epoch 22 :  Loss = 0.8364908415477121   ACC = 76.87581831000101: Epoch 22 :  Loss = 0.8364908415477121   ACC = 76.87581831000101 Class wise = [95.85       96.58048374 59.87482615 42.57540603 35.97678917  2.90322581\n",
            " 28.49462366  6.30630631  0.          0.        ]\n",
            "TEST TEST  val_dataset: Epoch 22 :  Loss = 3.2014272548675535   ACC = 33.71: Epoch 22 :  Loss = 3.2014272548675535   ACC = 33.71 Class wise = [95.3 95.5 53.6 34.4 27.3  3.8 20.7  6.5  0.   0. ]\n",
            "TEST TEST  test_dataset: Epoch 22 :  Loss = 3.3852867210388182   ACC = 35.18: Epoch 22 :  Loss = 3.3852867210388182   ACC = 35.18 Class wise = [95.1 95.8 56.8 38.9 31.8  3.3 25.1  5.   0.   0. ]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 22 :  Loss = 0.6249517375716439   ACC = 78.26568637325008\n",
            "TEST TEST  train_dataset: Epoch 23 :  Loss = 0.9737758469468746   ACC = 75.51616476986605: Epoch 23 :  Loss = 0.9737758469468746   ACC = 75.51616476986605 Class wise = [99.25       89.44954128 50.62586926 56.84454756 17.79497099  1.93548387\n",
            " 36.02150538  0.          0.          0.        ]\n",
            "TEST TEST  val_dataset: Epoch 23 :  Loss = 3.5772671199798585   ACC = 33.36: Epoch 23 :  Loss = 3.5772671199798585   ACC = 33.36 Class wise = [98.  88.7 43.8 53.9 14.3  3.4 31.   0.5  0.   0. ]\n",
            "TEST TEST  test_dataset: Epoch 23 :  Loss = 4.010014461517334   ACC = 33.989999999999995: Epoch 23 :  Loss = 4.010014461517334   ACC = 33.989999999999995 Class wise = [98.4 87.8 48.4 51.5 15.5  1.9 36.1  0.3  0.   0. ]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 23 :  Loss = 0.6126361291314171   ACC = 78.50740255816295\n",
            "TEST TEST  train_dataset: Epoch 24 :  Loss = 0.6870962715854889   ACC = 79.46419579010978: Epoch 24 :  Loss = 0.6870962715854889   ACC = 79.46419579010978 Class wise = [90.625      98.79065888 71.07093185 67.28538283 36.94390716 18.38709677\n",
            " 18.27956989  9.90990991  1.49253731  0.        ]\n",
            "TEST TEST  val_dataset: Epoch 24 :  Loss = 2.855812905502319   ACC = 37.61: Epoch 24 :  Loss = 2.855812905502319   ACC = 37.61 Class wise = [89.5 97.5 62.7 62.  25.  13.3 15.6 10.5  0.   0. ]\n",
            "TEST TEST  test_dataset: Epoch 24 :  Loss = 3.126262762451172   ACC = 37.96: Epoch 24 :  Loss = 3.126262762451172   ACC = 37.96 Class wise = [90.  98.  65.7 61.8 27.6 12.9 16.1  7.5  0.   0. ]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 24 :  Loss = 0.6036849222114552   ACC = 79.09155000503574\n",
            "TEST TEST  train_dataset: Epoch 25 :  Loss = 0.6833597308067724   ACC = 78.68868969684762: Epoch 25 :  Loss = 0.6833597308067724   ACC = 78.68868969684762 Class wise = [90.3        95.87155963 82.96244784 32.01856148 52.22437137 25.48387097\n",
            " 18.8172043  43.24324324  1.49253731  0.        ]\n",
            "TEST TEST  val_dataset: Epoch 25 :  Loss = 2.5405715850830077   ACC = 39.56: Epoch 25 :  Loss = 2.5405715850830077   ACC = 39.56 Class wise = [91.3 94.4 79.2 27.5 37.4 16.9 14.6 34.3  0.   0. ]\n",
            "TEST TEST  test_dataset: Epoch 25 :  Loss = 2.702381763458252   ACC = 40.14: Epoch 25 :  Loss = 2.702381763458252   ACC = 40.14 Class wise = [88.3 94.2 80.3 25.8 40.9 21.9 15.6 33.8  0.6  0. ]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 25 :  Loss = 0.5896841464643933   ACC = 79.55483935945212\n",
            "TEST TEST  train_dataset: Epoch 26 :  Loss = 0.6688432569337619   ACC = 80.4008460066472: Epoch 26 :  Loss = 0.6688432569337619   ACC = 80.4008460066472 Class wise = [96.975      89.9499583  73.50486787 65.0812065  38.49129594  6.4516129\n",
            " 50.         15.31531532  0.          0.        ]\n",
            "TEST TEST  val_dataset: Epoch 26 :  Loss = 2.845283331298828   ACC = 38.31: Epoch 26 :  Loss = 2.845283331298828   ACC = 38.31 Class wise = [96.6 86.7 67.3 58.4 29.2  4.6 28.5 11.8  0.   0. ]\n",
            "TEST TEST  test_dataset: Epoch 26 :  Loss = 3.0473406284332274   ACC = 39.33: Epoch 26 :  Loss = 3.0473406284332274   ACC = 39.33 Class wise = [95.6 87.5 67.  57.9 29.7  4.5 41.3  9.7  0.1  0. ]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 26 :  Loss = 0.570453610505711   ACC = 80.00805720616377\n",
            "TEST TEST  train_dataset: Epoch 27 :  Loss = 0.6784286750312634   ACC = 81.67992748514452: Epoch 27 :  Loss = 0.6784286750312634   ACC = 81.67992748514452 Class wise = [95.8        98.29024187 63.00417246 69.02552204 61.50870406  1.29032258\n",
            " 36.55913978 26.12612613  1.49253731  0.        ]\n",
            "TEST TEST  val_dataset: Epoch 27 :  Loss = 2.8862756401062013   ACC = 39.83: Epoch 27 :  Loss = 2.8862756401062013   ACC = 39.83 Class wise = [93.3 96.6 52.8 60.4 49.1  0.3 24.2 21.6  0.   0. ]\n",
            "TEST TEST  test_dataset: Epoch 27 :  Loss = 3.083545373916626   ACC = 41.260000000000005: Epoch 27 :  Loss = 3.083545373916626   ACC = 41.260000000000005 Class wise = [95.2 98.4 58.8 57.1 51.   0.6 29.2 22.2  0.1  0. ]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 27 :  Loss = 0.5576419543884998   ACC = 80.46127505287541\n",
            "TEST TEST  train_dataset: Epoch 28 :  Loss = 0.601193137874367   ACC = 82.2036458857891: Epoch 28 :  Loss = 0.601193137874367   ACC = 82.2036458857891 Class wise = [96.65       95.74645538 59.94436718 70.76566125 75.43520309 18.70967742\n",
            " 13.44086022 49.54954955  0.          0.        ]\n",
            "TEST TEST  val_dataset: Epoch 28 :  Loss = 2.7114111835479737   ACC = 42.44: Epoch 28 :  Loss = 2.7114111835479737   ACC = 42.44 Class wise = [97.5 94.7 47.2 62.  57.7 12.7 13.2 39.4  0.   0. ]\n",
            "TEST TEST  test_dataset: Epoch 28 :  Loss = 2.8834005783081054   ACC = 43.21: Epoch 28 :  Loss = 2.8834005783081054   ACC = 43.21 Class wise = [95.8 95.2 52.3 63.2 62.2 15.1  9.6 38.7  0.   0. ]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 28 :  Loss = 0.5428906882117793   ACC = 81.23678114613759\n",
            "TEST TEST  train_dataset: Epoch 29 :  Loss = 0.7467457311897074   ACC = 80.09870077550609: Epoch 29 :  Loss = 0.7467457311897074   ACC = 80.09870077550609 Class wise = [96.6        95.99666389 59.73574409 63.45707657 32.10831721 21.29032258\n",
            " 74.19354839  9.90990991  0.          0.        ]\n",
            "TEST TEST  val_dataset: Epoch 29 :  Loss = 2.6882460304260256   ACC = 42.82: Epoch 29 :  Loss = 2.6882460304260256   ACC = 42.82 Class wise = [95.7 93.8 56.4 56.  33.3 20.9 61.2 10.4  0.5  0. ]\n",
            "TEST TEST  test_dataset: Epoch 29 :  Loss = 3.06299988861084   ACC = 41.75: Epoch 29 :  Loss = 3.06299988861084   ACC = 41.75 Class wise = [95.9 95.1 53.3 55.2 26.5 18.7 65.4  6.8  0.6  0. ]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 29 :  Loss = 0.52843908229159   ACC = 81.87128613153389\n",
            "TEST TEST  train_dataset: Epoch 30 :  Loss = 0.4925408069131021   ACC = 84.36902004230033: Epoch 30 :  Loss = 0.4925408069131021   ACC = 84.36902004230033 Class wise = [93.625      94.8707256  75.86926287 76.56612529 75.0483559  15.48387097\n",
            " 55.37634409 49.54954955 17.91044776  0.        ]\n",
            "TEST TEST  val_dataset: Epoch 30 :  Loss = 2.1334140830993653   ACC = 47.24: Epoch 30 :  Loss = 2.1334140830993653   ACC = 47.24 Class wise = [92.  92.2 67.7 70.1 58.6 10.  39.7 38.5  2.3  1.3]\n",
            "TEST TEST  test_dataset: Epoch 30 :  Loss = 2.2339781162261962   ACC = 48.89: Epoch 30 :  Loss = 2.2339781162261962   ACC = 48.89 Class wise = [92.6 93.  70.1 67.2 59.4 12.9 45.  41.5  4.6  2.6]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 30 :  Loss = 0.5135697085537547   ACC = 81.95185819317152\n",
            "dy tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
            "       grad_fn=<MvBackward>)\n",
            "ly tensor([0.0000, 0.1111, 0.2222, 0.3333, 0.4444, 0.5556, 0.6667, 0.7778, 0.8889,\n",
            "        1.0000], device='cuda:0', grad_fn=<MvBackward>)\n",
            "TEST TEST  train_dataset: Epoch 31 :  Loss = 0.50236129441378   ACC = 84.68123678114614: Epoch 31 :  Loss = 0.50236129441378   ACC = 84.68123678114614 Class wise = [94.15       97.28940784 79.97218359 60.55684455 60.92843327 67.74193548\n",
            " 32.25806452 45.94594595  1.49253731  0.        ]\n",
            "TEST TEST  val_dataset: Epoch 31 :  Loss = 2.64199987487793   ACC = 45.94: Epoch 31 :  Loss = 2.64199987487793   ACC = 45.94 Class wise = [92.8 94.6 69.8 53.9 43.4 50.1 19.4 35.2  0.2  0. ]\n",
            "TEST TEST  test_dataset: Epoch 31 :  Loss = 2.7755955078125   ACC = 47.23: Epoch 31 :  Loss = 2.7755955078125   ACC = 47.23 Class wise = [92.3 96.1 69.8 51.8 45.  54.5 25.7 36.9  0.2  0. ]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 31 :  Loss = 0.5052222039046659   ACC = 82.44536207070199\n",
            "TEST TEST  train_dataset: Epoch 32 :  Loss = 0.5218438798776865   ACC = 84.30859099607211: Epoch 32 :  Loss = 0.5218438798776865   ACC = 84.30859099607211 Class wise = [96.675      93.28607173 74.61752434 70.88167053 49.9032882  58.06451613\n",
            " 63.44086022 22.52252252  1.49253731  2.5       ]\n",
            "TEST TEST  val_dataset: Epoch 32 :  Loss = 2.482307438659668   ACC = 47.53: Epoch 32 :  Loss = 2.482307438659668   ACC = 47.53 Class wise = [94.8 91.4 62.8 65.5 39.2 43.9 49.8 26.6  0.   1.3]\n",
            "TEST TEST  test_dataset: Epoch 32 :  Loss = 2.7066028347015383   ACC = 47.82: Epoch 32 :  Loss = 2.7066028347015383   ACC = 47.82 Class wise = [96.  91.7 65.5 62.1 41.3 47.2 51.7 21.5  0.3  0.9]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 32 :  Loss = 0.5117249070025245   ACC = 82.62664920938664\n",
            "TEST TEST  train_dataset: Epoch 33 :  Loss = 0.5592134533115523   ACC = 82.38493302447377: Epoch 33 :  Loss = 0.5592134533115523   ACC = 82.38493302447377 Class wise = [88.8        98.74895746 81.15438108 62.0649652  57.44680851 59.35483871\n",
            " 13.44086022 31.53153153 25.37313433  0.        ]\n",
            "TEST TEST  val_dataset: Epoch 33 :  Loss = 2.354695157623291   ACC = 44.93: Epoch 33 :  Loss = 2.354695157623291   ACC = 44.93 Class wise = [89.  98.  73.9 59.4 41.9 44.6 11.1 21.6  9.5  0.3]\n",
            "TEST TEST  test_dataset: Epoch 33 :  Loss = 2.559818396759033   ACC = 45.72: Epoch 33 :  Loss = 2.559818396759033   ACC = 45.72 Class wise = [87.1 98.  73.9 54.4 44.6 51.8 11.9 20.  15.1  0.4]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 33 :  Loss = 0.47948336932027386   ACC = 83.43236982576292\n",
            "TEST TEST  train_dataset: Epoch 34 :  Loss = 0.6727466677380348   ACC = 81.34756773088931: Epoch 34 :  Loss = 0.6727466677380348   ACC = 81.34756773088931 Class wise = [90.65       99.49958299 71.76634214 52.20417633 61.70212766 27.74193548\n",
            " 53.76344086 56.75675676 22.3880597   0.        ]\n",
            "TEST TEST  val_dataset: Epoch 34 :  Loss = 2.7413157859802246   ACC = 44.230000000000004: Epoch 34 :  Loss = 2.7413157859802246   ACC = 44.230000000000004 Class wise = [90.2 98.9 65.8 46.3 47.  14.2 36.3 38.6  5.   0. ]\n",
            "TEST TEST  test_dataset: Epoch 34 :  Loss = 2.8269480144500734   ACC = 46.129999999999995: Epoch 34 :  Loss = 2.8269480144500734   ACC = 46.129999999999995 Class wise = [89.6 99.  64.1 41.1 48.5 22.5 44.9 41.6 10.   0. ]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 34 :  Loss = 0.47963053169945885   ACC = 83.21079665625945\n",
            "TEST TEST  train_dataset: Epoch 35 :  Loss = 0.4828490161117752   ACC = 84.68123678114614: Epoch 35 :  Loss = 0.4828490161117752   ACC = 84.68123678114614 Class wise = [95.425      93.82819016 85.04867872 54.98839907 68.27852998 31.93548387\n",
            " 74.7311828  38.73873874 14.92537313  0.        ]\n",
            "TEST TEST  val_dataset: Epoch 35 :  Loss = 2.2552469749450683   ACC = 49.7: Epoch 35 :  Loss = 2.2552469749450683   ACC = 49.7 Class wise = [92.7 93.5 78.  48.5 60.2 22.4 66.2 30.   5.5  0. ]\n",
            "TEST TEST  test_dataset: Epoch 35 :  Loss = 2.3785786071777344   ACC = 49.61: Epoch 35 :  Loss = 2.3785786071777344   ACC = 49.61 Class wise = [92.  93.7 77.8 47.3 54.3 27.3 66.2 30.   7.3  0.2]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 35 :  Loss = 0.46873186043183096   ACC = 84.11723234968275\n",
            "TEST TEST  train_dataset: Epoch 36 :  Loss = 0.42441173816738154   ACC = 86.03081881357639: Epoch 36 :  Loss = 0.42441173816738154   ACC = 86.03081881357639 Class wise = [93.9        98.16513761 71.83588317 64.15313225 88.20116054 70.32258065\n",
            " 62.90322581 27.02702703 32.8358209   7.5       ]\n",
            "TEST TEST  val_dataset: Epoch 36 :  Loss = 1.9646658710479736   ACC = 52.15: Epoch 36 :  Loss = 1.9646658710479736   ACC = 52.15 Class wise = [92.5 94.9 64.1 51.7 75.2 57.  50.1 24.1 10.6  1.3]\n",
            "TEST TEST  test_dataset: Epoch 36 :  Loss = 2.1041219253540038   ACC = 53.42: Epoch 36 :  Loss = 2.1041219253540038   ACC = 53.42 Class wise = [90.5 95.9 64.9 53.5 78.5 59.9 50.9 22.1 15.8  2.2]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 36 :  Loss = 0.44370322830668146   ACC = 84.80209487360257\n",
            "TEST TEST  train_dataset: Epoch 37 :  Loss = 0.530915371744231   ACC = 83.90573068788397: Epoch 37 :  Loss = 0.530915371744231   ACC = 83.90573068788397 Class wise = [96.825      93.11926606 89.56884562 48.60788863 41.3926499  49.67741935\n",
            " 62.90322581  9.00900901 34.32835821  0.        ]\n",
            "TEST TEST  val_dataset: Epoch 37 :  Loss = 2.7522123203277586   ACC = 44.190000000000005: Epoch 37 :  Loss = 2.7522123203277586   ACC = 44.190000000000005 Class wise = [95.2 89.3 84.3 41.4 31.3 36.5 48.   7.5  8.4  0. ]\n",
            "TEST TEST  test_dataset: Epoch 37 :  Loss = 2.875355932235718   ACC = 44.89: Epoch 37 :  Loss = 2.875355932235718   ACC = 44.89 Class wise = [95.2 91.  84.7 41.9 31.4 38.7 48.1  7.9 10.   0. ]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 37 :  Loss = 0.45130335785780973   ACC = 84.2985194883674\n",
            "TEST TEST  train_dataset: Epoch 38 :  Loss = 0.5355981178953155   ACC = 84.14744687279686: Epoch 38 :  Loss = 0.5355981178953155   ACC = 84.14744687279686 Class wise = [98.         84.77898249 77.39916551 65.0812065  73.11411992 40.96774194\n",
            " 80.64516129 52.25225225 16.41791045 10.        ]\n",
            "TEST TEST  val_dataset: Epoch 38 :  Loss = 2.3588902320861815   ACC = 50.23: Epoch 38 :  Loss = 2.3588902320861815   ACC = 50.23 Class wise = [98.1 79.3 69.7 56.  54.6 30.5 67.7 38.9  6.7  0.8]\n",
            "TEST TEST  test_dataset: Epoch 38 :  Loss = 2.4989236278533937   ACC = 50.870000000000005: Epoch 38 :  Loss = 2.4989236278533937   ACC = 50.870000000000005 Class wise = [96.9 80.5 69.6 54.4 58.5 33.4 68.6 37.7  7.8  1.3]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 38 :  Loss = 0.43707859756267253   ACC = 84.83230939671668\n",
            "TEST TEST  train_dataset: Epoch 39 :  Loss = 0.5181744315314718   ACC = 84.00644576493102: Epoch 39 :  Loss = 0.5181744315314718   ACC = 84.00644576493102 Class wise = [90.95       95.03753128 88.45618915 51.97215777 82.01160542 44.19354839\n",
            " 31.72043011 59.45945946 23.88059701  5.        ]\n",
            "TEST TEST  val_dataset: Epoch 39 :  Loss = 2.2971016874313355   ACC = 48.06: Epoch 39 :  Loss = 2.2971016874313355   ACC = 48.06 Class wise = [88.5 93.6 82.8 44.8 65.1 27.7 22.  45.4  7.8  2.9]\n",
            "TEST TEST  test_dataset: Epoch 39 :  Loss = 2.4186867252349855   ACC = 49.47: Epoch 39 :  Loss = 2.4186867252349855   ACC = 49.47 Class wise = [88.9 94.4 83.4 41.  67.4 33.3 24.  48.2  9.4  4.7]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 39 :  Loss = 0.43083430349868834   ACC = 84.92295296605901\n",
            "TEST TEST  train_dataset: Epoch 40 :  Loss = 0.41365961460491385   ACC = 87.04804109175144: Epoch 40 :  Loss = 0.41365961460491385   ACC = 87.04804109175144 Class wise = [97.125      94.95412844 84.63143255 73.66589327 47.58220503 75.48387097\n",
            " 35.48387097 45.04504505 43.28358209 10.        ]\n",
            "TEST TEST  val_dataset: Epoch 40 :  Loss = 2.1995882499694823   ACC = 49.28: Epoch 40 :  Loss = 2.1995882499694823   ACC = 49.28 Class wise = [96.1 92.  75.3 66.2 33.7 53.  27.7 34.9 13.   0.9]\n",
            "TEST TEST  test_dataset: Epoch 40 :  Loss = 2.387342663192749   ACC = 49.54: Epoch 40 :  Loss = 2.387342663192749   ACC = 49.54 Class wise = [95.3 93.6 76.8 63.5 31.1 58.  23.7 33.6 17.8  2. ]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 40 :  Loss = 0.4041686228742195   ACC = 85.63803001309296\n",
            "TEST TEST  train_dataset: Epoch 41 :  Loss = 0.4087177419941019   ACC = 87.15882767650317: Epoch 41 :  Loss = 0.4087177419941019   ACC = 87.15882767650317 Class wise = [96.         98.62385321 83.72739917 69.48955916 66.5377176  37.41935484\n",
            " 60.21505376 45.94594595 31.34328358  5.        ]\n",
            "TEST TEST  val_dataset: Epoch 41 :  Loss = 2.4027029064178467   ACC = 48.71: Epoch 41 :  Loss = 2.4027029064178467   ACC = 48.71 Class wise = [95.1 96.  74.3 62.  50.4 23.1 40.2 36.2  7.8  2. ]\n",
            "TEST TEST  test_dataset: Epoch 41 :  Loss = 2.588328298187256   ACC = 49.6: Epoch 41 :  Loss = 2.588328298187256   ACC = 49.6 Class wise = [93.1 97.  75.2 58.6 52.8 29.1 44.8 34.4  9.8  1.2]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 41 :  Loss = 0.3996491414450821   ACC = 85.87974619800585\n",
            "TEST TEST  train_dataset: Epoch 42 :  Loss = 0.3594525014631385   ACC = 88.36740860106758: Epoch 42 :  Loss = 0.3594525014631385   ACC = 88.36740860106758 Class wise = [96.55       98.3736447  81.15438108 77.84222738 82.9787234  40.\n",
            " 33.87096774 65.76576577 25.37313433 22.5       ]\n",
            "TEST TEST  val_dataset: Epoch 42 :  Loss = 2.2034638416290284   ACC = 50.24999999999999: Epoch 42 :  Loss = 2.2034638416290284   ACC = 50.24999999999999 Class wise = [95.3 97.7 71.4 66.8 65.8 24.9 22.6 43.7  9.6  4.7]\n",
            "TEST TEST  test_dataset: Epoch 42 :  Loss = 2.391684401702881   ACC = 50.160000000000004: Epoch 42 :  Loss = 2.391684401702881   ACC = 50.160000000000004 Class wise = [94.3 97.8 69.7 63.4 66.2 30.6 19.8 44.2 11.5  4.1]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 42 :  Loss = 0.3934329353991034   ACC = 85.87974619800585\n",
            "TEST TEST  train_dataset: Epoch 43 :  Loss = 0.40649692355379835   ACC = 87.68254607714775: Epoch 43 :  Loss = 0.40649692355379835   ACC = 87.68254607714775 Class wise = [95.75       95.3294412  87.1349096  74.24593968 64.41005803 69.67741935\n",
            " 52.15053763 18.01801802 46.26865672  0.        ]\n",
            "TEST TEST  val_dataset: Epoch 43 :  Loss = 2.517121417236328   ACC = 50.24999999999999: Epoch 43 :  Loss = 2.517121417236328   ACC = 50.24999999999999 Class wise = [95.5 93.3 76.5 66.3 48.5 49.3 39.6  9.5 23.9  0.1]\n",
            "TEST TEST  test_dataset: Epoch 43 :  Loss = 2.8503652507781982   ACC = 49.08: Epoch 43 :  Loss = 2.8503652507781982   ACC = 49.08 Class wise = [93.2 92.6 77.1 60.5 43.8 55.  35.8  9.3 23.2  0.3]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 43 :  Loss = 0.39185452404813664   ACC = 86.32289253701279\n",
            "TEST TEST  train_dataset: Epoch 44 :  Loss = 0.49959170629831945   ACC = 85.59774398227414: Epoch 44 :  Loss = 0.49959170629831945   ACC = 85.59774398227414 Class wise = [96.9        91.49291076 88.52573018 58.70069606 83.94584139 24.83870968\n",
            " 39.78494624 48.64864865 11.94029851  7.5       ]\n",
            "TEST TEST  val_dataset: Epoch 44 :  Loss = 2.77652631149292   ACC = 47.78: Epoch 44 :  Loss = 2.77652631149292   ACC = 47.78 Class wise = [95.3 87.6 82.  52.6 67.7 22.4 31.6 33.9  2.9  1.8]\n",
            "TEST TEST  test_dataset: Epoch 44 :  Loss = 3.174961273193359   ACC = 47.0: Epoch 44 :  Loss = 3.174961273193359   ACC = 47.0 Class wise = [95.9 87.4 79.3 46.  70.2 20.9 32.6 31.6  3.7  2.4]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 44 :  Loss = 0.3741696671916586   ACC = 86.9070399838856\n",
            "TEST TEST  train_dataset: Epoch 45 :  Loss = 0.46994821298205247   ACC = 85.59774398227414: Epoch 45 :  Loss = 0.46994821298205247   ACC = 85.59774398227414 Class wise = [95.575      98.79065888 51.32127955 89.79118329 80.85106383 66.12903226\n",
            " 43.01075269 63.96396396 29.85074627  2.5       ]\n",
            "TEST TEST  val_dataset: Epoch 45 :  Loss = 2.328487616729736   ACC = 50.839999999999996: Epoch 45 :  Loss = 2.328487616729736   ACC = 50.839999999999996 Class wise = [93.8 96.7 39.2 83.8 59.5 45.8 27.5 47.8 11.1  3.2]\n",
            "TEST TEST  test_dataset: Epoch 45 :  Loss = 2.5316278469085693   ACC = 51.5: Epoch 45 :  Loss = 2.5316278469085693   ACC = 51.5 Class wise = [92.3 97.9 40.8 79.7 62.6 49.1 32.8 46.1 11.5  2.2]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 45 :  Loss = 0.36802487860795163   ACC = 87.2393997381408\n",
            "TEST TEST  train_dataset: Epoch 46 :  Loss = 0.9042201568766031   ACC = 79.70591197502266: Epoch 46 :  Loss = 0.9042201568766031   ACC = 79.70591197502266 Class wise = [99.85       84.98748957 71.48817803 55.22041763 51.06382979 11.29032258\n",
            " 15.59139785 29.72972973 14.92537313 17.5       ]\n",
            "TEST TEST  val_dataset: Epoch 46 :  Loss = 3.6339316223144533   ACC = 38.35: Epoch 46 :  Loss = 3.6339316223144533   ACC = 38.35 Class wise = [99.  82.6 61.3 46.6 37.1  8.9 12.1 26.5  4.   5.4]\n",
            "TEST TEST  test_dataset: Epoch 46 :  Loss = 4.24340757598877   ACC = 37.71: Epoch 46 :  Loss = 4.24340757598877   ACC = 37.71 Class wise = [99.3 81.3 62.8 43.4 37.5  7.7 10.8 21.5  5.   7.8]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 46 :  Loss = 0.35339864013009903   ACC = 87.61204552321482\n",
            "TEST TEST  train_dataset: Epoch 47 :  Loss = 0.4620542279398205   ACC = 86.44375062946924: Epoch 47 :  Loss = 0.4620542279398205   ACC = 86.44375062946924 Class wise = [96.125      98.54045038 71.62726008 71.57772622 83.75241779 36.77419355\n",
            " 41.93548387 84.68468468  8.95522388  7.5       ]\n",
            "TEST TEST  val_dataset: Epoch 47 :  Loss = 2.7647183052062987   ACC = 49.86: Epoch 47 :  Loss = 2.7647183052062987   ACC = 49.86 Class wise = [93.2 98.  63.6 61.6 67.6 22.6 24.4 63.3  2.4  1.9]\n",
            "TEST TEST  test_dataset: Epoch 47 :  Loss = 3.0887627243041993   ACC = 49.71: Epoch 47 :  Loss = 3.0887627243041993   ACC = 49.71 Class wise = [94.5 98.5 58.  58.6 68.2 23.2 27.5 64.3  2.4  1.9]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 47 :  Loss = 0.3645390260254392   ACC = 86.91711149159029\n",
            "TEST TEST  train_dataset: Epoch 48 :  Loss = 0.2888655940539552   ACC = 90.72414140396818: Epoch 48 :  Loss = 0.2888655940539552   ACC = 90.72414140396818 Class wise = [96.6        98.87406172 85.4659249  88.86310905 78.72340426 50.64516129\n",
            " 53.22580645 60.36036036 61.19402985 17.5       ]\n",
            "TEST TEST  val_dataset: Epoch 48 :  Loss = 1.9984754806518554   ACC = 54.0: Epoch 48 :  Loss = 1.9984754806518554   ACC = 54.0 Class wise = [93.6 97.  74.1 78.1 55.8 29.9 33.6 42.9 30.4  4.6]\n",
            "TEST TEST  test_dataset: Epoch 48 :  Loss = 2.114800227737427   ACC = 55.06999999999999: Epoch 48 :  Loss = 2.114800227737427   ACC = 55.06999999999999 Class wise = [93.2 97.6 73.2 73.7 57.9 35.2 39.7 44.2 31.9  4.1]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 48 :  Loss = 0.33985946584004795   ACC = 88.24655050861114\n",
            "TEST TEST  train_dataset: Epoch 49 :  Loss = 0.3743071651720475   ACC = 88.25662201631584: Epoch 49 :  Loss = 0.3743071651720475   ACC = 88.25662201631584 Class wise = [96.6        99.08256881 80.52851182 58.00464037 87.42746615 52.58064516\n",
            " 73.11827957 59.45945946 58.20895522 22.5       ]\n",
            "TEST TEST  val_dataset: Epoch 49 :  Loss = 2.2037501777648925   ACC = 52.459999999999994: Epoch 49 :  Loss = 2.2037501777648925   ACC = 52.459999999999994 Class wise = [94.5 97.8 70.7 47.7 69.5 36.  51.1 35.2 13.6  8.5]\n",
            "TEST TEST  test_dataset: Epoch 49 :  Loss = 2.4370102613449096   ACC = 52.400000000000006: Epoch 49 :  Loss = 2.4370102613449096   ACC = 52.400000000000006 Class wise = [93.3 98.2 69.9 40.3 71.1 36.6 56.9 31.2 20.2  6.3]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 49 :  Loss = 0.3447588140065966   ACC = 87.79333266189948\n",
            "TEST TEST  train_dataset: Epoch 50 :  Loss = 0.3292204668867899   ACC = 89.65656158726961: Epoch 50 :  Loss = 0.3292204668867899   ACC = 89.65656158726961 Class wise = [95.425      96.12176814 84.49235049 89.55916473 93.23017408 34.83870968\n",
            " 55.37634409 59.45945946 40.29850746 17.5       ]\n",
            "TEST TEST  val_dataset: Epoch 50 :  Loss = 2.240711420440674   ACC = 51.76: Epoch 50 :  Loss = 2.240711420440674   ACC = 51.76 Class wise = [92.6 93.5 75.4 76.8 75.7 17.2 37.9 31.  13.5  4. ]\n",
            "TEST TEST  test_dataset: Epoch 50 :  Loss = 2.496984213256836   ACC = 51.93: Epoch 50 :  Loss = 2.496984213256836   ACC = 51.93 Class wise = [90.9 93.4 71.7 76.3 77.1 19.4 41.  31.9 14.1  3.5]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 50 :  Loss = 0.3336449649377416   ACC = 88.15590693926882\n",
            "TEST TEST  train_dataset: Epoch 51 :  Loss = 1.1207177550402012   ACC = 75.84852452412126: Epoch 51 :  Loss = 1.1207177550402012   ACC = 75.84852452412126 Class wise = [85.425      91.61801501 65.09040334 20.41763341 69.63249516 70.96774194\n",
            " 55.91397849 97.2972973   5.97014925 22.5       ]\n",
            "TEST TEST  val_dataset: Epoch 51 :  Loss = 2.631877780914307   ACC = 51.080000000000005: Epoch 51 :  Loss = 2.631877780914307   ACC = 51.080000000000005 Class wise = [82.  89.3 56.3 19.7 59.1 67.2 41.9 87.5  1.7  6.1]\n",
            "TEST TEST  test_dataset: Epoch 51 :  Loss = 2.9533582511901857   ACC = 51.39: Epoch 51 :  Loss = 2.9533582511901857   ACC = 51.39 Class wise = [84.  89.4 54.  16.6 61.2 65.8 45.3 88.3  2.   7.3]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 51 :  Loss = 0.36447196123114717   ACC = 87.04804109175144\n",
            "TEST TEST  train_dataset: Epoch 52 :  Loss = 0.30626251277264205   ACC = 90.27092355725652: Epoch 52 :  Loss = 0.30626251277264205   ACC = 90.27092355725652 Class wise = [97.575      94.32860717 89.56884562 75.05800464 76.20889749 79.35483871\n",
            " 43.01075269 85.58558559 31.34328358 67.5       ]\n",
            "TEST TEST  val_dataset: Epoch 52 :  Loss = 1.9416757321357727   ACC = 55.94: Epoch 52 :  Loss = 1.9416757321357727   ACC = 55.94 Class wise = [95.1 92.1 78.3 63.9 51.6 57.1 26.6 61.2  9.8 23.7]\n",
            "TEST TEST  test_dataset: Epoch 52 :  Loss = 2.2064651180267334   ACC = 54.879999999999995: Epoch 52 :  Loss = 2.2064651180267334   ACC = 54.879999999999995 Class wise = [93.6 91.1 78.7 58.6 53.7 57.  26.4 59.8 10.6 19.3]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 52 :  Loss = 0.32934639977717256   ACC = 88.23647900090643\n",
            "TEST TEST  train_dataset: Epoch 53 :  Loss = 0.3584794277138239   ACC = 89.18320072514857: Epoch 53 :  Loss = 0.3584794277138239   ACC = 89.18320072514857 Class wise = [97.425      96.66388657 89.42976356 59.51276102 90.13539652 52.58064516\n",
            " 72.04301075 46.84684685 22.3880597  27.5       ]\n",
            "TEST TEST  val_dataset: Epoch 53 :  Loss = 2.428538237762451   ACC = 52.33: Epoch 53 :  Loss = 2.428538237762451   ACC = 52.33 Class wise = [94.7 94.7 81.3 48.1 76.3 35.9 53.  27.8  6.1  5.4]\n",
            "TEST TEST  test_dataset: Epoch 53 :  Loss = 2.7764197853088377   ACC = 51.339999999999996: Epoch 53 :  Loss = 2.7764197853088377   ACC = 51.339999999999996 Class wise = [94.6 94.4 80.4 41.6 76.4 35.1 52.2 25.6  7.5  5.6]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 53 :  Loss = 0.31915098095855055   ACC = 88.76019740155101\n",
            "TEST TEST  train_dataset: Epoch 54 :  Loss = 0.4045771395995641   ACC = 87.96454829287944: Epoch 54 :  Loss = 0.4045771395995641   ACC = 87.96454829287944 Class wise = [95.825      96.58048374 86.02225313 59.39675174 94.77756286 43.22580645\n",
            " 50.53763441 60.36036036 50.74626866 42.5       ]\n",
            "TEST TEST  val_dataset: Epoch 54 :  Loss = 2.3286862155914307   ACC = 52.0: Epoch 54 :  Loss = 2.3286862155914307   ACC = 52.0 Class wise = [93.3 94.7 76.8 51.4 79.5 28.4 36.7 35.5 13.  10.7]\n",
            "TEST TEST  test_dataset: Epoch 54 :  Loss = 2.6536114585876467   ACC = 51.339999999999996: Epoch 54 :  Loss = 2.6536114585876467   ACC = 51.339999999999996 Class wise = [91.9 94.3 78.  45.  82.1 28.7 33.2 32.3 17.8 10.1]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 54 :  Loss = 0.3023258824400797   ACC = 89.2839158021956\n",
            "TEST TEST  train_dataset: Epoch 55 :  Loss = 0.3683447737548032   ACC = 88.39762312418169: Epoch 55 :  Loss = 0.3683447737548032   ACC = 88.39762312418169 Class wise = [93.8        99.33277731 72.53129346 73.31786543 85.29980658 81.93548387\n",
            " 58.06451613 82.88288288 77.6119403  52.5       ]\n",
            "TEST TEST  val_dataset: Epoch 55 :  Loss = 1.8088063440322877   ACC = 59.62: Epoch 55 :  Loss = 1.8088063440322877   ACC = 59.62 Class wise = [90.1 98.3 59.4 64.8 69.  59.5 41.5 62.7 32.4 18.5]\n",
            "TEST TEST  test_dataset: Epoch 55 :  Loss = 1.941253321838379   ACC = 60.11: Epoch 55 :  Loss = 1.941253321838379   ACC = 60.11 Class wise = [89.3 98.3 59.  56.2 73.2 62.2 41.5 62.7 40.  18.7]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 55 :  Loss = 0.29916372130147423   ACC = 89.3443448484238\n",
            "TEST TEST  train_dataset: Epoch 56 :  Loss = 0.27218652302368324   ACC = 91.14714472756572: Epoch 56 :  Loss = 0.27218652302368324   ACC = 91.14714472756572 Class wise = [96.275      95.82985822 86.57858136 77.95823666 90.52224371 70.64516129\n",
            " 78.49462366 63.96396396 92.53731343 45.        ]\n",
            "TEST TEST  val_dataset: Epoch 56 :  Loss = 1.8496817111968995   ACC = 59.08: Epoch 56 :  Loss = 1.8496817111968995   ACC = 59.08 Class wise = [92.4 92.6 77.7 61.4 70.2 49.2 53.2 33.8 52.1  8.2]\n",
            "TEST TEST  test_dataset: Epoch 56 :  Loss = 1.96710811958313   ACC = 59.830000000000005: Epoch 56 :  Loss = 1.96710811958313   ACC = 59.830000000000005 Class wise = [92.4 93.  75.8 58.9 71.1 49.3 56.7 35.4 56.4  9.3]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 56 :  Loss = 0.2868315447420137   ACC = 89.62634706415551\n",
            "TEST TEST  train_dataset: Epoch 57 :  Loss = 0.30999369721048153   ACC = 90.15006546480008: Epoch 57 :  Loss = 0.30999369721048153   ACC = 90.15006546480008 Class wise = [94.225      96.37197665 86.50904033 77.37819026 83.172147   92.90322581\n",
            " 54.83870968 59.45945946 82.08955224 47.5       ]\n",
            "TEST TEST  val_dataset: Epoch 57 :  Loss = 1.9791126432418824   ACC = 57.699999999999996: Epoch 57 :  Loss = 1.9791126432418824   ACC = 57.699999999999996 Class wise = [91.8 93.6 76.9 66.8 57.  66.5 34.1 35.4 42.3 12.6]\n",
            "TEST TEST  test_dataset: Epoch 57 :  Loss = 2.1814220115661622   ACC = 58.28: Epoch 57 :  Loss = 2.1814220115661622   ACC = 58.28 Class wise = [89.8 93.6 72.9 66.3 59.7 70.4 38.4 35.6 42.9 13.2]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 57 :  Loss = 0.28719231869017253   ACC = 89.8982777721825\n",
            "TEST TEST  train_dataset: Epoch 58 :  Loss = 0.3854104788347918   ACC = 88.95155604794037: Epoch 58 :  Loss = 0.3854104788347918   ACC = 88.95155604794037 Class wise = [96.925      98.66555463 69.74965229 70.76566125 96.51837524 71.29032258\n",
            " 72.04301075 67.56756757 47.76119403 37.5       ]\n",
            "TEST TEST  val_dataset: Epoch 58 :  Loss = 2.4380875759124754   ACC = 54.74: Epoch 58 :  Loss = 2.4380875759124754   ACC = 54.74 Class wise = [94.6 96.8 58.4 61.2 82.4 50.8 50.4 35.3 12.   5.5]\n",
            "TEST TEST  test_dataset: Epoch 58 :  Loss = 2.8628450496673583   ACC = 54.22: Epoch 58 :  Loss = 2.8628450496673583   ACC = 54.22 Class wise = [93.  97.5 57.6 52.5 85.4 51.2 51.2 37.5 11.   5.3]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 58 :  Loss = 0.2932459676190078   ACC = 89.46520294088025\n",
            "TEST TEST  train_dataset: Epoch 59 :  Loss = 0.33782983108377973   ACC = 90.01913586463893: Epoch 59 :  Loss = 0.33782983108377973   ACC = 90.01913586463893 Class wise = [95.4        98.54045038 91.30737135 77.26218097 74.6615087  51.61290323\n",
            " 76.88172043 49.54954955 53.73134328  0.        ]\n",
            "TEST TEST  val_dataset: Epoch 59 :  Loss = 2.6825379772186277   ACC = 53.510000000000005: Epoch 59 :  Loss = 2.6825379772186277   ACC = 53.510000000000005 Class wise = [92.5 97.6 82.5 65.7 54.4 34.  58.8 34.5 14.2  0.9]\n",
            "TEST TEST  test_dataset: Epoch 59 :  Loss = 3.0842354679107666   ACC = 52.400000000000006: Epoch 59 :  Loss = 3.0842354679107666   ACC = 52.400000000000006 Class wise = [91.4 96.9 82.  61.2 55.8 35.1 59.3 27.3 14.3  0.7]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 59 :  Loss = 0.30410983580118556   ACC = 89.66663309497432\n",
            "TEST TEST  train_dataset: Epoch 60 :  Loss = 0.2520260907801896   ACC = 91.83200725148555: Epoch 60 :  Loss = 0.2520260907801896   ACC = 91.83200725148555 Class wise = [95.175      99.45788157 85.32684284 86.07888631 91.8762089  64.51612903\n",
            " 89.24731183 55.85585586 65.67164179 25.        ]\n",
            "TEST TEST  val_dataset: Epoch 60 :  Loss = 2.151552938461304   ACC = 57.21000000000001: Epoch 60 :  Loss = 2.151552938461304   ACC = 57.21000000000001 Class wise = [93.  97.7 74.9 71.4 73.7 42.2 69.9 26.  19.   4.3]\n",
            "TEST TEST  test_dataset: Epoch 60 :  Loss = 2.4077074043273927   ACC = 57.04: Epoch 60 :  Loss = 2.4077074043273927   ACC = 57.04 Class wise = [90.5 97.3 72.2 67.4 72.9 40.4 73.1 28.4 23.1  5.1]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 60 :  Loss = 0.26289448188575615   ACC = 90.45221069594118\n",
            "dy tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
            "       grad_fn=<MvBackward>)\n",
            "ly tensor([0.0000, 0.1111, 0.2222, 0.3333, 0.4444, 0.5556, 0.6667, 0.7778, 0.8889,\n",
            "        1.0000], device='cuda:0', grad_fn=<MvBackward>)\n",
            "TEST TEST  train_dataset: Epoch 61 :  Loss = 0.43049604405737835   ACC = 89.0019135864639: Epoch 61 :  Loss = 0.43049604405737835   ACC = 89.0019135864639 Class wise = [91.55       99.74979149 87.20445063 74.7099768  80.85106383 70.\n",
            " 66.12903226 58.55855856 73.13432836 32.5       ]\n",
            "TEST TEST  val_dataset: Epoch 61 :  Loss = 2.5616930881500246   ACC = 54.339999999999996: Epoch 61 :  Loss = 2.5616930881500246   ACC = 54.339999999999996 Class wise = [87.4 99.2 76.7 60.8 62.2 40.2 44.5 31.4 33.1  7.9]\n",
            "TEST TEST  test_dataset: Epoch 61 :  Loss = 2.8540963100433347   ACC = 54.49: Epoch 61 :  Loss = 2.8540963100433347   ACC = 54.49 Class wise = [88.  98.9 77.5 57.6 60.1 42.1 45.9 32.7 33.2  8.9]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 61 :  Loss = 0.2949014549733697   ACC = 89.35441635612851\n",
            "TEST TEST  train_dataset: Epoch 62 :  Loss = 0.4951728130079658   ACC = 85.87974619800585: Epoch 62 :  Loss = 0.4951728130079658   ACC = 85.87974619800585 Class wise = [94.825      86.28023353 72.04450626 69.37354988 94.77756286 90.\n",
            " 86.55913978 54.95495495 22.3880597  62.5       ]\n",
            "TEST TEST  val_dataset: Epoch 62 :  Loss = 2.1691630601882936   ACC = 57.730000000000004: Epoch 62 :  Loss = 2.1691630601882936   ACC = 57.730000000000004 Class wise = [91.9 83.5 60.6 54.3 79.8 69.8 65.8 36.4  7.9 27.3]\n",
            "TEST TEST  test_dataset: Epoch 62 :  Loss = 2.495129155731201   ACC = 57.769999999999996: Epoch 62 :  Loss = 2.495129155731201   ACC = 57.769999999999996 Class wise = [89.3 81.9 59.3 51.4 81.7 71.1 67.9 30.3  9.1 35.7]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 62 :  Loss = 0.32033116198976375   ACC = 88.56883875516165\n",
            "TEST TEST  train_dataset: Epoch 63 :  Loss = 0.2251087776638972   ACC = 92.12408097492195: Epoch 63 :  Loss = 0.2251087776638972   ACC = 92.12408097492195 Class wise = [97.6        98.54045038 89.01251739 66.12529002 88.00773694 88.38709677\n",
            " 79.56989247 81.08108108 44.7761194  82.5       ]\n",
            "TEST TEST  val_dataset: Epoch 63 :  Loss = 1.918929415512085   ACC = 59.79: Epoch 63 :  Loss = 1.918929415512085   ACC = 59.79 Class wise = [93.4 96.4 78.8 51.1 68.4 65.  56.3 52.3 10.2 26. ]\n",
            "TEST TEST  test_dataset: Epoch 63 :  Loss = 2.080387349319458   ACC = 60.0: Epoch 63 :  Loss = 2.080387349319458   ACC = 60.0 Class wise = [93.9 96.9 75.8 47.7 65.4 65.3 56.5 52.2 13.4 32.9]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 63 :  Loss = 0.26269715970971336   ACC = 90.37163863430355\n",
            "TEST TEST  train_dataset: Epoch 64 :  Loss = 0.38174403940806495   ACC = 88.7702689092557: Epoch 64 :  Loss = 0.38174403940806495   ACC = 88.7702689092557 Class wise = [98.225      94.41201001 68.91515994 74.82598608 87.42746615 91.29032258\n",
            " 58.06451613 82.88288288 46.26865672 47.5       ]\n",
            "TEST TEST  val_dataset: Epoch 64 :  Loss = 2.192571612167358   ACC = 57.54: Epoch 64 :  Loss = 2.192571612167358   ACC = 57.54 Class wise = [95.2 92.3 55.3 64.4 68.  71.2 39.7 59.1 13.3 16.9]\n",
            "TEST TEST  test_dataset: Epoch 64 :  Loss = 2.489612236404419   ACC = 57.589999999999996: Epoch 64 :  Loss = 2.489612236404419   ACC = 57.589999999999996 Class wise = [96.  92.4 52.  61.9 69.3 73.5 39.9 59.  15.1 16.8]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 64 :  Loss = 0.2553690076714761   ACC = 90.96585758888106\n",
            "TEST TEST  train_dataset: Epoch 65 :  Loss = 0.18526457474783764   ACC = 93.84630879242623: Epoch 65 :  Loss = 0.18526457474783764   ACC = 93.84630879242623 Class wise = [98.075      97.53961635 92.28094576 88.05104408 89.94197292 75.16129032\n",
            " 81.72043011 68.46846847 46.26865672 32.5       ]\n",
            "TEST TEST  val_dataset: Epoch 65 :  Loss = 2.3458511796951296   ACC = 54.59: Epoch 65 :  Loss = 2.3458511796951296   ACC = 54.59 Class wise = [94.5 94.2 76.7 71.2 64.  40.8 51.9 38.4  7.6  6.6]\n",
            "TEST TEST  test_dataset: Epoch 65 :  Loss = 2.5930383934020997   ACC = 56.31: Epoch 65 :  Loss = 2.5930383934020997   ACC = 56.31 Class wise = [95.2 94.8 80.7 70.4 63.6 42.6 59.1 37.8 11.   7.9]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 65 :  Loss = 0.271251222292262   ACC = 90.46228220364588\n",
            "TEST TEST  train_dataset: Epoch 66 :  Loss = 0.5277339768669063   ACC = 86.0207473058717: Epoch 66 :  Loss = 0.5277339768669063   ACC = 86.0207473058717 Class wise = [88.15       95.57964971 94.43671766 71.80974478 72.53384913 47.74193548\n",
            " 86.02150538 28.82882883 32.8358209  22.5       ]\n",
            "TEST TEST  val_dataset: Epoch 66 :  Loss = 2.8135049423217775   ACC = 51.72: Epoch 66 :  Loss = 2.8135049423217775   ACC = 51.72 Class wise = [84.5 93.8 88.2 57.5 59.4 32.5 66.2 17.8 10.7  6.6]\n",
            "TEST TEST  test_dataset: Epoch 66 :  Loss = 3.2618937397003176   ACC = 51.03: Epoch 66 :  Loss = 3.2618937397003176   ACC = 51.03 Class wise = [84.1 94.7 88.5 52.8 53.1 31.1 70.3 16.5 12.7  6.5]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 66 :  Loss = 0.26825164657835393   ACC = 90.61335481921644\n",
            "TEST TEST  train_dataset: Epoch 67 :  Loss = 0.3743040070143312   ACC = 89.55584651022258: Epoch 67 :  Loss = 0.3743040070143312   ACC = 89.55584651022258 Class wise = [98.875      95.3294412  94.71488178 64.61716937 64.99032882 51.93548387\n",
            " 83.87096774 28.82882883 50.74626866 32.5       ]\n",
            "TEST TEST  val_dataset: Epoch 67 :  Loss = 2.8057994956970216   ACC = 51.27: Epoch 67 :  Loss = 2.8057994956970216   ACC = 51.27 Class wise = [97.7 93.5 86.2 52.2 45.6 33.3 65.6 16.6 17.   5. ]\n",
            "TEST TEST  test_dataset: Epoch 67 :  Loss = 3.273771475982666   ACC = 50.5: Epoch 67 :  Loss = 3.273771475982666   ACC = 50.5 Class wise = [96.8 92.4 86.4 47.  43.  31.  66.2 15.8 19.8  6.6]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 67 :  Loss = 0.24720764484923224   ACC = 91.13707321986101\n",
            "TEST TEST  train_dataset: Epoch 68 :  Loss = 0.24925894455218653   ACC = 92.09386645180784: Epoch 68 :  Loss = 0.24925894455218653   ACC = 92.09386645180784 Class wise = [97.675      97.41451209 95.4798331  72.62180974 82.59187621 65.48387097\n",
            " 67.20430108 54.05405405 83.58208955 77.5       ]\n",
            "TEST TEST  val_dataset: Epoch 68 :  Loss = 2.1829377975463866   ACC = 55.48: Epoch 68 :  Loss = 2.1829377975463866   ACC = 55.48 Class wise = [94.6 94.9 87.9 57.8 58.3 34.9 41.5 28.4 31.1 25.4]\n",
            "TEST TEST  test_dataset: Epoch 68 :  Loss = 2.3841621753692626   ACC = 56.699999999999996: Epoch 68 :  Loss = 2.3841621753692626   ACC = 56.699999999999996 Class wise = [95.3 93.7 85.6 49.1 60.6 37.3 47.3 32.2 32.8 33.1]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 68 :  Loss = 0.24572579479971518   ACC = 91.51979051263974\n",
            "TEST TEST  train_dataset: Epoch 69 :  Loss = 0.29363269350994314   ACC = 90.93564306576695: Epoch 69 :  Loss = 0.29363269350994314   ACC = 90.93564306576695 Class wise = [99.2        97.28940784 93.53268428 67.74941995 73.88781431 67.09677419\n",
            " 46.23655914 64.86486486 53.73134328 37.5       ]\n",
            "TEST TEST  val_dataset: Epoch 69 :  Loss = 2.744003807258606   ACC = 51.2: Epoch 69 :  Loss = 2.744003807258606   ACC = 51.2 Class wise = [98.2 95.4 84.9 51.4 54.6 35.3 26.5 43.  13.2  9.5]\n",
            "TEST TEST  test_dataset: Epoch 69 :  Loss = 3.213005302810669   ACC = 50.160000000000004: Epoch 69 :  Loss = 3.213005302810669   ACC = 50.160000000000004 Class wise = [97.3 94.7 83.5 46.2 53.3 34.6 29.1 39.2 15.5  8.2]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 69 :  Loss = 0.23825597427939227   ACC = 91.7010776513244\n",
            "TEST TEST  train_dataset: Epoch 70 :  Loss = 0.21079951701375313   ACC = 93.21180380702991: Epoch 70 :  Loss = 0.21079951701375313   ACC = 93.21180380702991 Class wise = [96.65       96.87239366 94.71488178 87.70301624 87.04061896 73.87096774\n",
            " 66.66666667 85.58558559 53.73134328 35.        ]\n",
            "TEST TEST  val_dataset: Epoch 70 :  Loss = 2.3270920631408694   ACC = 56.84: Epoch 70 :  Loss = 2.3270920631408694   ACC = 56.84 Class wise = [94.1 94.4 83.3 73.2 58.5 42.1 42.1 62.1 12.2  6.4]\n",
            "TEST TEST  test_dataset: Epoch 70 :  Loss = 2.487296272468567   ACC = 57.230000000000004: Epoch 70 :  Loss = 2.487296272468567   ACC = 57.230000000000004 Class wise = [91.4 94.4 82.3 66.6 62.7 44.5 44.1 63.4 15.1  7.8]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 70 :  Loss = 0.22952247645658289   ACC = 91.76150669755262\n",
            "TEST TEST  train_dataset: Epoch 71 :  Loss = 0.2936536461123888   ACC = 90.8248564810152: Epoch 71 :  Loss = 0.2936536461123888   ACC = 90.8248564810152 Class wise = [98.85       98.79065888 79.2767733  61.13689095 92.45647969 86.77419355\n",
            " 81.72043011 80.18018018 46.26865672 22.5       ]\n",
            "TEST TEST  val_dataset: Epoch 71 :  Loss = 2.541531888580322   ACC = 55.45: Epoch 71 :  Loss = 2.541531888580322   ACC = 55.45 Class wise = [95.6 96.8 64.3 53.  72.7 56.  57.3 47.5  9.1  2.2]\n",
            "TEST TEST  test_dataset: Epoch 71 :  Loss = 2.8476167045593264   ACC = 56.720000000000006: Epoch 71 :  Loss = 2.8476167045593264   ACC = 56.720000000000006 Class wise = [96.8 96.2 62.4 44.7 75.1 66.4 62.2 49.1 11.8  2.5]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 71 :  Loss = 0.23822888486130095   ACC = 91.46943297411623\n",
            "TEST TEST  train_dataset: Epoch 72 :  Loss = 0.30589145706828264   ACC = 90.8047134656058: Epoch 72 :  Loss = 0.30589145706828264   ACC = 90.8047134656058 Class wise = [98.05       98.29024187 79.7635605  66.47331787 97.87234043 89.67741935\n",
            " 44.62365591 87.38738739 46.26865672 55.        ]\n",
            "TEST TEST  val_dataset: Epoch 72 :  Loss = 2.2677339809417725   ACC = 56.34: Epoch 72 :  Loss = 2.2677339809417725   ACC = 56.34 Class wise = [95.5 95.4 66.2 56.9 83.1 63.5 19.6 56.4 12.3 14.5]\n",
            "TEST TEST  test_dataset: Epoch 72 :  Loss = 2.5706019943237304   ACC = 56.32: Epoch 72 :  Loss = 2.5706019943237304   ACC = 56.32 Class wise = [94.7 96.8 63.  47.7 85.1 67.6 26.1 54.3 14.1 13.8]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 72 :  Loss = 0.23099871884601114   ACC = 91.77157820525733\n",
            "TEST TEST  train_dataset: Epoch 73 :  Loss = 0.28908430634600923   ACC = 90.99607211199516: Epoch 73 :  Loss = 0.28908430634600923   ACC = 90.99607211199516 Class wise = [91.5        99.49958299 97.07927677 82.13457077 83.75241779 81.93548387\n",
            " 44.08602151 59.45945946 44.7761194  50.        ]\n",
            "TEST TEST  val_dataset: Epoch 73 :  Loss = 2.731969004058838   ACC = 53.779999999999994: Epoch 73 :  Loss = 2.731969004058838   ACC = 53.779999999999994 Class wise = [87.6 97.8 87.5 66.5 59.4 50.2 27.8 35.8  9.4 15.8]\n",
            "TEST TEST  test_dataset: Epoch 73 :  Loss = 3.114761169433594   ACC = 53.0: Epoch 73 :  Loss = 3.114761169433594   ACC = 53.0 Class wise = [86.4 98.5 87.  62.5 60.2 48.1 30.  32.8 11.  13.5]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 73 :  Loss = 0.2464485379825703   ACC = 91.16728774297512\n",
            "TEST TEST  train_dataset: Epoch 74 :  Loss = 0.26068376123106773   ACC = 92.06365192869373: Epoch 74 :  Loss = 0.26068376123106773   ACC = 92.06365192869373 Class wise = [98.825      99.20767306 94.64534075 64.61716937 68.66537718 76.12903226\n",
            " 82.25806452 80.18018018 46.26865672 67.5       ]\n",
            "TEST TEST  val_dataset: Epoch 74 :  Loss = 2.435995391845703   ACC = 54.96: Epoch 74 :  Loss = 2.435995391845703   ACC = 54.96 Class wise = [96.  97.6 84.5 48.3 43.6 43.  53.8 53.5  9.7 19.6]\n",
            "TEST TEST  test_dataset: Epoch 74 :  Loss = 2.693291386604309   ACC = 55.730000000000004: Epoch 74 :  Loss = 2.693291386604309   ACC = 55.730000000000004 Class wise = [95.4 97.7 82.6 43.2 44.9 48.5 56.7 51.9 13.3 23.1]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 74 :  Loss = 0.2191421473382859   ACC = 92.09386645180784\n",
            "TEST TEST  train_dataset: Epoch 75 :  Loss = 0.1547628882452613   ACC = 94.92396011682949: Epoch 75 :  Loss = 0.1547628882452613   ACC = 94.92396011682949 Class wise = [97.825      98.95746455 95.27121001 81.3225058  87.81431335 85.16129032\n",
            " 86.02150538 88.28828829 86.56716418 85.        ]\n",
            "TEST TEST  val_dataset: Epoch 75 :  Loss = 1.930308533859253   ACC = 61.42999999999999: Epoch 75 :  Loss = 1.930308533859253   ACC = 61.42999999999999 Class wise = [95.  96.8 84.  60.8 65.7 48.2 53.  53.5 29.1 28.2]\n",
            "TEST TEST  test_dataset: Epoch 75 :  Loss = 2.150611316871643   ACC = 60.99: Epoch 75 :  Loss = 2.150611316871643   ACC = 60.99 Class wise = [94.3 97.  82.7 56.9 66.  48.  55.5 52.4 31.2 25.9]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 75 :  Loss = 0.21648024325134746   ACC = 92.30536811360662\n",
            "TEST TEST  train_dataset: Epoch 76 :  Loss = 0.21330752413502657   ACC = 93.4736630073522: Epoch 76 :  Loss = 0.21330752413502657   ACC = 93.4736630073522 Class wise = [97.525      97.83152627 86.85674548 95.93967517 88.20116054 74.83870968\n",
            " 66.12903226 54.05405405 80.59701493 82.5       ]\n",
            "TEST TEST  val_dataset: Epoch 76 :  Loss = 2.5457956619262694   ACC = 56.769999999999996: Epoch 76 :  Loss = 2.5457956619262694   ACC = 56.769999999999996 Class wise = [93.6 94.2 70.5 86.  64.2 42.8 42.7 27.3 25.2 21.2]\n",
            "TEST TEST  test_dataset: Epoch 76 :  Loss = 2.7377042644500733   ACC = 57.4: Epoch 76 :  Loss = 2.7377042644500733   ACC = 57.4 Class wise = [93.9 94.  71.1 81.  65.9 39.2 45.9 29.5 28.1 25.4]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 76 :  Loss = 0.20037334291149042   ACC = 92.8995870681841\n",
            "TEST TEST  train_dataset: Epoch 77 :  Loss = 0.28853534239634415   ACC = 91.41907543559272: Epoch 77 :  Loss = 0.28853534239634415   ACC = 91.41907543559272 Class wise = [99.5        98.29024187 76.9123783  85.15081206 88.58800774 72.25806452\n",
            " 66.12903226 58.55855856 26.86567164 30.        ]\n",
            "TEST TEST  val_dataset: Epoch 77 :  Loss = 2.780875714492798   ACC = 53.42: Epoch 77 :  Loss = 2.780875714492798   ACC = 53.42 Class wise = [98.6 95.8 63.8 70.  68.6 39.7 43.9 36.8  9.2  7.8]\n",
            "TEST TEST  test_dataset: Epoch 77 :  Loss = 3.223160202026367   ACC = 52.769999999999996: Epoch 77 :  Loss = 3.223160202026367   ACC = 52.769999999999996 Class wise = [97.1 96.5 60.3 66.  71.  41.  45.  33.8 10.3  6.7]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 77 :  Loss = 0.23476725546587798   ACC = 91.19750226608923\n",
            "TEST TEST  train_dataset: Epoch 78 :  Loss = 0.18801604031838132   ACC = 93.88659482324503: Epoch 78 :  Loss = 0.18801604031838132   ACC = 93.88659482324503 Class wise = [98.85       96.91409508 93.67176634 87.58700696 86.26692456 72.25806452\n",
            " 73.65591398 82.88288288 49.25373134 25.        ]\n",
            "TEST TEST  val_dataset: Epoch 78 :  Loss = 2.375396389007568   ACC = 56.34: Epoch 78 :  Loss = 2.375396389007568   ACC = 56.34 Class wise = [95.9 94.3 81.7 68.9 62.5 35.3 44.9 51.5 21.1  7.3]\n",
            "TEST TEST  test_dataset: Epoch 78 :  Loss = 2.6721431028366087   ACC = 56.18: Epoch 78 :  Loss = 2.6721431028366087   ACC = 56.18 Class wise = [96.7 94.3 79.1 67.4 62.6 38.4 46.1 50.2 19.8  7.2]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 78 :  Loss = 0.232924504508928   ACC = 91.50971900493504\n",
            "TEST TEST  train_dataset: Epoch 79 :  Loss = 0.2592229657111505   ACC = 91.76150669755262: Epoch 79 :  Loss = 0.2592229657111505   ACC = 91.76150669755262 Class wise = [99.         91.40950792 89.49930459 68.79350348 90.71566731 87.41935484\n",
            " 83.33333333 83.78378378 86.56716418 82.5       ]\n",
            "TEST TEST  val_dataset: Epoch 79 :  Loss = 1.7510247505187988   ACC = 62.2: Epoch 79 :  Loss = 1.7510247505187988   ACC = 62.2 Class wise = [96.3 89.8 75.3 51.1 65.1 56.9 57.2 57.1 41.6 31.6]\n",
            "TEST TEST  test_dataset: Epoch 79 :  Loss = 1.9029104656219482   ACC = 62.46000000000001: Epoch 79 :  Loss = 1.9029104656219482   ACC = 62.46000000000001 Class wise = [96.  87.  76.5 47.4 66.9 61.  56.3 53.3 42.9 37.3]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 79 :  Loss = 0.22061048729630536   ACC = 92.04350891328433\n",
            "TEST TEST  train_dataset: Epoch 80 :  Loss = 0.24278803711355795   ACC = 92.2751535904925: Epoch 80 :  Loss = 0.24278803711355795   ACC = 92.2751535904925 Class wise = [94.775      98.70725605 97.07927677 74.94199536 81.81818182 65.16129032\n",
            " 76.34408602 89.18918919 94.02985075 82.5       ]\n",
            "TEST TEST  val_dataset: Epoch 80 :  Loss = 2.0196786296844484   ACC = 60.38: Epoch 80 :  Loss = 2.0196786296844484   ACC = 60.38 Class wise = [91.9 96.8 86.1 58.5 58.4 35.4 49.3 59.9 45.  22.5]\n",
            "TEST TEST  test_dataset: Epoch 80 :  Loss = 2.2265627948760986   ACC = 61.23: Epoch 80 :  Loss = 2.2265627948760986   ACC = 61.23 Class wise = [90.4 96.6 88.6 53.9 59.1 38.4 49.5 62.7 46.2 26.9]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 80 :  Loss = 0.20859596621583196   ACC = 92.49672675999598\n",
            "TEST TEST  train_dataset: Epoch 81 :  Loss = 0.23096626518548033   ACC = 93.00030214523115: Epoch 81 :  Loss = 0.23096626518548033   ACC = 93.00030214523115 Class wise = [99.575      98.04003336 79.97218359 87.81902552 77.94970986 91.29032258\n",
            " 67.20430108 89.18918919 74.62686567 82.5       ]\n",
            "TEST TEST  val_dataset: Epoch 81 :  Loss = 2.271407199859619   ACC = 57.709999999999994: Epoch 81 :  Loss = 2.271407199859619   ACC = 57.709999999999994 Class wise = [97.  96.1 65.8 70.7 50.5 55.3 34.1 51.5 25.1 31. ]\n",
            "TEST TEST  test_dataset: Epoch 81 :  Loss = 2.472377365684509   ACC = 59.03: Epoch 81 :  Loss = 2.472377365684509   ACC = 59.03 Class wise = [97.1 95.8 64.  68.1 52.4 58.2 37.6 52.7 27.5 36.9]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 81 :  Loss = 0.19360659586715728   ACC = 93.04058817604995\n",
            "TEST TEST  train_dataset: Epoch 82 :  Loss = 0.16934170935260576   ACC = 94.59160036257428: Epoch 82 :  Loss = 0.16934170935260576   ACC = 94.59160036257428 Class wise = [99.275      99.41618015 90.40333797 78.3062645  94.77756286 89.67741935\n",
            " 58.06451613 90.99099099 82.08955224 75.        ]\n",
            "TEST TEST  val_dataset: Epoch 82 :  Loss = 2.1552199850082396   ACC = 58.589999999999996: Epoch 82 :  Loss = 2.1552199850082396   ACC = 58.589999999999996 Class wise = [96.2 97.4 78.3 55.2 74.9 53.2 28.6 56.6 30.3 15.2]\n",
            "TEST TEST  test_dataset: Epoch 82 :  Loss = 2.333091185760498   ACC = 59.41: Epoch 82 :  Loss = 2.333091185760498   ACC = 59.41 Class wise = [95.5 97.7 76.5 52.5 75.5 54.7 30.7 58.7 31.6 20.7]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 82 :  Loss = 0.1898482030480635   ACC = 93.1815892839158\n",
            "TEST TEST  train_dataset: Epoch 83 :  Loss = 0.19615063199716964   ACC = 93.50387753046631: Epoch 83 :  Loss = 0.19615063199716964   ACC = 93.50387753046631 Class wise = [98.05       95.87155963 85.11821975 86.774942   94.19729207 81.93548387\n",
            " 92.47311828 77.47747748 88.05970149 82.5       ]\n",
            "TEST TEST  val_dataset: Epoch 83 :  Loss = 1.8707628929138183   ACC = 62.61: Epoch 83 :  Loss = 1.8707628929138183   ACC = 62.61 Class wise = [95.6 90.9 71.4 64.9 75.4 49.3 76.2 46.1 35.2 21.1]\n",
            "TEST TEST  test_dataset: Epoch 83 :  Loss = 1.9813682037353515   ACC = 63.970000000000006: Epoch 83 :  Loss = 1.9813682037353515   ACC = 63.970000000000006 Class wise = [94.3 92.7 67.8 63.7 75.9 49.6 77.3 45.4 38.7 34.3]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 83 :  Loss = 0.20651185645811243   ACC = 92.72837143720415\n",
            "TEST TEST  train_dataset: Epoch 84 :  Loss = 0.16340827625531879   ACC = 94.72252996273542: Epoch 84 :  Loss = 0.16340827625531879   ACC = 94.72252996273542 Class wise = [99.1        95.74645538 93.74130737 92.22737819 79.30367505 85.48387097\n",
            " 77.41935484 82.88288288 95.52238806 67.5       ]\n",
            "TEST TEST  val_dataset: Epoch 84 :  Loss = 2.1648545249938964   ACC = 58.06: Epoch 84 :  Loss = 2.1648545249938964   ACC = 58.06 Class wise = [97.2 93.1 81.7 68.9 52.8 43.5 46.  45.5 35.6 16.3]\n",
            "TEST TEST  test_dataset: Epoch 84 :  Loss = 2.3595595001220704   ACC = 59.699999999999996: Epoch 84 :  Loss = 2.3595595001220704   ACC = 59.699999999999996 Class wise = [97.1 92.1 81.3 69.  56.6 46.1 48.8 44.1 37.5 24.4]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 84 :  Loss = 0.29055537061006215   ACC = 90.2104945110283\n",
            "TEST TEST  train_dataset: Epoch 85 :  Loss = 0.22794658881439064   ACC = 92.77872897572766: Epoch 85 :  Loss = 0.22794658881439064   ACC = 92.77872897572766 Class wise = [93.775      98.91576314 89.63838665 83.99071926 98.25918762 80.64516129\n",
            " 91.39784946 87.38738739 61.19402985 25.        ]\n",
            "TEST TEST  val_dataset: Epoch 85 :  Loss = 2.209139651107788   ACC = 59.24: Epoch 85 :  Loss = 2.209139651107788   ACC = 59.24 Class wise = [88.3 97.3 79.7 63.9 78.9 50.4 71.5 45.  11.9  5.5]\n",
            "TEST TEST  test_dataset: Epoch 85 :  Loss = 2.3468104934692384   ACC = 59.14: Epoch 85 :  Loss = 2.3468104934692384   ACC = 59.14 Class wise = [89.2 97.6 77.  58.7 78.3 49.2 71.8 46.3 17.4  5.9]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 85 :  Loss = 0.18554324117722812   ACC = 93.40316245341927\n",
            "TEST TEST  train_dataset: Epoch 86 :  Loss = 0.186335765801596   ACC = 94.31966965454728: Epoch 86 :  Loss = 0.186335765801596   ACC = 94.31966965454728 Class wise = [98.6        98.74895746 87.27399166 95.70765661 95.74468085 65.80645161\n",
            " 62.90322581 80.18018018 74.62686567 45.        ]\n",
            "TEST TEST  val_dataset: Epoch 86 :  Loss = 2.5891412033081056   ACC = 56.04: Epoch 86 :  Loss = 2.5891412033081056   ACC = 56.04 Class wise = [95.3 97.2 73.3 77.8 70.4 32.4 41.  43.6 22.3  7.1]\n",
            "TEST TEST  test_dataset: Epoch 86 :  Loss = 2.952944382858276   ACC = 56.52: Epoch 86 :  Loss = 2.952944382858276   ACC = 56.52 Class wise = [94.5 96.9 69.2 78.4 72.7 34.1 39.6 46.2 25.   8.6]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 86 :  Loss = 0.1921678192366501   ACC = 92.94994460670762\n",
            "TEST TEST  train_dataset: Epoch 87 :  Loss = 0.19415514745018564   ACC = 93.60459260751335: Epoch 87 :  Loss = 0.19415514745018564   ACC = 93.60459260751335 Class wise = [98.125      98.66555463 94.08901252 72.62180974 82.01160542 91.61290323\n",
            " 71.50537634 85.58558559 89.55223881 70.        ]\n",
            "TEST TEST  val_dataset: Epoch 87 :  Loss = 2.1644728420257566   ACC = 59.17: Epoch 87 :  Loss = 2.1644728420257566   ACC = 59.17 Class wise = [93.8 95.4 83.  56.  54.9 66.9 42.5 52.2 31.4 15.6]\n",
            "TEST TEST  test_dataset: Epoch 87 :  Loss = 2.3953334922790526   ACC = 59.25: Epoch 87 :  Loss = 2.3953334922790526   ACC = 59.25 Class wise = [94.2 96.7 82.5 49.6 56.6 65.9 43.4 53.4 34.2 16. ]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 87 :  Loss = 0.21589076694602727   ACC = 92.2650820827878\n",
            "TEST TEST  train_dataset: Epoch 88 :  Loss = 0.21870442198679302   ACC = 93.06073119145935: Epoch 88 :  Loss = 0.21870442198679302   ACC = 93.06073119145935 Class wise = [95.2        98.3736447  95.68845619 90.60324826 90.13539652 60.32258065\n",
            " 76.34408602 72.97297297 40.29850746 32.5       ]\n",
            "TEST TEST  val_dataset: Epoch 88 :  Loss = 2.87560269241333   ACC = 54.49: Epoch 88 :  Loss = 2.87560269241333   ACC = 54.49 Class wise = [91.8 96.  84.1 69.9 65.3 30.9 50.7 44.4  4.8  7. ]\n",
            "TEST TEST  test_dataset: Epoch 88 :  Loss = 3.3352123752593994   ACC = 54.190000000000005: Epoch 88 :  Loss = 3.3352123752593994   ACC = 54.190000000000005 Class wise = [90.8 94.9 85.4 66.4 67.2 30.6 49.5 44.7  6.1  6.3]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 88 :  Loss = 0.1832109533692309   ACC = 93.1916607916205\n",
            "TEST TEST  train_dataset: Epoch 89 :  Loss = 0.21878141587997255   ACC = 93.32259039178165: Epoch 89 :  Loss = 0.21878141587997255   ACC = 93.32259039178165 Class wise = [99.175      95.24603837 88.10848401 87.9350348  87.42746615 68.70967742\n",
            " 76.88172043 78.37837838 98.50746269 72.5       ]\n",
            "TEST TEST  val_dataset: Epoch 89 :  Loss = 2.1372174350738526   ACC = 60.34: Epoch 89 :  Loss = 2.1372174350738526   ACC = 60.34 Class wise = [97.8 92.6 76.8 68.8 59.6 38.5 46.  46.3 54.2 22.8]\n",
            "TEST TEST  test_dataset: Epoch 89 :  Loss = 2.406945248031616   ACC = 60.0: Epoch 89 :  Loss = 2.406945248031616   ACC = 60.0 Class wise = [96.7 91.9 71.7 64.8 62.  36.7 47.6 46.7 57.1 24.8]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 89 :  Loss = 0.19196521798695595   ACC = 93.24201833014402\n",
            "TEST TEST  train_dataset: Epoch 90 :  Loss = 0.20944190294943207   ACC = 93.29237586866755: Epoch 90 :  Loss = 0.20944190294943207   ACC = 93.29237586866755 Class wise = [96.45       99.83319433 97.00973574 80.62645012 59.38104449 95.16129032\n",
            " 80.10752688 77.47747748 86.56716418 65.        ]\n",
            "TEST TEST  val_dataset: Epoch 90 :  Loss = 2.357108743286133   ACC = 56.330000000000005: Epoch 90 :  Loss = 2.357108743286133   ACC = 56.330000000000005 Class wise = [92.  97.8 86.4 61.8 35.6 58.7 47.  42.8 27.4 13.8]\n",
            "TEST TEST  test_dataset: Epoch 90 :  Loss = 2.511641819190979   ACC = 57.3: Epoch 90 :  Loss = 2.511641819190979   ACC = 57.3 Class wise = [89.7 98.  85.3 56.5 34.1 65.3 47.5 44.5 35.5 16.6]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 90 :  Loss = 0.17348525345007307   ACC = 93.89666633094974\n",
            "dy tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
            "       grad_fn=<MvBackward>)\n",
            "ly tensor([0.0000, 0.1111, 0.2222, 0.3333, 0.4444, 0.5556, 0.6667, 0.7778, 0.8889,\n",
            "        1.0000], device='cuda:0', grad_fn=<MvBackward>)\n",
            "TEST TEST  train_dataset: Epoch 91 :  Loss = 0.1848029528615734   ACC = 94.26931211602377: Epoch 91 :  Loss = 0.1848029528615734   ACC = 94.26931211602377 Class wise = [97.875      98.95746455 89.56884562 84.80278422 82.78529981 97.41935484\n",
            " 74.19354839 84.68468468 85.07462687 85.        ]\n",
            "TEST TEST  val_dataset: Epoch 91 :  Loss = 2.369764457321167   ACC = 59.48: Epoch 91 :  Loss = 2.369764457321167   ACC = 59.48 Class wise = [95.9 97.2 74.5 64.  52.5 68.6 42.6 44.9 26.  28.6]\n",
            "TEST TEST  test_dataset: Epoch 91 :  Loss = 2.701962208366394   ACC = 59.330000000000005: Epoch 91 :  Loss = 2.701962208366394   ACC = 59.330000000000005 Class wise = [94.  97.9 73.5 61.9 57.6 67.5 45.6 45.4 23.3 26.6]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 91 :  Loss = 0.18341137844833175   ACC = 93.35280491489576\n",
            "TEST TEST  train_dataset: Epoch 92 :  Loss = 0.21439623704386665   ACC = 93.31251888407695: Epoch 92 :  Loss = 0.21439623704386665   ACC = 93.31251888407695 Class wise = [97.875      98.8323603  90.40333797 71.22969838 91.10251451 91.29032258\n",
            " 72.58064516 93.69369369 73.13432836 60.        ]\n",
            "TEST TEST  val_dataset: Epoch 92 :  Loss = 2.1965226699829103   ACC = 61.41: Epoch 92 :  Loss = 2.1965226699829103   ACC = 61.41 Class wise = [95.6 95.8 76.  49.9 69.6 60.7 57.1 71.3 21.2 16.9]\n",
            "TEST TEST  test_dataset: Epoch 92 :  Loss = 2.5644046031951904   ACC = 60.22: Epoch 92 :  Loss = 2.5644046031951904   ACC = 60.22 Class wise = [93.5 96.7 75.8 45.4 71.1 61.  51.4 66.6 24.4 16.3]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 92 :  Loss = 0.16476831834897232   ACC = 94.0779534696344\n",
            "TEST TEST  train_dataset: Epoch 93 :  Loss = 0.15388900788964455   ACC = 95.32682042501762: Epoch 93 :  Loss = 0.15388900788964455   ACC = 95.32682042501762 Class wise = [99.2        99.16597164 91.86369958 81.3225058  92.84332689 91.93548387\n",
            " 83.87096774 89.18918919 68.65671642 77.5       ]\n",
            "TEST TEST  val_dataset: Epoch 93 :  Loss = 2.456554156112671   ACC = 58.3: Epoch 93 :  Loss = 2.456554156112671   ACC = 58.3 Class wise = [95.7 97.7 75.1 59.4 67.5 49.4 47.9 51.5 24.8 14. ]\n",
            "TEST TEST  test_dataset: Epoch 93 :  Loss = 2.840739557647705   ACC = 57.47: Epoch 93 :  Loss = 2.840739557647705   ACC = 57.47 Class wise = [95.4 98.  73.  52.1 67.  55.8 47.9 48.3 23.7 13.5]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 93 :  Loss = 0.18012524687856066   ACC = 93.61466411521805\n",
            "TEST TEST  train_dataset: Epoch 94 :  Loss = 0.22122755487773915   ACC = 93.40316245341927: Epoch 94 :  Loss = 0.22122755487773915   ACC = 93.40316245341927 Class wise = [96.125      99.87489575 95.96662031 80.62645012 88.39458414 78.06451613\n",
            " 64.51612903 81.98198198 40.29850746 55.        ]\n",
            "TEST TEST  val_dataset: Epoch 94 :  Loss = 2.959428558921814   ACC = 55.45: Epoch 94 :  Loss = 2.959428558921814   ACC = 55.45 Class wise = [91.  98.6 82.7 63.2 62.  41.9 39.  53.2  6.3 16.6]\n",
            "TEST TEST  test_dataset: Epoch 94 :  Loss = 3.4441293647766114   ACC = 54.72: Epoch 94 :  Loss = 3.4441293647766114   ACC = 54.72 Class wise = [91.  99.  83.5 54.  63.6 42.5 41.1 52.6  6.6 13.3]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 94 :  Loss = 0.17573916786014043   ACC = 93.45351999194278\n",
            "TEST TEST  train_dataset: Epoch 95 :  Loss = 0.24431969624761968   ACC = 93.25208983784873: Epoch 95 :  Loss = 0.24431969624761968   ACC = 93.25208983784873 Class wise = [98.375      98.74895746 83.51877608 93.387471   72.34042553 94.19354839\n",
            " 80.10752688 59.45945946 68.65671642 57.5       ]\n",
            "TEST TEST  val_dataset: Epoch 95 :  Loss = 2.80702264175415   ACC = 56.75: Epoch 95 :  Loss = 2.80702264175415   ACC = 56.75 Class wise = [95.3 95.9 69.9 77.3 48.4 59.2 57.9 36.1 15.2 12.3]\n",
            "TEST TEST  test_dataset: Epoch 95 :  Loss = 3.302981588745117   ACC = 55.66: Epoch 95 :  Loss = 3.302981588745117   ACC = 55.66 Class wise = [93.6 96.9 64.9 76.3 49.6 59.2 54.1 32.6 16.7 12.7]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 95 :  Loss = 0.20056991061513332   ACC = 92.8593010373653\n",
            "TEST TEST  train_dataset: Epoch 96 :  Loss = 0.22865453120971996   ACC = 93.04058817604995: Epoch 96 :  Loss = 0.22865453120971996   ACC = 93.04058817604995 Class wise = [98.8        99.24937448 91.44645341 67.86542923 75.0483559  98.70967742\n",
            " 72.04301075 81.98198198 91.04477612 65.        ]\n",
            "TEST TEST  val_dataset: Epoch 96 :  Loss = 2.2504156593322753   ACC = 59.589999999999996: Epoch 96 :  Loss = 2.2504156593322753   ACC = 59.589999999999996 Class wise = [96.6 96.4 76.1 51.2 47.5 75.7 41.9 54.7 43.8 12. ]\n",
            "TEST TEST  test_dataset: Epoch 96 :  Loss = 2.5098385011672972   ACC = 59.53000000000001: Epoch 96 :  Loss = 2.5098385011672972   ACC = 59.53000000000001 Class wise = [95.9 97.1 73.  48.1 47.1 78.3 43.6 52.2 43.6 16.4]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 96 :  Loss = 0.17917141282602864   ACC = 93.4333769765334\n",
            "TEST TEST  train_dataset: Epoch 97 :  Loss = 0.1394594886412144   ACC = 95.2764628864941: Epoch 97 :  Loss = 0.1394594886412144   ACC = 95.2764628864941 Class wise = [98.175      98.04003336 93.46314325 88.97911833 93.23017408 90.64516129\n",
            " 84.94623656 74.77477477 64.17910448 60.        ]\n",
            "TEST TEST  val_dataset: Epoch 97 :  Loss = 2.2897405723571778   ACC = 59.34: Epoch 97 :  Loss = 2.2897405723571778   ACC = 59.34 Class wise = [93.3 96.2 79.8 69.1 68.4 52.7 55.7 47.7 18.5 12. ]\n",
            "TEST TEST  test_dataset: Epoch 97 :  Loss = 2.689707440185547   ACC = 58.93000000000001: Epoch 97 :  Loss = 2.689707440185547   ACC = 58.93000000000001 Class wise = [93.3 96.  78.9 64.9 68.7 56.1 53.8 45.6 20.7 11.3]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 97 :  Loss = 0.21896318272048823   ACC = 92.46651223688185\n",
            "TEST TEST  train_dataset: Epoch 98 :  Loss = 0.1759024791015048   ACC = 94.3901702084802: Epoch 98 :  Loss = 0.1759024791015048   ACC = 94.3901702084802 Class wise = [96.475      99.58298582 82.33657858 92.80742459 96.51837524 90.64516129\n",
            " 95.69892473 86.48648649 80.59701493 82.5       ]\n",
            "TEST TEST  val_dataset: Epoch 98 :  Loss = 1.998537498474121   ACC = 62.96000000000001: Epoch 98 :  Loss = 1.998537498474121   ACC = 62.96000000000001 Class wise = [92.5 97.5 69.3 72.9 74.5 52.  70.5 53.8 26.  20.6]\n",
            "TEST TEST  test_dataset: Epoch 98 :  Loss = 2.2735501182556153   ACC = 62.36000000000001: Epoch 98 :  Loss = 2.2735501182556153   ACC = 62.36000000000001 Class wise = [92.3 98.2 63.4 70.5 72.5 54.2 71.8 53.7 24.9 22.1]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 98 :  Loss = 0.15277279777005306   ACC = 94.58152885486957\n",
            "TEST TEST  train_dataset: Epoch 99 :  Loss = 0.14682808690266835   ACC = 95.5383220868164: Epoch 99 :  Loss = 0.14682808690266835   ACC = 95.5383220868164 Class wise = [99.65       98.1234362  91.37691238 94.31554524 88.39458414 79.03225806\n",
            " 86.02150538 80.18018018 58.20895522 75.        ]\n",
            "TEST TEST  val_dataset: Epoch 99 :  Loss = 2.931107231712341   ACC = 55.279999999999994: Epoch 99 :  Loss = 2.931107231712341   ACC = 55.279999999999994 Class wise = [98.1 94.5 72.9 76.8 57.2 39.3 43.2 40.1 13.8 16.9]\n",
            "TEST TEST  test_dataset: Epoch 99 :  Loss = 3.286131983947754   ACC = 55.589999999999996: Epoch 99 :  Loss = 3.286131983947754   ACC = 55.589999999999996 Class wise = [97.4 94.6 73.6 73.1 56.7 42.1 47.6 38.7 12.5 19.6]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 99 :  Loss = 0.1716894611876853   ACC = 94.12831100815792\n",
            "TEST TEST  train_dataset: Epoch 100 :  Loss = 0.2785608705790913   ACC = 92.67801389868063: Epoch 100 :  Loss = 0.2785608705790913   ACC = 92.67801389868063 Class wise = [97.875      98.3736447  92.69819193 66.58932715 96.13152805 65.80645161\n",
            " 64.51612903 97.2972973  89.55223881 80.        ]\n",
            "TEST TEST  val_dataset: Epoch 100 :  Loss = 2.2958888637542723   ACC = 60.22: Epoch 100 :  Loss = 2.2958888637542723   ACC = 60.22 Class wise = [93.3 95.5 80.1 52.5 76.8 36.8 37.5 70.9 30.5 28.3]\n",
            "TEST TEST  test_dataset: Epoch 100 :  Loss = 2.6206455150604246   ACC = 59.98: Epoch 100 :  Loss = 2.6206455150604246   ACC = 59.98 Class wise = [93.2 95.2 80.  43.  77.1 35.8 38.7 70.2 31.  35.6]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 100 :  Loss = 0.16487047703247654   ACC = 94.00745291570148\n",
            "TEST TEST  train_dataset: Epoch 101 :  Loss = 0.2994140228640218   ACC = 91.29821734313627: Epoch 101 :  Loss = 0.2994140228640218   ACC = 91.29821734313627 Class wise = [99.65       86.57214345 90.82058414 82.83062645 93.23017408 69.67741935\n",
            " 70.43010753 74.77477477 61.19402985 75.        ]\n",
            "TEST TEST  val_dataset: Epoch 101 :  Loss = 2.5963277252197265   ACC = 54.910000000000004: Epoch 101 :  Loss = 2.5963277252197265   ACC = 54.910000000000004 Class wise = [98.5 86.2 77.5 60.5 77.2 37.2 36.5 37.8 19.  18.7]\n",
            "TEST TEST  test_dataset: Epoch 101 :  Loss = 3.074681678771973   ACC = 53.959999999999994: Epoch 101 :  Loss = 3.074681678771973   ACC = 53.959999999999994 Class wise = [98.4 82.8 76.2 51.5 73.5 39.4 39.2 36.8 15.4 26.4]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 101 :  Loss = 0.2190238767333448   ACC = 92.2852250981972\n",
            "TEST TEST  train_dataset: Epoch 102 :  Loss = 0.4037737273079761   ACC = 91.18743075838454: Epoch 102 :  Loss = 0.4037737273079761   ACC = 91.18743075838454 Class wise = [98.85       96.74728941 81.01529903 96.86774942 76.78916828 30.32258065\n",
            " 81.1827957  63.06306306 79.10447761 37.5       ]\n",
            "TEST TEST  val_dataset: Epoch 102 :  Loss = 3.2295527439117433   ACC = 54.690000000000005: Epoch 102 :  Loss = 3.2295527439117433   ACC = 54.690000000000005 Class wise = [96.9 94.4 66.5 84.9 56.6 16.3 54.4 42.  27.9  7. ]\n",
            "TEST TEST  test_dataset: Epoch 102 :  Loss = 3.871651811218262   ACC = 53.5: Epoch 102 :  Loss = 3.871651811218262   ACC = 53.5 Class wise = [95.5 94.2 61.7 82.2 53.7 15.7 59.9 37.8 27.1  7.2]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 102 :  Loss = 0.199523705144188   ACC = 92.74851445261355\n",
            "TEST TEST  train_dataset: Epoch 103 :  Loss = 0.11286923888951063   ACC = 96.31382818007856: Epoch 103 :  Loss = 0.11286923888951063   ACC = 96.31382818007856 Class wise = [98.575      99.70809008 95.41029207 91.29930394 95.16441006 86.4516129\n",
            " 72.58064516 89.18918919 62.68656716 85.        ]\n",
            "TEST TEST  val_dataset: Epoch 103 :  Loss = 2.368652035522461   ACC = 58.89: Epoch 103 :  Loss = 2.368652035522461   ACC = 58.89 Class wise = [95.5 98.1 79.9 69.  71.5 50.  44.3 47.6  8.9 24.1]\n",
            "TEST TEST  test_dataset: Epoch 103 :  Loss = 2.6689441370010374   ACC = 58.32000000000001: Epoch 103 :  Loss = 2.6689441370010374   ACC = 58.32000000000001 Class wise = [94.5 98.6 80.  63.  72.3 47.4 44.5 47.3 10.9 24.7]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 103 :  Loss = 0.1532481052097759   ACC = 94.46067076241313\n",
            "TEST TEST  train_dataset: Epoch 104 :  Loss = 0.2224015173012546   ACC = 93.57437808439923: Epoch 104 :  Loss = 0.2224015173012546   ACC = 93.57437808439923 Class wise = [97.7        97.58131776 87.20445063 96.51972158 82.9787234  82.25806452\n",
            " 76.34408602 66.66666667 62.68656716 37.5       ]\n",
            "TEST TEST  val_dataset: Epoch 104 :  Loss = 2.926629421615601   ACC = 55.47: Epoch 104 :  Loss = 2.926629421615601   ACC = 55.47 Class wise = [95.  94.9 73.2 80.8 54.  47.6 47.8 36.4 17.4  7.6]\n",
            "TEST TEST  test_dataset: Epoch 104 :  Loss = 3.4477665393829344   ACC = 54.82: Epoch 104 :  Loss = 3.4477665393829344   ACC = 54.82 Class wise = [93.4 95.1 71.8 78.5 55.5 45.8 51.6 31.2 17.8  7.5]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 104 :  Loss = 0.1760490485352114   ACC = 93.71537919226508\n",
            "TEST TEST  train_dataset: Epoch 105 :  Loss = 0.18429950115267443   ACC = 94.31966965454728: Epoch 105 :  Loss = 0.18429950115267443   ACC = 94.31966965454728 Class wise = [98.725      96.4970809  84.56189152 92.22737819 97.29206963 89.03225806\n",
            " 67.20430108 94.59459459 68.65671642 90.        ]\n",
            "TEST TEST  val_dataset: Epoch 105 :  Loss = 2.260099253463745   ACC = 60.209999999999994: Epoch 105 :  Loss = 2.260099253463745   ACC = 60.209999999999994 Class wise = [95.5 93.9 69.  73.  77.7 46.3 42.3 63.  12.8 28.6]\n",
            "TEST TEST  test_dataset: Epoch 105 :  Loss = 2.637481753540039   ACC = 59.46: Epoch 105 :  Loss = 2.637481753540039   ACC = 59.46 Class wise = [96.2 92.9 64.8 66.7 80.3 46.2 39.2 60.8 14.  33.5]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 105 :  Loss = 0.14685984312293393   ACC = 94.87360257830598\n",
            "TEST TEST  train_dataset: Epoch 106 :  Loss = 0.1681888802895323   ACC = 94.80310202437306: Epoch 106 :  Loss = 0.1681888802895323   ACC = 94.80310202437306 Class wise = [96.875      99.58298582 95.41029207 87.3549884  84.91295938 83.5483871\n",
            " 88.17204301 76.57657658 77.6119403  65.        ]\n",
            "TEST TEST  val_dataset: Epoch 106 :  Loss = 2.326070631790161   ACC = 59.45: Epoch 106 :  Loss = 2.326070631790161   ACC = 59.45 Class wise = [93.7 97.9 80.3 64.9 58.4 49.8 56.5 45.4 28.5 19.1]\n",
            "TEST TEST  test_dataset: Epoch 106 :  Loss = 2.7463176345825193   ACC = 59.830000000000005: Epoch 106 :  Loss = 2.7463176345825193   ACC = 59.830000000000005 Class wise = [93.1 98.6 79.7 62.3 59.8 51.3 59.8 43.6 28.1 22. ]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 106 :  Loss = 0.16448633940225402   ACC = 93.90673783865444\n",
            "TEST TEST  train_dataset: Epoch 107 :  Loss = 0.16929638563163907   ACC = 94.56138583946017: Epoch 107 :  Loss = 0.16929638563163907   ACC = 94.56138583946017 Class wise = [99.175      99.41618015 91.37691238 76.10208817 87.62088975 86.77419355\n",
            " 90.32258065 85.58558559 85.07462687 65.        ]\n",
            "TEST TEST  val_dataset: Epoch 107 :  Loss = 2.4269312950134276   ACC = 58.64: Epoch 107 :  Loss = 2.4269312950134276   ACC = 58.64 Class wise = [96.5 97.6 78.7 50.1 61.9 53.1 58.  51.4 28.  11.1]\n",
            "TEST TEST  test_dataset: Epoch 107 :  Loss = 2.812195315074921   ACC = 58.39: Epoch 107 :  Loss = 2.812195315074921   ACC = 58.39 Class wise = [96.2 97.4 73.7 46.4 61.  53.2 62.3 50.2 31.1 12.4]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 107 :  Loss = 0.17493314715247701   ACC = 93.64487863833216\n",
            "TEST TEST  train_dataset: Epoch 108 :  Loss = 0.15858804015297343   ACC = 95.04481820928594: Epoch 108 :  Loss = 0.15858804015297343   ACC = 95.04481820928594 Class wise = [98.8        98.1234362  87.6216968  92.11136891 91.6827853  79.35483871\n",
            " 89.78494624 83.78378378 92.53731343 90.        ]\n",
            "TEST TEST  val_dataset: Epoch 108 :  Loss = 2.135946141242981   ACC = 62.67: Epoch 108 :  Loss = 2.135946141242981   ACC = 62.67 Class wise = [96.3 94.7 72.9 74.3 72.2 41.8 68.2 48.7 28.4 29.2]\n",
            "TEST TEST  test_dataset: Epoch 108 :  Loss = 2.452623267364502   ACC = 62.580000000000005: Epoch 108 :  Loss = 2.452623267364502   ACC = 62.580000000000005 Class wise = [95.2 95.  68.7 71.5 71.5 40.8 71.6 50.2 28.8 32.5]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 108 :  Loss = 0.17752936215592313   ACC = 93.84630879242623\n",
            "TEST TEST  train_dataset: Epoch 109 :  Loss = 0.16741875061960976   ACC = 94.77288750125894: Epoch 109 :  Loss = 0.16741875061960976   ACC = 94.77288750125894 Class wise = [99.6        98.79065888 91.37691238 91.53132251 89.36170213 65.48387097\n",
            " 62.3655914  93.69369369 68.65671642 57.5       ]\n",
            "TEST TEST  val_dataset: Epoch 109 :  Loss = 2.777575079727173   ACC = 54.96: Epoch 109 :  Loss = 2.777575079727173   ACC = 54.96 Class wise = [97.7 96.2 76.4 71.9 62.7 26.3 34.5 54.7 18.5 10.7]\n",
            "TEST TEST  test_dataset: Epoch 109 :  Loss = 3.239226361465454   ACC = 54.48: Epoch 109 :  Loss = 3.239226361465454   ACC = 54.48 Class wise = [97.5 96.1 73.5 67.7 64.4 27.3 38.2 51.8 17.2 11.1]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 109 :  Loss = 0.18035780453786399   ACC = 93.50387753046631\n",
            "TEST TEST  train_dataset: Epoch 110 :  Loss = 0.16826217505855376   ACC = 94.68224393191662: Epoch 110 :  Loss = 0.16826217505855376   ACC = 94.68224393191662 Class wise = [97.85       98.20683903 95.34075104 89.55916473 79.49709865 98.06451613\n",
            " 61.82795699 83.78378378 47.76119403 85.        ]\n",
            "TEST TEST  val_dataset: Epoch 110 :  Loss = 2.607591603088379   ACC = 57.07: Epoch 110 :  Loss = 2.607591603088379   ACC = 57.07 Class wise = [94.  96.8 81.1 68.4 50.5 65.  33.8 49.5  8.9 22.7]\n",
            "TEST TEST  test_dataset: Epoch 110 :  Loss = 2.94074620475769   ACC = 57.37: Epoch 110 :  Loss = 2.94074620475769   ACC = 57.37 Class wise = [92.7 95.7 81.7 63.6 50.2 65.7 35.3 50.2  9.6 29. ]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 110 :  Loss = 0.1410566235679834   ACC = 95.02467519387653\n",
            "TEST TEST  train_dataset: Epoch 111 :  Loss = 0.19622959175106502   ACC = 94.52109980864135: Epoch 111 :  Loss = 0.19622959175106502   ACC = 94.52109980864135 Class wise = [97.425      99.66638866 89.98609179 95.70765661 94.58413926 72.25806452\n",
            " 43.5483871  78.37837838 95.52238806 85.        ]\n",
            "TEST TEST  val_dataset: Epoch 111 :  Loss = 2.473005084228516   ACC = 58.45: Epoch 111 :  Loss = 2.473005084228516   ACC = 58.45 Class wise = [92.7 98.4 76.5 77.1 72.4 36.6 25.9 36.8 43.4 24.7]\n",
            "TEST TEST  test_dataset: Epoch 111 :  Loss = 2.940959394264221   ACC = 58.14: Epoch 111 :  Loss = 2.940959394264221   ACC = 58.14 Class wise = [91.2 98.4 74.7 75.2 70.6 35.8 25.9 35.  45.2 29.4]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 111 :  Loss = 0.1457166305144444   ACC = 94.55131433175546\n",
            "TEST TEST  train_dataset: Epoch 112 :  Loss = 0.15318061597926677   ACC = 95.2563198710847: Epoch 112 :  Loss = 0.15318061597926677   ACC = 95.2563198710847 Class wise = [96.375      99.70809008 93.60222531 87.47099768 95.74468085 86.12903226\n",
            " 83.87096774 97.2972973  79.10447761 82.5       ]\n",
            "TEST TEST  val_dataset: Epoch 112 :  Loss = 2.4295999576568605   ACC = 61.11: Epoch 112 :  Loss = 2.4295999576568605   ACC = 61.11 Class wise = [90.5 97.4 81.5 67.6 76.6 49.4 56.3 57.8 19.  15. ]\n",
            "TEST TEST  test_dataset: Epoch 112 :  Loss = 2.773704294204712   ACC = 60.61: Epoch 112 :  Loss = 2.773704294204712   ACC = 60.61 Class wise = [89.5 98.  79.4 60.1 76.7 49.9 59.6 59.4 17.2 16.3]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 112 :  Loss = 0.16563477140396116   ACC = 94.0779534696344\n",
            "TEST TEST  train_dataset: Epoch 113 :  Loss = 0.2356491587123358   ACC = 93.00030214523115: Epoch 113 :  Loss = 0.2356491587123358   ACC = 93.00030214523115 Class wise = [98.9        97.03919933 77.67732962 99.4199536  90.90909091 75.16129032\n",
            " 59.67741935 69.36936937 82.08955224 77.5       ]\n",
            "TEST TEST  val_dataset: Epoch 113 :  Loss = 2.8431188549041746   ACC = 54.75: Epoch 113 :  Loss = 2.8431188549041746   ACC = 54.75 Class wise = [96.5 93.3 61.4 88.6 66.3 38.2 35.5 35.2 16.4 16.1]\n",
            "TEST TEST  test_dataset: Epoch 113 :  Loss = 3.2317850593566892   ACC = 54.85: Epoch 113 :  Loss = 3.2317850593566892   ACC = 54.85 Class wise = [95.4 93.5 58.1 87.3 68.3 34.4 38.9 32.2 18.  22.4]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 113 :  Loss = 0.14524216343628002   ACC = 94.71245845503073\n",
            "TEST TEST  train_dataset: Epoch 114 :  Loss = 0.2585695798172369   ACC = 93.4736630073522: Epoch 114 :  Loss = 0.2585695798172369   ACC = 93.4736630073522 Class wise = [97.55       99.62468724 88.73435327 81.43851508 96.51837524 63.87096774\n",
            " 80.64516129 91.89189189 52.23880597 70.        ]\n",
            "TEST TEST  val_dataset: Epoch 114 :  Loss = 2.962480042266846   ACC = 56.02: Epoch 114 :  Loss = 2.962480042266846   ACC = 56.02 Class wise = [94.2 97.4 75.2 63.1 75.6 27.7 51.5 51.4  9.  15.1]\n",
            "TEST TEST  test_dataset: Epoch 114 :  Loss = 3.395039316558838   ACC = 55.82: Epoch 114 :  Loss = 3.395039316558838   ACC = 55.82 Class wise = [95.  97.9 73.5 57.1 78.6 27.3 51.1 52.  10.6 15.1]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 114 :  Loss = 0.15748719886201953   ACC = 94.3498841776614\n",
            "TEST TEST  train_dataset: Epoch 115 :  Loss = 0.2799011277921647   ACC = 92.6075133447477: Epoch 115 :  Loss = 0.2799011277921647   ACC = 92.6075133447477 Class wise = [99.325      94.1618015  95.75799722 69.48955916 86.65377176 70.64516129\n",
            " 90.86021505 57.65765766 89.55223881 70.        ]\n",
            "TEST TEST  val_dataset: Epoch 115 :  Loss = 2.720097093963623   ACC = 56.330000000000005: Epoch 115 :  Loss = 2.720097093963623   ACC = 56.330000000000005 Class wise = [97.8 90.7 82.3 45.8 58.3 41.6 63.8 26.5 36.9 19.6]\n",
            "TEST TEST  test_dataset: Epoch 115 :  Loss = 3.20948548412323   ACC = 55.97: Epoch 115 :  Loss = 3.20948548412323   ACC = 55.97 Class wise = [97.6 90.5 82.  41.8 59.2 38.8 65.3 26.6 38.6 19.3]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 115 :  Loss = 0.17732506350203575   ACC = 93.65495014603687\n",
            "TEST TEST  train_dataset: Epoch 116 :  Loss = 0.12080292980219377   ACC = 96.20304159532682: Epoch 116 :  Loss = 0.12080292980219377   ACC = 96.20304159532682 Class wise = [99.625      99.16597164 95.20166898 96.63573086 78.52998066 67.74193548\n",
            " 96.23655914 91.89189189 86.56716418 80.        ]\n",
            "TEST TEST  val_dataset: Epoch 116 :  Loss = 2.44151632232666   ACC = 59.06: Epoch 116 :  Loss = 2.44151632232666   ACC = 59.06 Class wise = [97.6 96.9 78.9 77.8 47.3 32.1 58.1 56.9 23.9 21.1]\n",
            "TEST TEST  test_dataset: Epoch 116 :  Loss = 2.680850233078003   ACC = 60.089999999999996: Epoch 116 :  Loss = 2.680850233078003   ACC = 60.089999999999996 Class wise = [96.6 96.2 79.2 73.5 46.9 29.5 66.3 56.2 31.5 25. ]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 116 :  Loss = 0.1759476607564305   ACC = 93.45351999194278\n",
            "TEST TEST  train_dataset: Epoch 117 :  Loss = 0.133035633468006   ACC = 95.67932319468224: Epoch 117 :  Loss = 0.133035633468006   ACC = 95.67932319468224 Class wise = [97.575      99.62468724 92.07232267 95.70765661 90.71566731 74.83870968\n",
            " 92.47311828 80.18018018 97.01492537 80.        ]\n",
            "TEST TEST  val_dataset: Epoch 117 :  Loss = 2.1899134006500245   ACC = 60.8: Epoch 117 :  Loss = 2.1899134006500245   ACC = 60.8 Class wise = [95.1 97.8 73.4 78.7 65.8 37.3 53.9 39.7 46.4 19.9]\n",
            "TEST TEST  test_dataset: Epoch 117 :  Loss = 2.3746405363082888   ACC = 61.019999999999996: Epoch 117 :  Loss = 2.3746405363082888   ACC = 61.019999999999996 Class wise = [92.5 98.4 73.2 73.2 64.  37.3 60.  37.6 50.2 23.8]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 117 :  Loss = 0.16804164226039056   ACC = 93.71537919226508\n",
            "TEST TEST  train_dataset: Epoch 118 :  Loss = 0.18254786541465787   ACC = 94.54124282405077: Epoch 118 :  Loss = 0.18254786541465787   ACC = 94.54124282405077 Class wise = [98.525      99.20767306 88.10848401 96.51972158 89.16827853 58.38709677\n",
            " 87.6344086  63.96396396 88.05970149 82.5       ]\n",
            "TEST TEST  val_dataset: Epoch 118 :  Loss = 2.696120133590698   ACC = 57.550000000000004: Epoch 118 :  Loss = 2.696120133590698   ACC = 57.550000000000004 Class wise = [96.2 97.4 74.4 76.5 64.1 29.8 56.3 31.7 29.5 19.6]\n",
            "TEST TEST  test_dataset: Epoch 118 :  Loss = 3.107271171569824   ACC = 56.910000000000004: Epoch 118 :  Loss = 3.107271171569824   ACC = 56.910000000000004 Class wise = [94.8 96.6 70.6 74.9 65.5 29.6 57.4 29.4 33.7 16.6]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 118 :  Loss = 0.15510410435406963   ACC = 94.37002719307081\n",
            "TEST TEST  train_dataset: Epoch 119 :  Loss = 0.19676916222666305   ACC = 93.94702386947326: Epoch 119 :  Loss = 0.19676916222666305   ACC = 93.94702386947326 Class wise = [97.1        99.87489575 83.24061196 94.43155452 92.64990329 69.67741935\n",
            " 92.47311828 69.36936937 95.52238806 75.        ]\n",
            "TEST TEST  val_dataset: Epoch 119 :  Loss = 2.3424188556671144   ACC = 59.29: Epoch 119 :  Loss = 2.3424188556671144   ACC = 59.29 Class wise = [94.2 99.3 66.8 77.  66.8 31.9 60.8 32.8 42.9 20.4]\n",
            "TEST TEST  test_dataset: Epoch 119 :  Loss = 2.6192610527038576   ACC = 59.48: Epoch 119 :  Loss = 2.6192610527038576   ACC = 59.48 Class wise = [93.2 99.5 66.  70.4 66.8 30.9 64.4 33.6 47.1 22.9]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1\n",
            "Epoch 119 :  Loss = 0.1618283153456712   ACC = 94.23909759290966\n",
            "TEST TEST  train_dataset: Epoch 120 :  Loss = 0.1722019764967394   ACC = 94.702386947326: Epoch 120 :  Loss = 0.1722019764967394   ACC = 94.702386947326 Class wise = [99.125      98.62385321 92.55910987 79.46635731 96.51837524 66.4516129\n",
            " 95.16129032 76.57657658 92.53731343 70.        ]\n",
            "TEST TEST  val_dataset: Epoch 120 :  Loss = 2.4477088533401488   ACC = 60.17: Epoch 120 :  Loss = 2.4477088533401488   ACC = 60.17 Class wise = [95.9 97.4 80.5 57.7 73.4 29.5 75.  40.2 36.1 16. ]\n",
            "TEST TEST  test_dataset: Epoch 120 :  Loss = 2.7844036468505857   ACC = 59.8: Epoch 120 :  Loss = 2.7844036468505857   ACC = 59.8 Class wise = [96.8 95.4 78.4 49.3 74.  28.  79.3 39.1 39.8 17.9]\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0', requires_grad=True) tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) \n",
            "\n",
            "lr:  0.1   arch lr:  0.01\n",
            "Epoch 120 :  Loss = 0.1421228062231287   ACC = 94.83331654748716\n",
            "dy tensor([1.0041, 0.9995, 0.9964, 0.9932, 0.9897, 0.9859, 0.9814, 0.9760, 0.9689,\n",
            "        0.9586], device='cuda:0', grad_fn=<MvBackward>)\n",
            "ly tensor([-0.0018,  0.1054,  0.2139,  0.3223,  0.4306,  0.5385,  0.6460,  0.7526,\n",
            "         0.8581,  0.9610], device='cuda:0', grad_fn=<MvBackward>)\n",
            "TEST TEST  train_dataset: Epoch 121 :  Loss = 0.1447387900076276   ACC = 95.48796454829288: Epoch 121 :  Loss = 0.1447387900076276   ACC = 95.48796454829288 Class wise = [ 96.075       99.20767306  95.61891516  94.43155452  92.26305609\n",
            "  70.32258065  91.39784946  92.79279279  92.53731343 100.        ]\n",
            "TEST TEST  val_dataset: Epoch 121 :  Loss = 1.9424198261260985   ACC = 64.37: Epoch 121 :  Loss = 1.9424198261260985   ACC = 64.37 Class wise = [91.4 97.7 82.5 76.2 68.3 33.5 58.9 50.3 38.4 46.5]\n",
            "TEST TEST  test_dataset: Epoch 121 :  Loss = 2.087117338562012   ACC = 65.01: Epoch 121 :  Loss = 2.087117338562012   ACC = 65.01 Class wise = [89.9 97.3 80.6 71.6 70.6 32.4 61.2 53.5 38.3 54.7]\n",
            "tensor([-0.0092, -0.0080, -0.0094, -0.0058, -0.0062, -0.0047, -0.0042,  1.0060],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 9.9257e-01, -6.1169e-03, -7.9542e-03, -4.3741e-03, -5.2070e-03,\n",
            "        -4.8297e-03, -3.0520e-03, -1.3373e-08], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.1   arch lr:  0.01\n",
            "Epoch 121 :  Loss = 0.18924484643790643   ACC = 93.33266189948635\n",
            "TEST TEST  train_dataset: Epoch 122 :  Loss = 0.2092298626170344   ACC = 94.03766743881559: Epoch 122 :  Loss = 0.2092298626170344   ACC = 94.03766743881559 Class wise = [98.55       99.62468724 90.9596662  69.83758701 86.26692456 99.03225806\n",
            " 92.47311828 74.77477477 80.59701493 85.        ]\n",
            "TEST TEST  val_dataset: Epoch 122 :  Loss = 2.407648675918579   ACC = 58.809999999999995: Epoch 122 :  Loss = 2.407648675918579   ACC = 58.809999999999995 Class wise = [95.2 97.8 73.7 43.4 59.1 76.5 63.4 35.3 19.3 24.4]\n",
            "TEST TEST  test_dataset: Epoch 122 :  Loss = 2.8295792446136474   ACC = 58.309999999999995: Epoch 122 :  Loss = 2.8295792446136474   ACC = 58.309999999999995 Class wise = [94.2 98.  69.2 46.1 57.  76.4 65.4 34.2 19.1 23.5]\n",
            "tensor([-0.0177, -0.0156, -0.0175, -0.0113, -0.0117, -0.0084, -0.0081,  1.0142],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 9.8479e-01, -1.2602e-02, -1.6189e-02, -9.0558e-03, -1.0726e-02,\n",
            "        -9.9250e-03, -6.3458e-03, -2.4903e-08], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.1   arch lr:  0.01\n",
            "Epoch 122 :  Loss = 0.1518359769866214   ACC = 94.54124282405077\n",
            "TEST TEST  train_dataset: Epoch 123 :  Loss = 0.11404359621912322   ACC = 96.05196897975628: Epoch 123 :  Loss = 0.11404359621912322   ACC = 96.05196897975628 Class wise = [99.025      98.24854045 94.85396384 83.52668213 89.94197292 97.41935484\n",
            " 93.01075269 93.69369369 82.08955224 92.5       ]\n",
            "TEST TEST  val_dataset: Epoch 123 :  Loss = 1.9889620094299316   ACC = 63.92: Epoch 123 :  Loss = 1.9889620094299316   ACC = 63.92 Class wise = [95.9 95.6 81.5 61.4 57.5 64.8 66.2 61.2 19.4 35.7]\n",
            "TEST TEST  test_dataset: Epoch 123 :  Loss = 2.2479556985855105   ACC = 63.62: Epoch 123 :  Loss = 2.2479556985855105   ACC = 63.62 Class wise = [95.9 94.5 79.  55.6 60.  61.6 66.2 61.6 21.6 40.2]\n",
            "tensor([-0.0273, -0.0237, -0.0275, -0.0173, -0.0181, -0.0132, -0.0125,  1.0202],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 9.7760e-01, -1.8445e-02, -2.4023e-02, -1.3213e-02, -1.5712e-02,\n",
            "        -1.4566e-02, -9.1996e-03, -3.6415e-08], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.1   arch lr:  0.01\n",
            "Epoch 123 :  Loss = 0.13766272402965887   ACC = 95.18581931715178\n",
            "TEST TEST  train_dataset: Epoch 124 :  Loss = 0.23436805798287286   ACC = 93.39309094571458: Epoch 124 :  Loss = 0.23436805798287286   ACC = 93.39309094571458 Class wise = [95.8        98.04003336 94.36717663 96.86774942 76.78916828 68.38709677\n",
            " 86.55913978 49.54954955 83.58208955 42.5       ]\n",
            "TEST TEST  val_dataset: Epoch 124 :  Loss = 3.0000468132019042   ACC = 55.379999999999995: Epoch 124 :  Loss = 3.0000468132019042   ACC = 55.379999999999995 Class wise = [92.6 95.  83.8 80.2 53.4 33.7 54.8 22.  31.6  6.7]\n",
            "TEST TEST  test_dataset: Epoch 124 :  Loss = 3.4829754981994627   ACC = 54.339999999999996: Epoch 124 :  Loss = 3.4829754981994627   ACC = 54.339999999999996 Class wise = [90.5 95.7 80.3 78.8 50.6 32.8 54.4 22.  29.1  9.2]\n",
            "tensor([-0.0365, -0.0316, -0.0370, -0.0230, -0.0243, -0.0181, -0.0166,  1.0250],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 9.7067e-01, -2.4143e-02, -3.1493e-02, -1.7300e-02, -2.0569e-02,\n",
            "        -1.9070e-02, -1.2046e-02, -4.7960e-08], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.1   arch lr:  0.01\n",
            "Epoch 124 :  Loss = 0.13639835074584475   ACC = 95.22610534797059\n",
            "TEST TEST  train_dataset: Epoch 125 :  Loss = 0.07464285753948749   ACC = 97.37133648907242: Epoch 125 :  Loss = 0.07464285753948749   ACC = 97.37133648907242 Class wise = [ 99.625       99.45788157  94.9930459   91.76334107  94.39071567\n",
            "  92.25806452  88.17204301 100.          85.07462687  87.5       ]\n",
            "TEST TEST  val_dataset: Epoch 125 :  Loss = 2.2823674459457397   ACC = 59.67: Epoch 125 :  Loss = 2.2823674459457397   ACC = 59.67 Class wise = [96.7 96.9 79.3 65.5 66.3 51.5 45.3 57.3 18.  19.9]\n",
            "TEST TEST  test_dataset: Epoch 125 :  Loss = 2.591315623664856   ACC = 60.08: Epoch 125 :  Loss = 2.591315623664856   ACC = 60.08 Class wise = [96.6 96.7 77.6 59.4 67.1 51.7 50.5 58.8 19.8 22.6]\n",
            "tensor([-0.0463, -0.0399, -0.0471, -0.0291, -0.0308, -0.0232, -0.0210,  1.0306],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 9.6374e-01, -2.9783e-02, -3.9045e-02, -2.1298e-02, -2.5376e-02,\n",
            "        -2.3548e-02, -1.4778e-02, -6.0689e-08], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.1   arch lr:  0.01\n",
            "Epoch 125 :  Loss = 0.1577871068239044   ACC = 94.17866854668145\n",
            "TEST TEST  train_dataset: Epoch 126 :  Loss = 0.2042844107485043   ACC = 93.71537919226508: Epoch 126 :  Loss = 0.2042844107485043   ACC = 93.71537919226508 Class wise = [ 97.975       98.29024187  90.68150209  73.66589327  88.39458414\n",
            "  98.06451613  68.8172043   86.48648649  97.01492537 100.        ]\n",
            "TEST TEST  val_dataset: Epoch 126 :  Loss = 2.0304875411987306   ACC = 62.73: Epoch 126 :  Loss = 2.0304875411987306   ACC = 62.73 Class wise = [93.9 97.1 75.7 50.1 60.8 72.4 31.  40.9 58.1 47.3]\n",
            "TEST TEST  test_dataset: Epoch 126 :  Loss = 2.2192388854980467   ACC = 63.11: Epoch 126 :  Loss = 2.2192388854980467   ACC = 63.11 Class wise = [94.2 95.8 70.4 46.3 59.5 75.8 33.5 43.  56.5 56.1]\n",
            "tensor([-0.0554, -0.0476, -0.0567, -0.0347, -0.0369, -0.0281, -0.0249,  1.0352],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 9.5700e-01, -3.5223e-02, -4.6442e-02, -2.5130e-02, -3.0013e-02,\n",
            "        -2.7879e-02, -1.7399e-02, -7.2550e-08], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.1   arch lr:  0.01\n",
            "Epoch 126 :  Loss = 0.1236049722948035   ACC = 95.79010977943399\n",
            "TEST TEST  train_dataset: Epoch 127 :  Loss = 0.12554028143443866   ACC = 96.20304159532682: Epoch 127 :  Loss = 0.12554028143443866   ACC = 96.20304159532682 Class wise = [99.05       99.5412844  96.94019471 79.11832947 92.26305609 97.41935484\n",
            " 89.78494624 92.79279279 67.1641791  82.5       ]\n",
            "TEST TEST  val_dataset: Epoch 127 :  Loss = 2.51728953704834   ACC = 60.69: Epoch 127 :  Loss = 2.51728953704834   ACC = 60.69 Class wise = [95.8 97.  83.5 52.8 60.4 63.8 61.9 52.1 13.8 25.8]\n",
            "TEST TEST  test_dataset: Epoch 127 :  Loss = 2.811099361038208   ACC = 60.660000000000004: Epoch 127 :  Loss = 2.811099361038208   ACC = 60.660000000000004 Class wise = [95.1 97.5 83.1 48.  61.6 62.  61.2 50.8 15.1 32.2]\n",
            "tensor([-0.0647, -0.0561, -0.0658, -0.0410, -0.0437, -0.0334, -0.0296,  1.0394],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 9.5052e-01, -4.0666e-02, -5.3277e-02, -2.9041e-02, -3.4632e-02,\n",
            "        -3.2139e-02, -2.0114e-02, -8.5689e-08], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.1   arch lr:  0.01\n",
            "Epoch 127 :  Loss = 0.13960718061643276   ACC = 95.15560479403766\n",
            "TEST TEST  train_dataset: Epoch 128 :  Loss = 0.179428887218372   ACC = 94.71245845503073: Epoch 128 :  Loss = 0.179428887218372   ACC = 94.71245845503073 Class wise = [99.525      97.206005   95.75799722 85.26682135 94.00386847 71.61290323\n",
            " 57.52688172 63.06306306 95.52238806 77.5       ]\n",
            "TEST TEST  val_dataset: Epoch 128 :  Loss = 3.020516690826416   ACC = 55.75: Epoch 128 :  Loss = 3.020516690826416   ACC = 55.75 Class wise = [97.  95.2 84.1 61.9 67.2 32.2 29.1 34.8 36.  20. ]\n",
            "TEST TEST  test_dataset: Epoch 128 :  Loss = 3.332235115432739   ACC = 56.18: Epoch 128 :  Loss = 3.332235115432739   ACC = 56.18 Class wise = [96.8 93.3 81.6 58.9 74.1 35.3 29.5 31.6 37.7 23. ]\n",
            "tensor([-0.0758, -0.0657, -0.0772, -0.0483, -0.0515, -0.0400, -0.0350,  1.0432],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 9.4387e-01, -4.6111e-02, -6.0452e-02, -3.2949e-02, -3.9278e-02,\n",
            "        -3.6453e-02, -2.2863e-02, -1.0180e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.1   arch lr:  0.01\n",
            "Epoch 128 :  Loss = 0.1890632224138175   ACC = 93.4635914996475\n",
            "TEST TEST  train_dataset: Epoch 129 :  Loss = 0.1619480605142356   ACC = 95.12539027092356: Epoch 129 :  Loss = 0.1619480605142356   ACC = 95.12539027092356 Class wise = [99.225      99.45788157 92.48956885 84.57076566 92.45647969 72.25806452\n",
            " 97.31182796 70.27027027 71.64179104 57.5       ]\n",
            "TEST TEST  val_dataset: Epoch 129 :  Loss = 3.012276276397705   ACC = 57.85: Epoch 129 :  Loss = 3.012276276397705   ACC = 57.85 Class wise = [96.5 98.6 76.4 61.1 64.7 35.2 78.3 35.6 17.5 14.6]\n",
            "TEST TEST  test_dataset: Epoch 129 :  Loss = 3.4232153274536135   ACC = 57.76: Epoch 129 :  Loss = 3.4232153274536135   ACC = 57.76 Class wise = [96.  98.6 76.1 55.4 66.9 33.5 81.5 35.3 20.2 14.1]\n",
            "tensor([-0.0871, -0.0754, -0.0892, -0.0555, -0.0593, -0.0464, -0.0403,  1.0476],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 9.3653e-01, -5.2028e-02, -6.8546e-02, -3.7174e-02, -4.4342e-02,\n",
            "        -4.1173e-02, -2.5791e-02, -1.1099e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.1   arch lr:  0.01\n",
            "Epoch 129 :  Loss = 0.15403703580958353   ACC = 94.32974116225199\n",
            "TEST TEST  train_dataset: Epoch 130 :  Loss = 0.17728427994982426   ACC = 94.87360257830598: Epoch 130 :  Loss = 0.17728427994982426   ACC = 94.87360257830598 Class wise = [99.425      96.87239366 88.8038943  97.21577726 88.39458414 78.70967742\n",
            " 67.74193548 88.28828829 71.64179104 80.        ]\n",
            "TEST TEST  val_dataset: Epoch 130 :  Loss = 2.726634853363037   ACC = 58.45: Epoch 130 :  Loss = 2.726634853363037   ACC = 58.45 Class wise = [97.8 94.2 72.8 83.2 62.4 38.2 36.6 55.6 18.8 24.9]\n",
            "TEST TEST  test_dataset: Epoch 130 :  Loss = 3.067701821899414   ACC = 58.43000000000001: Epoch 130 :  Loss = 3.067701821899414   ACC = 58.43000000000001 Class wise = [96.5 93.5 68.6 80.8 61.4 39.1 37.7 55.7 19.5 31.5]\n",
            "tensor([-0.0967, -0.0833, -0.0994, -0.0612, -0.0657, -0.0517, -0.0445,  1.0513],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 9.2987e-01, -5.7337e-02, -7.5888e-02, -4.0894e-02, -4.8873e-02,\n",
            "        -4.5424e-02, -2.8345e-02, -1.2253e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.1   arch lr:  0.01\n",
            "Epoch 130 :  Loss = 0.13449280038014502   ACC = 95.12539027092356\n",
            "TEST TEST  train_dataset: Epoch 131 :  Loss = 0.18207528252221747   ACC = 94.3901702084802: Epoch 131 :  Loss = 0.18207528252221747   ACC = 94.3901702084802 Class wise = [96.45       94.20350292 93.88038943 98.02784223 91.8762089  68.06451613\n",
            " 91.39784946 91.89189189 95.52238806 95.        ]\n",
            "TEST TEST  val_dataset: Epoch 131 :  Loss = 2.2015915550231933   ACC = 63.79: Epoch 131 :  Loss = 2.2015915550231933   ACC = 63.79 Class wise = [93.1 93.2 80.  84.3 64.3 34.5 58.3 48.2 46.  36. ]\n",
            "TEST TEST  test_dataset: Epoch 131 :  Loss = 2.460960182571411   ACC = 63.75999999999999: Epoch 131 :  Loss = 2.460960182571411   ACC = 63.75999999999999 Class wise = [91.8 90.3 78.2 79.7 67.4 32.  65.7 48.  44.3 40.2]\n",
            "tensor([-0.1085, -0.0934, -0.1120, -0.0688, -0.0741, -0.0589, -0.0501,  1.0541],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 9.2292e-01, -6.3026e-02, -8.3449e-02, -4.5012e-02, -5.3738e-02,\n",
            "        -4.9935e-02, -3.1293e-02, -1.3501e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.1   arch lr:  0.01\n",
            "Epoch 131 :  Loss = 0.1227088749486762   ACC = 95.68939470238695\n",
            "TEST TEST  train_dataset: Epoch 132 :  Loss = 0.1971361076667333   ACC = 94.48081377782253: Epoch 132 :  Loss = 0.1971361076667333   ACC = 94.48081377782253 Class wise = [95.4        99.91659716 96.38386648 79.93039443 92.0696325  80.\n",
            " 94.08602151 88.28828829 91.04477612 90.        ]\n",
            "TEST TEST  val_dataset: Epoch 132 :  Loss = 2.4365469787597656   ACC = 60.760000000000005: Epoch 132 :  Loss = 2.4365469787597656   ACC = 60.760000000000005 Class wise = [90.1 98.4 86.1 54.3 70.8 42.8 61.5 47.2 30.6 25.8]\n",
            "TEST TEST  test_dataset: Epoch 132 :  Loss = 2.78222511177063   ACC = 60.12: Epoch 132 :  Loss = 2.78222511177063   ACC = 60.12 Class wise = [89.3 98.6 82.6 47.6 68.  40.4 65.4 48.9 31.9 28.5]\n",
            "tensor([-0.1197, -0.1028, -0.1239, -0.0757, -0.0819, -0.0658, -0.0551,  1.0560],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 9.1647e-01, -6.8137e-02, -9.0623e-02, -4.8600e-02, -5.8108e-02,\n",
            "        -5.4040e-02, -3.3753e-02, -1.4601e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.1   arch lr:  0.01\n",
            "Epoch 132 :  Loss = 0.1531621303234123   ACC = 94.59160036257428\n",
            "TEST TEST  train_dataset: Epoch 133 :  Loss = 0.17167445839874118   ACC = 94.82324503978245: Epoch 133 :  Loss = 0.17167445839874118   ACC = 94.82324503978245 Class wise = [98.675      98.70725605 94.85396384 68.44547564 95.16441006 97.41935484\n",
            " 90.32258065 77.47747748 94.02985075 90.        ]\n",
            "TEST TEST  val_dataset: Epoch 133 :  Loss = 2.2639350021362303   ACC = 62.12: Epoch 133 :  Loss = 2.2639350021362303   ACC = 62.12 Class wise = [95.7 96.5 79.6 43.5 72.1 69.4 56.6 42.9 37.8 27.1]\n",
            "TEST TEST  test_dataset: Epoch 133 :  Loss = 2.508282949066162   ACC = 62.51: Epoch 133 :  Loss = 2.508282949066162   ACC = 62.51 Class wise = [94.7 95.2 78.6 38.3 72.7 67.4 61.1 40.5 42.6 34. ]\n",
            "tensor([-0.1310, -0.1125, -0.1354, -0.0827, -0.0899, -0.0726, -0.0599,  1.0585],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 9.0966e-01, -7.3627e-02, -9.7950e-02, -5.2385e-02, -6.2760e-02,\n",
            "        -5.8404e-02, -3.6255e-02, -1.5627e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.1   arch lr:  0.01\n",
            "Epoch 133 :  Loss = 0.12192623302440309   ACC = 95.59875113304462\n",
            "TEST TEST  train_dataset: Epoch 134 :  Loss = 0.13663426574377005   ACC = 95.5886796253399: Epoch 134 :  Loss = 0.13663426574377005   ACC = 95.5886796253399 Class wise = [ 96.925       97.78982485  97.91376912  85.49883991  97.29206963\n",
            "  82.90322581  89.78494624  83.78378378 100.          92.5       ]\n",
            "TEST TEST  val_dataset: Epoch 134 :  Loss = 2.044870386505127   ACC = 63.22: Epoch 134 :  Loss = 2.044870386505127   ACC = 63.22 Class wise = [92.1 96.1 86.2 61.4 75.5 45.7 51.9 37.5 54.3 31.5]\n",
            "TEST TEST  test_dataset: Epoch 134 :  Loss = 2.2715256614685058   ACC = 63.93: Epoch 134 :  Loss = 2.2715256614685058   ACC = 63.93 Class wise = [92.1 95.6 85.7 56.2 77.9 44.2 54.7 36.7 54.8 41.4]\n",
            "tensor([-0.1406, -0.1204, -0.1457, -0.0884, -0.0964, -0.0782, -0.0641,  1.0611],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 9.0375e-01, -7.8381e-02, -1.0443e-01, -5.5730e-02, -6.6812e-02,\n",
            "        -6.2196e-02, -3.8566e-02, -1.7071e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.1   arch lr:  0.01\n",
            "Epoch 134 :  Loss = 0.12350408803277271   ACC = 95.74982374861517\n",
            "TEST TEST  train_dataset: Epoch 135 :  Loss = 0.24223719778131989   ACC = 93.1614462685064: Epoch 135 :  Loss = 0.24223719778131989   ACC = 93.1614462685064 Class wise = [ 92.975       95.03753128  95.4798331   91.06728538  89.36170213\n",
            "  80.          97.31182796  92.79279279  89.55223881 100.        ]\n",
            "TEST TEST  val_dataset: Epoch 135 :  Loss = 2.158992752838135   ACC = 64.31: Epoch 135 :  Loss = 2.158992752838135   ACC = 64.31 Class wise = [86.9 93.6 85.6 68.6 67.  41.2 71.3 51.2 36.1 41.6]\n",
            "TEST TEST  test_dataset: Epoch 135 :  Loss = 2.359470878982544   ACC = 64.89: Epoch 135 :  Loss = 2.359470878982544   ACC = 64.89 Class wise = [86.4 91.9 82.6 64.6 66.4 41.7 74.7 54.2 36.1 50.3]\n",
            "tensor([-0.1514, -0.1297, -0.1567, -0.0952, -0.1042, -0.0852, -0.0688,  1.0619],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 8.9782e-01, -8.3185e-02, -1.1082e-01, -5.9064e-02, -7.0884e-02,\n",
            "        -6.6007e-02, -4.0790e-02, -1.8293e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.1   arch lr:  0.01\n",
            "Epoch 135 :  Loss = 0.15884420955059333   ACC = 94.55131433175546\n",
            "TEST TEST  train_dataset: Epoch 136 :  Loss = 0.17487255139382377   ACC = 94.49088528552724: Epoch 136 :  Loss = 0.17487255139382377   ACC = 94.49088528552724 Class wise = [ 94.675       95.41284404  94.29763561  95.82366589  91.2959381\n",
            "  88.06451613  94.62365591  91.89189189 100.          87.5       ]\n",
            "TEST TEST  val_dataset: Epoch 136 :  Loss = 1.8978435123443604   ACC = 66.21000000000001: Epoch 136 :  Loss = 1.8978435123443604   ACC = 66.21000000000001 Class wise = [89.  93.  80.3 76.4 63.6 48.4 64.1 54.6 65.4 27.3]\n",
            "TEST TEST  test_dataset: Epoch 136 :  Loss = 2.0174574766159057   ACC = 67.62: Epoch 136 :  Loss = 2.0174574766159057   ACC = 67.62 Class wise = [87.4 92.1 78.8 76.1 64.2 53.8 65.5 53.3 69.8 35.2]\n",
            "tensor([-0.1623, -0.1391, -0.1677, -0.1022, -0.1119, -0.0918, -0.0741,  1.0649],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 8.9154e-01, -8.8215e-02, -1.1765e-01, -6.2564e-02, -7.5161e-02,\n",
            "        -7.0023e-02, -4.3192e-02, -1.9608e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.1   arch lr:  0.01\n",
            "Epoch 136 :  Loss = 0.10752675159512504   ACC = 96.29368516466916\n",
            "TEST TEST  train_dataset: Epoch 137 :  Loss = 0.09716386254764295   ACC = 96.66633094974317: Epoch 137 :  Loss = 0.09716386254764295   ACC = 96.66633094974317 Class wise = [96.775      99.5412844  98.12239221 90.02320186 97.09864603 90.64516129\n",
            " 87.6344086  93.69369369 95.52238806 97.5       ]\n",
            "TEST TEST  val_dataset: Epoch 137 :  Loss = 2.2014462005615236   ACC = 63.17: Epoch 137 :  Loss = 2.2014462005615236   ACC = 63.17 Class wise = [93.6 97.  85.7 63.5 72.9 46.9 54.7 55.6 33.7 28.1]\n",
            "TEST TEST  test_dataset: Epoch 137 :  Loss = 2.3880462802886964   ACC = 64.03999999999999: Epoch 137 :  Loss = 2.3880462802886964   ACC = 64.03999999999999 Class wise = [91.8 96.6 83.9 60.4 74.2 45.2 54.9 58.1 36.  39.3]\n",
            "tensor([-0.1739, -0.1489, -0.1801, -0.1094, -0.1202, -0.0993, -0.0792,  1.0653],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 8.8549e-01, -9.3099e-02, -1.2429e-01, -6.6003e-02, -7.9324e-02,\n",
            "        -7.3914e-02, -4.5534e-02, -2.0824e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.1   arch lr:  0.01\n",
            "Epoch 137 :  Loss = 0.1319258259957333   ACC = 95.20596233256119\n",
            "TEST TEST  train_dataset: Epoch 138 :  Loss = 0.16744031961840322   ACC = 95.01460368617181: Epoch 138 :  Loss = 0.16744031961840322   ACC = 95.01460368617181 Class wise = [97.8        99.41618015 98.26147427 77.49419954 90.52224371 69.35483871\n",
            " 92.47311828 94.59459459 89.55223881 92.5       ]\n",
            "TEST TEST  val_dataset: Epoch 138 :  Loss = 2.396920236968994   ACC = 61.480000000000004: Epoch 138 :  Loss = 2.396920236968994   ACC = 61.480000000000004 Class wise = [93.5 96.6 87.3 56.6 59.6 36.1 59.8 51.6 39.2 34.5]\n",
            "TEST TEST  test_dataset: Epoch 138 :  Loss = 2.6252796436309813   ACC = 62.27: Epoch 138 :  Loss = 2.6252796436309813   ACC = 62.27 Class wise = [94.5 96.8 87.1 49.6 61.7 32.8 63.4 52.1 43.4 41.3]\n",
            "tensor([-0.1841, -0.1575, -0.1908, -0.1156, -0.1273, -0.1054, -0.0835,  1.0680],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 8.7978e-01, -9.7622e-02, -1.3058e-01, -6.9085e-02, -8.3163e-02,\n",
            "        -7.7538e-02, -4.7540e-02, -2.2099e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.1   arch lr:  0.01\n",
            "Epoch 138 :  Loss = 0.12470272825429604   ACC = 95.42753550206467\n",
            "TEST TEST  train_dataset: Epoch 139 :  Loss = 0.11318563527084032   ACC = 96.59583039581025: Epoch 139 :  Loss = 0.11318563527084032   ACC = 96.59583039581025 Class wise = [99.425      98.79065888 94.29763561 88.63109049 89.55512573 92.90322581\n",
            " 93.01075269 94.59459459 86.56716418 95.        ]\n",
            "TEST TEST  val_dataset: Epoch 139 :  Loss = 2.2811902256011964   ACC = 63.36000000000001: Epoch 139 :  Loss = 2.2811902256011964   ACC = 63.36000000000001 Class wise = [96.3 96.3 79.5 60.8 57.2 53.2 63.7 57.7 30.3 38.6]\n",
            "TEST TEST  test_dataset: Epoch 139 :  Loss = 2.529263211631775   ACC = 63.72: Epoch 139 :  Loss = 2.529263211631775   ACC = 63.72 Class wise = [95.8 95.9 75.8 59.9 59.1 53.2 62.7 58.4 33.1 43.3]\n",
            "tensor([-0.1964, -0.1680, -0.2036, -0.1234, -0.1362, -0.1137, -0.0893,  1.0673],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 8.7403e-01, -1.0223e-01, -1.3681e-01, -7.2316e-02, -8.7086e-02,\n",
            "        -8.1215e-02, -4.9778e-02, -2.3273e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.1   arch lr:  0.01\n",
            "Epoch 139 :  Loss = 0.12139738978354132   ACC = 95.59875113304462\n",
            "TEST TEST  train_dataset: Epoch 140 :  Loss = 0.21589212812485561   ACC = 93.97723839258737: Epoch 140 :  Loss = 0.21589212812485561   ACC = 93.97723839258737 Class wise = [ 97.75        95.7881568   78.92906815  93.61948956  93.42359768\n",
            "  97.74193548  97.84946237  98.1981982   97.01492537 100.        ]\n",
            "TEST TEST  val_dataset: Epoch 140 :  Loss = 1.7569598810195923   ACC = 69.47: Epoch 140 :  Loss = 1.7569598810195923   ACC = 69.47 Class wise = [93.1 93.5 61.7 72.2 66.7 69.  69.6 67.9 42.1 58.9]\n",
            "TEST TEST  test_dataset: Epoch 140 :  Loss = 1.9424361240386963   ACC = 69.88: Epoch 140 :  Loss = 1.9424361240386963   ACC = 69.88 Class wise = [92.2 92.4 56.2 69.  66.5 68.9 71.4 69.5 44.8 67.9]\n",
            "tensor([-0.2077, -0.1776, -0.2157, -0.1307, -0.1446, -0.1215, -0.0947,  1.0662],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 8.6854e-01, -1.0670e-01, -1.4283e-01, -7.5522e-02, -9.0905e-02,\n",
            "        -8.4765e-02, -5.2031e-02, -2.4627e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.1   arch lr:  0.01\n",
            "Epoch 140 :  Loss = 0.13879717174331782   ACC = 94.75274448584953\n",
            "TEST TEST  train_dataset: Epoch 141 :  Loss = 0.20193006605981448   ACC = 94.33981266995669: Epoch 141 :  Loss = 0.20193006605981448   ACC = 94.33981266995669 Class wise = [96.75       94.82902419 90.33379694 94.19953596 95.74468085 91.29032258\n",
            " 76.88172043 85.58558559 88.05970149 92.5       ]\n",
            "TEST TEST  val_dataset: Epoch 141 :  Loss = 2.348049196243286   ACC = 64.09: Epoch 141 :  Loss = 2.348049196243286   ACC = 64.09 Class wise = [92.6 92.  74.6 77.3 71.9 53.6 48.3 48.9 34.8 46.9]\n",
            "TEST TEST  test_dataset: Epoch 141 :  Loss = 2.640914575576782   ACC = 63.73: Epoch 141 :  Loss = 2.640914575576782   ACC = 63.73 Class wise = [92.4 91.7 72.5 73.5 74.6 50.9 48.4 46.2 34.6 52.5]\n",
            "tensor([-0.2204, -0.1886, -0.2286, -0.1391, -0.1541, -0.1303, -0.1010,  1.0652],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 8.6263e-01, -1.1157e-01, -1.4913e-01, -7.9029e-02, -9.5057e-02,\n",
            "        -8.8612e-02, -5.4512e-02, -2.6146e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.1   arch lr:  0.01\n",
            "Epoch 141 :  Loss = 0.1616321706405062   ACC = 94.14845402356733\n",
            "TEST TEST  train_dataset: Epoch 142 :  Loss = 0.13364533182717195   ACC = 95.82032430254809: Epoch 142 :  Loss = 0.13364533182717195   ACC = 95.82032430254809 Class wise = [98.8        96.62218515 94.08901252 90.25522042 89.36170213 87.09677419\n",
            " 94.08602151 97.2972973  89.55223881 97.5       ]\n",
            "TEST TEST  val_dataset: Epoch 142 :  Loss = 2.268401142120361   ACC = 64.41: Epoch 142 :  Loss = 2.268401142120361   ACC = 64.41 Class wise = [95.  94.2 81.2 66.3 59.8 51.6 62.8 60.9 30.7 41.6]\n",
            "TEST TEST  test_dataset: Epoch 142 :  Loss = 2.434691733551025   ACC = 64.92999999999999: Epoch 142 :  Loss = 2.434691733551025   ACC = 64.92999999999999 Class wise = [95.1 93.8 77.2 62.7 58.1 50.9 64.8 60.3 34.6 51.8]\n",
            "tensor([-0.2327, -0.1990, -0.2420, -0.1468, -0.1629, -0.1383, -0.1067,  1.0657],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 8.5632e-01, -1.1664e-01, -1.5611e-01, -8.2606e-02, -9.9385e-02,\n",
            "        -9.2659e-02, -5.6957e-02, -2.7310e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.1   arch lr:  0.01\n",
            "Epoch 142 :  Loss = 0.11208990089289911   ACC = 95.80018128713868\n",
            "TEST TEST  train_dataset: Epoch 143 :  Loss = 0.19995656759312222   ACC = 94.14845402356733: Epoch 143 :  Loss = 0.19995656759312222   ACC = 94.14845402356733 Class wise = [91.3        99.62468724 95.13212796 89.79118329 94.97098646 93.87096774\n",
            " 95.16129032 92.79279279 95.52238806 97.5       ]\n",
            "TEST TEST  val_dataset: Epoch 143 :  Loss = 2.1281351039886474   ACC = 66.47999999999999: Epoch 143 :  Loss = 2.1281351039886474   ACC = 66.47999999999999 Class wise = [88.  98.  80.8 65.4 65.1 57.1 70.  55.2 54.3 30.9]\n",
            "TEST TEST  test_dataset: Epoch 143 :  Loss = 2.2658244487762453   ACC = 66.85: Epoch 143 :  Loss = 2.2658244487762453   ACC = 66.85 Class wise = [82.7 98.1 79.6 61.7 71.4 57.3 70.3 52.9 60.3 34.2]\n",
            "tensor([-0.2432, -0.2080, -0.2528, -0.1534, -0.1706, -0.1453, -0.1114,  1.0655],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 8.5097e-01, -1.2097e-01, -1.6186e-01, -8.5610e-02, -1.0305e-01,\n",
            "        -9.6095e-02, -5.8989e-02, -2.8364e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.1   arch lr:  0.01\n",
            "Epoch 143 :  Loss = 0.19445073366111135   ACC = 93.01037365293584\n",
            "TEST TEST  train_dataset: Epoch 144 :  Loss = 0.1602989705094687   ACC = 95.24624836337999: Epoch 144 :  Loss = 0.1602989705094687   ACC = 95.24624836337999 Class wise = [ 95.675       98.62385321  94.29763561  92.34338747  90.71566731\n",
            "  81.61290323  97.84946237  94.59459459  95.52238806 100.        ]\n",
            "TEST TEST  val_dataset: Epoch 144 :  Loss = 2.002588303756714   ACC = 66.47999999999999: Epoch 144 :  Loss = 2.002588303756714   ACC = 66.47999999999999 Class wise = [90.6 97.2 78.5 69.3 59.4 41.6 71.9 63.3 39.  54. ]\n",
            "TEST TEST  test_dataset: Epoch 144 :  Loss = 2.139454580116272   ACC = 67.86: Epoch 144 :  Loss = 2.139454580116272   ACC = 67.86 Class wise = [89.8 97.3 76.6 67.9 63.4 40.7 75.3 63.6 42.8 61.2]\n",
            "tensor([-0.2551, -0.2188, -0.2641, -0.1616, -0.1797, -0.1535, -0.1174,  1.0656],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 8.4493e-01, -1.2600e-01, -1.6812e-01, -8.9138e-02, -1.0730e-01,\n",
            "        -1.0004e-01, -6.1364e-02, -2.9283e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.1   arch lr:  0.01\n",
            "Epoch 144 :  Loss = 0.14880653828838727   ACC = 94.62181488568838\n",
            "TEST TEST  train_dataset: Epoch 145 :  Loss = 0.17158794768664132   ACC = 95.16567630174238: Epoch 145 :  Loss = 0.17158794768664132   ACC = 95.16567630174238 Class wise = [98.55       98.91576314 92.90681502 88.74709977 96.32495164 54.19354839\n",
            " 92.47311828 83.78378378 97.01492537 95.        ]\n",
            "TEST TEST  val_dataset: Epoch 145 :  Loss = 2.3295855377197268   ACC = 63.3: Epoch 145 :  Loss = 2.3295855377197268   ACC = 63.3 Class wise = [95.  96.5 78.6 70.  76.9 23.4 67.1 42.7 42.5 40.3]\n",
            "TEST TEST  test_dataset: Epoch 145 :  Loss = 2.704401359176636   ACC = 63.239999999999995: Epoch 145 :  Loss = 2.704401359176636   ACC = 63.239999999999995 Class wise = [93.9 96.9 76.6 63.6 79.1 25.1 69.  40.7 44.8 42.7]\n",
            "tensor([-0.2668, -0.2292, -0.2754, -0.1694, -0.1887, -0.1619, -0.1232,  1.0641],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 8.3916e-01, -1.3083e-01, -1.7405e-01, -9.2552e-02, -1.1138e-01,\n",
            "        -1.0381e-01, -6.3728e-02, -3.0051e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.1   arch lr:  0.01\n",
            "Epoch 145 :  Loss = 0.12075264732701287   ACC = 95.2764628864941\n",
            "TEST TEST  train_dataset: Epoch 146 :  Loss = 0.18469589069051942   ACC = 94.60167187027898: Epoch 146 :  Loss = 0.18469589069051942   ACC = 94.60167187027898 Class wise = [ 98.975       93.07756464  91.16828929  89.55916473  94.58413926\n",
            "  83.87096774  94.62365591  95.4954955   71.64179104 100.        ]\n",
            "TEST TEST  val_dataset: Epoch 146 :  Loss = 2.0226243522644043   ACC = 65.55: Epoch 146 :  Loss = 2.0226243522644043   ACC = 65.55 Class wise = [96.5 93.  75.3 63.7 67.8 42.8 62.3 65.  25.2 63.9]\n",
            "TEST TEST  test_dataset: Epoch 146 :  Loss = 2.2616413440704344   ACC = 66.14: Epoch 146 :  Loss = 2.2616413440704344   ACC = 66.14 Class wise = [94.2 91.5 72.5 61.2 69.3 43.6 65.9 63.1 28.5 71.6]\n",
            "tensor([-0.2793, -0.2398, -0.2884, -0.1769, -0.1978, -0.1705, -0.1283,  1.0622],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 8.3350e-01, -1.3537e-01, -1.8014e-01, -9.5633e-02, -1.1521e-01,\n",
            "        -1.0743e-01, -6.5728e-02, -3.1134e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.1   arch lr:  0.01\n",
            "Epoch 146 :  Loss = 0.10519436296904383   ACC = 95.37717796354114\n",
            "TEST TEST  train_dataset: Epoch 147 :  Loss = 0.2558544815661192   ACC = 93.70530768456038: Epoch 147 :  Loss = 0.2558544815661192   ACC = 93.70530768456038 Class wise = [ 93.55        96.99749791  92.48956885  89.79118329  89.16827853\n",
            "  93.22580645  90.32258065  99.0990991   95.52238806 100.        ]\n",
            "TEST TEST  val_dataset: Epoch 147 :  Loss = 2.0819817202568056   ACC = 67.54: Epoch 147 :  Loss = 2.0819817202568056   ACC = 67.54 Class wise = [88.2 95.  78.4 65.3 58.3 59.  62.7 67.8 39.9 60.8]\n",
            "TEST TEST  test_dataset: Epoch 147 :  Loss = 2.302487373161316   ACC = 68.42: Epoch 147 :  Loss = 2.302487373161316   ACC = 68.42 Class wise = [86.1 95.8 73.9 64.3 56.5 63.3 63.  72.4 44.2 64.7]\n",
            "tensor([-0.2917, -0.2497, -0.3023, -0.1843, -0.2065, -0.1788, -0.1337,  1.0611],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 8.2785e-01, -1.3987e-01, -1.8646e-01, -9.8856e-02, -1.1908e-01,\n",
            "        -1.1104e-01, -6.8002e-02, -3.2177e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.1   arch lr:  0.01\n",
            "Epoch 147 :  Loss = 0.13607147240407014   ACC = 94.24916910061437\n",
            "TEST TEST  train_dataset: Epoch 148 :  Loss = 0.1390823294210799   ACC = 95.49803605599759: Epoch 148 :  Loss = 0.1390823294210799   ACC = 95.49803605599759 Class wise = [93.75       99.33277731 97.49652295 93.73549884 92.84332689 92.58064516\n",
            " 91.39784946 90.99099099 94.02985075 97.5       ]\n",
            "TEST TEST  val_dataset: Epoch 148 :  Loss = 2.0223961767196657   ACC = 65.72: Epoch 148 :  Loss = 2.0223961767196657   ACC = 65.72 Class wise = [87.2 97.4 87.1 68.  66.1 51.8 54.5 56.7 50.7 37.7]\n",
            "TEST TEST  test_dataset: Epoch 148 :  Loss = 2.2997957723617555   ACC = 66.85: Epoch 148 :  Loss = 2.2997957723617555   ACC = 66.85 Class wise = [86.2 97.7 85.6 68.1 67.9 53.3 57.4 56.1 52.5 43.7]\n",
            "tensor([-0.3032, -0.2597, -0.3140, -0.1916, -0.2151, -0.1870, -0.1389,  1.0592],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 8.2277e-01, -1.4397e-01, -1.9190e-01, -1.0164e-01, -1.2254e-01,\n",
            "        -1.1429e-01, -6.9810e-02, -3.3115e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.1   arch lr:  0.01\n",
            "Epoch 148 :  Loss = 0.12794367930166117   ACC = 94.56138583946017\n",
            "TEST TEST  train_dataset: Epoch 149 :  Loss = 0.3244762719367876   ACC = 91.42914694329741: Epoch 149 :  Loss = 0.3244762719367876   ACC = 91.42914694329741 Class wise = [ 97.2         90.74228524  83.58831711  98.02784223  93.81044487\n",
            "  56.12903226  53.22580645  92.79279279 100.          97.5       ]\n",
            "TEST TEST  val_dataset: Epoch 149 :  Loss = 2.4052317287445066   ACC = 62.43: Epoch 149 :  Loss = 2.4052317287445066   ACC = 62.43 Class wise = [95.1 87.3 66.5 82.7 67.  26.4 25.8 54.2 67.1 52.2]\n",
            "TEST TEST  test_dataset: Epoch 149 :  Loss = 2.849393599319458   ACC = 62.64999999999999: Epoch 149 :  Loss = 2.849393599319458   ACC = 62.64999999999999 Class wise = [95.  86.2 64.1 80.1 70.  24.  23.4 53.2 74.7 55.8]\n",
            "tensor([-0.3145, -0.2693, -0.3258, -0.1984, -0.2235, -0.1951, -0.1435,  1.0565],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 8.1801e-01, -1.4781e-01, -1.9700e-01, -1.0422e-01, -1.2576e-01,\n",
            "        -1.1734e-01, -7.1462e-02, -3.4088e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.1   arch lr:  0.01\n",
            "Epoch 149 :  Loss = 0.2102526600877556   ACC = 91.77157820525733\n",
            "TEST TEST  train_dataset: Epoch 150 :  Loss = 0.2152627943034306   ACC = 93.7455937153792: Epoch 150 :  Loss = 0.2152627943034306   ACC = 93.7455937153792 Class wise = [ 93.725       93.86989158  94.15855355  88.16705336  96.90522244\n",
            "  96.4516129   97.84946237  98.1981982   94.02985075 100.        ]\n",
            "TEST TEST  val_dataset: Epoch 150 :  Loss = 1.6467731761932374   ACC = 70.45: Epoch 150 :  Loss = 1.6467731761932374   ACC = 70.45 Class wise = [87.4 92.  79.8 61.  73.4 66.2 68.7 62.2 48.3 65.5]\n",
            "TEST TEST  test_dataset: Epoch 150 :  Loss = 1.754427363204956   ACC = 70.87: Epoch 150 :  Loss = 1.754427363204956   ACC = 70.87 Class wise = [87.1 91.3 77.  58.6 75.9 65.  73.5 59.9 51.  69.4]\n",
            "tensor([-0.3260, -0.2786, -0.3384, -0.2053, -0.2317, -0.2028, -0.1485,  1.0552],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 8.1266e-01, -1.5198e-01, -2.0297e-01, -1.0704e-01, -1.2931e-01,\n",
            "        -1.2070e-01, -7.3324e-02, -3.4969e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.1   arch lr:  0.01\n",
            "Epoch 150 :  Loss = 0.12029426551583143   ACC = 94.40024171618492\n",
            "dy tensor([ 0.9722,  0.7967,  0.6781,  0.5577,  0.4275,  0.2818,  0.1130, -0.0919,\n",
            "        -0.3587, -0.7450], device='cuda:0', grad_fn=<MvBackward>)\n",
            "ly tensor([-0.0454, -0.0368,  0.0062,  0.0487,  0.0862,  0.1155,  0.1326,  0.1308,\n",
            "         0.0972,  0.0028], device='cuda:0', grad_fn=<MvBackward>)\n",
            "TEST TEST  train_dataset: Epoch 151 :  Loss = 0.3730757461367585   ACC = 90.62342632692115: Epoch 151 :  Loss = 0.3730757461367585   ACC = 90.62342632692115 Class wise = [ 94.125       90.28356964  79.41585535  89.44315545  99.41972921\n",
            "  89.03225806  80.64516129  97.2972973  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 151 :  Loss = 2.0112309982299803   ACC = 68.39: Epoch 151 :  Loss = 2.0112309982299803   ACC = 68.39 Class wise = [89.2 88.  66.7 69.5 85.4 51.4 43.2 67.4 70.4 52.7]\n",
            "TEST TEST  test_dataset: Epoch 151 :  Loss = 2.3521180696487427   ACC = 68.16: Epoch 151 :  Loss = 2.3521180696487427   ACC = 68.16 Class wise = [87.1 85.4 61.9 64.8 85.6 51.2 44.  66.9 73.6 61.1]\n",
            "tensor([-0.3379, -0.2886, -0.3514, -0.2127, -0.2406, -0.2116, -0.1538,  1.0515],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 8.0787e-01, -1.5578e-01, -2.0828e-01, -1.0967e-01, -1.3255e-01,\n",
            "        -1.2375e-01, -7.5069e-02, -3.5822e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.1   arch lr:  0.01\n",
            "Epoch 151 :  Loss = 0.13133877595859011   ACC = 93.95709537717796\n",
            "TEST TEST  train_dataset: Epoch 152 :  Loss = 0.20249619868516724   ACC = 93.96716688488267: Epoch 152 :  Loss = 0.20249619868516724   ACC = 93.96716688488267 Class wise = [ 94.125       93.78648874  90.05563282  97.33178654  99.6131528\n",
            "  87.74193548  96.23655914  98.1981982  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 152 :  Loss = 1.830804829788208   ACC = 70.81: Epoch 152 :  Loss = 1.830804829788208   ACC = 70.81 Class wise = [89.6 91.6 74.6 83.  79.5 42.7 68.6 60.7 60.8 57. ]\n",
            "TEST TEST  test_dataset: Epoch 152 :  Loss = 2.033843344116211   ACC = 70.73: Epoch 152 :  Loss = 2.033843344116211   ACC = 70.73 Class wise = [88.3 89.6 68.8 79.5 82.1 41.  67.1 61.6 66.7 62.6]\n",
            "tensor([-0.3498, -0.2988, -0.3637, -0.2203, -0.2495, -0.2201, -0.1594,  1.0493],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 8.0288e-01, -1.5978e-01, -2.1368e-01, -1.1242e-01, -1.3594e-01,\n",
            "        -1.2694e-01, -7.6908e-02, -3.6566e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.1   arch lr:  0.01\n",
            "Epoch 152 :  Loss = 0.10034672585315534   ACC = 95.05488971699063\n",
            "TEST TEST  train_dataset: Epoch 153 :  Loss = 0.26483879569362256   ACC = 93.12116023768759: Epoch 153 :  Loss = 0.26483879569362256   ACC = 93.12116023768759 Class wise = [ 93.45        95.53794829  96.17524339  80.62645012  88.97485493\n",
            "  94.83870968  91.39784946 100.          95.52238806 100.        ]\n",
            "TEST TEST  val_dataset: Epoch 153 :  Loss = 2.035024749469757   ACC = 69.26: Epoch 153 :  Loss = 2.035024749469757   ACC = 69.26 Class wise = [89.  93.2 83.4 55.9 61.9 65.3 59.3 71.  48.  65.6]\n",
            "TEST TEST  test_dataset: Epoch 153 :  Loss = 2.2473236404418944   ACC = 70.34: Epoch 153 :  Loss = 2.2473236404418944   ACC = 70.34 Class wise = [87.9 94.4 82.9 53.8 64.6 68.8 59.6 71.  50.5 69.9]\n",
            "tensor([-0.3629, -0.3092, -0.3786, -0.2279, -0.2589, -0.2297, -0.1646,  1.0447],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 7.9807e-01, -1.6346e-01, -2.1924e-01, -1.1491e-01, -1.3908e-01,\n",
            "        -1.2994e-01, -7.8528e-02, -3.7791e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.1   arch lr:  0.01\n",
            "Epoch 153 :  Loss = 0.15619809705017795   ACC = 92.48665525229127\n",
            "TEST TEST  train_dataset: Epoch 154 :  Loss = 0.1490863816584142   ACC = 95.79010977943399: Epoch 154 :  Loss = 0.1490863816584142   ACC = 95.79010977943399 Class wise = [ 95.925       97.91492911  92.6286509   97.5638051   94.19729207\n",
            "  89.67741935  95.16129032  93.69369369 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 154 :  Loss = 2.285299204826355   ACC = 66.59: Epoch 154 :  Loss = 2.285299204826355   ACC = 66.59 Class wise = [91.  94.1 76.  79.9 67.1 52.3 65.4 49.8 47.8 42.5]\n",
            "TEST TEST  test_dataset: Epoch 154 :  Loss = 2.46850492477417   ACC = 66.96: Epoch 154 :  Loss = 2.46850492477417   ACC = 66.96 Class wise = [90.1 94.1 73.4 76.4 65.4 50.7 64.4 51.2 54.  49.9]\n",
            "tensor([-0.3733, -0.3181, -0.3895, -0.2341, -0.2666, -0.2371, -0.1688,  1.0422],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 7.9337e-01, -1.6720e-01, -2.2431e-01, -1.1740e-01, -1.4223e-01,\n",
            "        -1.3292e-01, -8.0120e-02, -3.8765e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.1   arch lr:  0.01\n",
            "Epoch 154 :  Loss = 0.12322787365556567   ACC = 93.33266189948635\n",
            "TEST TEST  train_dataset: Epoch 155 :  Loss = 0.37880351097037007   ACC = 91.55000503575386: Epoch 155 :  Loss = 0.37880351097037007   ACC = 91.55000503575386 Class wise = [ 92.125       91.40950792  89.22114047  97.33178654  89.55512573\n",
            "  84.83870968  89.24731183  85.58558559  95.52238806 100.        ]\n",
            "TEST TEST  val_dataset: Epoch 155 :  Loss = 2.387803855895996   ACC = 67.28: Epoch 155 :  Loss = 2.387803855895996   ACC = 67.28 Class wise = [87.3 88.5 73.4 83.8 64.6 49.3 50.3 41.4 64.1 70.1]\n",
            "TEST TEST  test_dataset: Epoch 155 :  Loss = 2.8067444496154783   ACC = 66.72: Epoch 155 :  Loss = 2.8067444496154783   ACC = 66.72 Class wise = [84.9 87.9 72.9 81.6 61.7 46.5 50.4 40.3 67.3 73.7]\n",
            "tensor([-0.3837, -0.3266, -0.4003, -0.2400, -0.2741, -0.2445, -0.1726,  1.0395],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 7.8886e-01, -1.7077e-01, -2.2912e-01, -1.1970e-01, -1.4522e-01,\n",
            "        -1.3577e-01, -8.1493e-02, -3.9743e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.1   arch lr:  0.01\n",
            "Epoch 155 :  Loss = 0.1382581010267254   ACC = 92.5772988216336\n",
            "TEST TEST  train_dataset: Epoch 156 :  Loss = 0.4396453696542349   ACC = 91.12700171215631: Epoch 156 :  Loss = 0.4396453696542349   ACC = 91.12700171215631 Class wise = [ 91.          86.57214345  94.43671766  97.5638051   90.32882012\n",
            "  92.58064516  90.86021505  96.3963964   94.02985075 100.        ]\n",
            "TEST TEST  val_dataset: Epoch 156 :  Loss = 2.009456876373291   ACC = 67.7: Epoch 156 :  Loss = 2.009456876373291   ACC = 67.7 Class wise = [86.1 84.4 72.6 78.4 54.7 48.  51.4 61.  62.6 77.8]\n",
            "TEST TEST  test_dataset: Epoch 156 :  Loss = 2.1612205409526823   ACC = 68.67999999999999: Epoch 156 :  Loss = 2.1612205409526823   ACC = 68.67999999999999 Class wise = [84.7 84.9 74.  72.9 58.7 51.9 51.4 61.6 66.5 80.2]\n",
            "tensor([-0.3944, -0.3356, -0.4111, -0.2463, -0.2818, -0.2519, -0.1768,  1.0380],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 7.8429e-01, -1.7439e-01, -2.3403e-01, -1.2205e-01, -1.4825e-01,\n",
            "        -1.3865e-01, -8.2913e-02, -4.0557e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.1   arch lr:  0.01\n",
            "Epoch 156 :  Loss = 0.11545581168813376   ACC = 93.52402054587571\n",
            "TEST TEST  train_dataset: Epoch 157 :  Loss = 0.2321559143415786   ACC = 94.0779534696344: Epoch 157 :  Loss = 0.2321559143415786   ACC = 94.0779534696344 Class wise = [ 93.15        95.3294412   93.39360223  97.44779582  94.97098646\n",
            "  90.          90.32258065  91.89189189  98.50746269 100.        ]\n",
            "TEST TEST  val_dataset: Epoch 157 :  Loss = 2.167237003326416   ACC = 67.88: Epoch 157 :  Loss = 2.167237003326416   ACC = 67.88 Class wise = [85.5 92.2 77.6 81.5 66.1 44.1 53.3 53.7 64.9 59.9]\n",
            "TEST TEST  test_dataset: Epoch 157 :  Loss = 2.3466825817108155   ACC = 68.81: Epoch 157 :  Loss = 2.3466825817108155   ACC = 68.81 Class wise = [86.2 93.6 74.7 80.7 67.7 44.9 54.7 54.3 65.8 65.5]\n",
            "tensor([-0.4058, -0.3447, -0.4237, -0.2526, -0.2899, -0.2601, -0.1809,  1.0345],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 7.8007e-01, -1.7763e-01, -2.3875e-01, -1.2414e-01, -1.5098e-01,\n",
            "        -1.4128e-01, -8.4182e-02, -4.1518e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.1   arch lr:  0.01\n",
            "Epoch 157 :  Loss = 0.16584895358055377   ACC = 91.32843186625038\n",
            "TEST TEST  train_dataset: Epoch 158 :  Loss = 0.29912068573193284   ACC = 92.8391580219559: Epoch 158 :  Loss = 0.29912068573193284   ACC = 92.8391580219559 Class wise = [ 91.175       97.78982485  86.16133519  96.9837587   96.90522244\n",
            "  87.74193548  94.62365591  86.48648649 100.          97.5       ]\n",
            "TEST TEST  val_dataset: Epoch 158 :  Loss = 2.049670665359497   ACC = 69.19999999999999: Epoch 158 :  Loss = 2.049670665359497   ACC = 69.19999999999999 Class wise = [87.8 94.1 70.  81.  73.6 48.9 69.2 50.  66.7 50.7]\n",
            "TEST TEST  test_dataset: Epoch 158 :  Loss = 2.2460631706237795   ACC = 69.66: Epoch 158 :  Loss = 2.2460631706237795   ACC = 69.66 Class wise = [84.7 94.5 67.6 78.9 75.7 48.5 69.1 50.5 69.9 57.2]\n",
            "tensor([-0.4157, -0.3525, -0.4350, -0.2577, -0.2967, -0.2670, -0.1839,  1.0316],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 7.7585e-01, -1.8086e-01, -2.4349e-01, -1.2617e-01, -1.5369e-01,\n",
            "        -1.4389e-01, -8.5325e-02, -4.2479e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.1   arch lr:  0.01\n",
            "Epoch 158 :  Loss = 0.18762279810268168   ACC = 90.24070903414241\n",
            "TEST TEST  train_dataset: Epoch 159 :  Loss = 0.49698358440601176   ACC = 89.15298620203444: Epoch 159 :  Loss = 0.49698358440601176   ACC = 89.15298620203444 Class wise = [ 90.15        88.94912427  90.33379694  82.13457077  88.78143133\n",
            "  83.22580645  99.46236559  87.38738739 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 159 :  Loss = 2.1363561038970946   ACC = 68.89999999999999: Epoch 159 :  Loss = 2.1363561038970946   ACC = 68.89999999999999 Class wise = [85.8 86.7 79.  62.4 63.  41.5 88.4 52.2 70.1 59.9]\n",
            "TEST TEST  test_dataset: Epoch 159 :  Loss = 2.340384107208252   ACC = 69.22: Epoch 159 :  Loss = 2.340384107208252   ACC = 69.22 Class wise = [84.8 87.  74.5 58.7 61.4 43.6 88.4 48.5 74.6 70.7]\n",
            "tensor([-0.4267, -0.3615, -0.4469, -0.2639, -0.3046, -0.2749, -0.1880,  1.0287],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 7.7110e-01, -1.8459e-01, -2.4871e-01, -1.2863e-01, -1.5684e-01,\n",
            "        -1.4689e-01, -8.6860e-02, -4.3103e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.1   arch lr:  0.01\n",
            "Epoch 159 :  Loss = 0.12626779534921437   ACC = 92.37586866753954\n",
            "TEST TEST  train_dataset: Epoch 160 :  Loss = 0.44629112813276206   ACC = 90.5025682344647: Epoch 160 :  Loss = 0.44629112813276206   ACC = 90.5025682344647 Class wise = [ 90.9         88.11509591  90.19471488  86.42691415  95.16441006\n",
            "  97.74193548 100.          96.3963964  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 160 :  Loss = 1.629111417388916   ACC = 73.32: Epoch 160 :  Loss = 1.629111417388916   ACC = 73.32 Class wise = [87.8 86.7 72.3 63.4 67.1 68.1 78.1 68.1 65.7 75.9]\n",
            "TEST TEST  test_dataset: Epoch 160 :  Loss = 1.843850365447998   ACC = 73.59: Epoch 160 :  Loss = 1.843850365447998   ACC = 73.59 Class wise = [84.2 86.2 69.3 61.4 68.6 69.1 80.5 68.  66.3 82.3]\n",
            "tensor([-0.4362, -0.3689, -0.4574, -0.2687, -0.3111, -0.2816, -0.1908,  1.0256],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 7.6718e-01, -1.8754e-01, -2.5314e-01, -1.3046e-01, -1.5932e-01,\n",
            "        -1.4930e-01, -8.7867e-02, -4.3996e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.010000000000000002   arch lr:  0.01\n",
            "Epoch 160 :  Loss = 0.06061769082064258   ACC = 94.69231543962131\n",
            "TEST TEST  train_dataset: Epoch 161 :  Loss = 0.20843497382718035   ACC = 95.61889414845403: Epoch 161 :  Loss = 0.20843497382718035   ACC = 95.61889414845403 Class wise = [ 94.275       94.1618015   98.19193324  97.21577726  99.03288201\n",
            "  97.41935484  99.46236559  98.1981982  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 161 :  Loss = 1.6677296883583068   ACC = 74.74: Epoch 161 :  Loss = 1.6677296883583068   ACC = 74.74 Class wise = [89.5 92.3 82.6 72.8 73.2 55.1 69.1 71.8 69.  72. ]\n",
            "TEST TEST  test_dataset: Epoch 161 :  Loss = 1.8049062957763673   ACC = 74.98: Epoch 161 :  Loss = 1.8049062957763673   ACC = 74.98 Class wise = [86.9 91.1 79.7 68.6 76.6 55.5 72.7 69.6 70.5 78.6]\n",
            "tensor([-0.4452, -0.3761, -0.4674, -0.2737, -0.3176, -0.2883, -0.1939,  1.0217],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 7.6387e-01, -1.9007e-01, -2.5687e-01, -1.3208e-01, -1.6145e-01,\n",
            "        -1.5135e-01, -8.8811e-02, -4.4671e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.010000000000000002   arch lr:  0.01\n",
            "Epoch 161 :  Loss = 0.04385332003354378   ACC = 95.69946621009166\n",
            "TEST TEST  train_dataset: Epoch 162 :  Loss = 0.2135283584980851   ACC = 95.66925168697755: Epoch 162 :  Loss = 0.2135283584980851   ACC = 95.66925168697755 Class wise = [ 95.375       92.32693912  98.26147427  96.9837587   99.6131528\n",
            "  98.38709677 100.          97.2972973  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 162 :  Loss = 1.592869605255127   ACC = 74.95: Epoch 162 :  Loss = 1.592869605255127   ACC = 74.95 Class wise = [90.  88.7 81.  71.2 74.7 60.  72.3 69.  67.9 74.7]\n",
            "TEST TEST  test_dataset: Epoch 162 :  Loss = 1.7711991767883302   ACC = 75.47: Epoch 162 :  Loss = 1.7711991767883302   ACC = 75.47 Class wise = [88.6 88.6 78.3 67.3 78.7 59.4 74.3 69.4 69.1 81. ]\n",
            "tensor([-0.4531, -0.3825, -0.4761, -0.2780, -0.3233, -0.2942, -0.1965,  1.0186],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 7.6102e-01, -1.9226e-01, -2.6006e-01, -1.3346e-01, -1.6329e-01,\n",
            "        -1.5312e-01, -8.9594e-02, -4.5645e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.010000000000000002   arch lr:  0.01\n",
            "Epoch 162 :  Loss = 0.03990438997277273   ACC = 95.66925168697755\n",
            "TEST TEST  train_dataset: Epoch 163 :  Loss = 0.20511944821197362   ACC = 95.8505388256622: Epoch 163 :  Loss = 0.20511944821197362   ACC = 95.8505388256622 Class wise = [ 95.425       92.74395329  98.40055633  97.91183295  98.83945841\n",
            "  99.03225806 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 163 :  Loss = 1.6124635990142822   ACC = 74.98: Epoch 163 :  Loss = 1.6124635990142822   ACC = 74.98 Class wise = [90.3 90.3 80.5 72.4 72.3 59.  73.4 67.9 65.7 78. ]\n",
            "TEST TEST  test_dataset: Epoch 163 :  Loss = 1.7868996276855469   ACC = 75.51: Epoch 163 :  Loss = 1.7868996276855469   ACC = 75.51 Class wise = [89.2 89.3 78.9 69.9 76.8 59.9 74.  66.9 68.2 82. ]\n",
            "tensor([-0.4599, -0.3878, -0.4835, -0.2815, -0.3280, -0.2990, -0.1987,  1.0162],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 7.5840e-01, -1.9423e-01, -2.6305e-01, -1.3471e-01, -1.6496e-01,\n",
            "        -1.5473e-01, -9.0321e-02, -4.6641e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.010000000000000002   arch lr:  0.01\n",
            "Epoch 163 :  Loss = 0.037818725972464225   ACC = 96.162755564508\n",
            "TEST TEST  train_dataset: Epoch 164 :  Loss = 0.21621158452393865   ACC = 95.5584651022258: Epoch 164 :  Loss = 0.21621158452393865   ACC = 95.5584651022258 Class wise = [ 94.325       93.4528774   98.12239221  98.02784223  98.83945841\n",
            "  99.35483871 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 164 :  Loss = 1.5827811416625976   ACC = 75.44999999999999: Epoch 164 :  Loss = 1.5827811416625976   ACC = 75.44999999999999 Class wise = [90.1 91.  81.6 72.  71.5 58.3 73.4 71.  69.3 76.3]\n",
            "TEST TEST  test_dataset: Epoch 164 :  Loss = 1.7739051952362062   ACC = 75.87: Epoch 164 :  Loss = 1.7739051952362062   ACC = 75.87 Class wise = [86.6 90.4 77.9 70.7 75.4 58.7 75.3 70.4 71.9 81.4]\n",
            "tensor([-0.4680, -0.3942, -0.4926, -0.2858, -0.3338, -0.3051, -0.2014,  1.0124],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 7.5558e-01, -1.9640e-01, -2.6621e-01, -1.3611e-01, -1.6679e-01,\n",
            "        -1.5649e-01, -9.1163e-02, -4.7632e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.010000000000000002   arch lr:  0.01\n",
            "Epoch 164 :  Loss = 0.03212281350984941   ACC = 96.25339913385034\n",
            "TEST TEST  train_dataset: Epoch 165 :  Loss = 0.18176983732154744   ACC = 96.32389968778327: Epoch 165 :  Loss = 0.18176983732154744   ACC = 96.32389968778327 Class wise = [ 95.75        93.61968307  99.09596662  97.33178654  99.6131528\n",
            "  99.67741935 100.          97.2972973  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 165 :  Loss = 1.5841634231567383   ACC = 75.51: Epoch 165 :  Loss = 1.5841634231567383   ACC = 75.51 Class wise = [90.7 89.9 82.3 67.8 74.5 62.9 74.2 69.5 68.4 74.9]\n",
            "TEST TEST  test_dataset: Epoch 165 :  Loss = 1.7670789184570312   ACC = 75.87: Epoch 165 :  Loss = 1.7670789184570312   ACC = 75.87 Class wise = [89.5 89.6 79.4 64.7 77.7 61.7 74.7 70.  70.9 80.5]\n",
            "tensor([-0.4756, -0.4001, -0.5013, -0.2899, -0.3392, -0.3108, -0.2041,  1.0091],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 7.5283e-01, -1.9849e-01, -2.6935e-01, -1.3748e-01, -1.6856e-01,\n",
            "        -1.5819e-01, -9.2023e-02, -4.8646e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.010000000000000002   arch lr:  0.01\n",
            "Epoch 165 :  Loss = 0.03004349252019454   ACC = 96.49511531876321\n",
            "TEST TEST  train_dataset: Epoch 166 :  Loss = 0.18559156108214953   ACC = 96.30375667237385: Epoch 166 :  Loss = 0.18559156108214953   ACC = 96.30375667237385 Class wise = [ 95.675       93.32777314  98.8178025   98.95591647  99.41972921\n",
            "  99.67741935 100.          96.3963964  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 166 :  Loss = 1.6249515958786012   ACC = 75.92999999999999: Epoch 166 :  Loss = 1.6249515958786012   ACC = 75.92999999999999 Class wise = [91.2 91.1 82.4 73.8 73.4 61.4 73.7 69.1 67.2 76. ]\n",
            "TEST TEST  test_dataset: Epoch 166 :  Loss = 1.808580618095398   ACC = 75.92: Epoch 166 :  Loss = 1.808580618095398   ACC = 75.92 Class wise = [88.7 89.6 78.6 70.9 73.9 60.9 74.7 67.7 72.6 81.6]\n",
            "tensor([-0.4831, -0.4058, -0.5098, -0.2936, -0.3443, -0.3163, -0.2062,  1.0055],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 7.5031e-01, -2.0037e-01, -2.7224e-01, -1.3865e-01, -1.7015e-01,\n",
            "        -1.5974e-01, -9.2669e-02, -4.9746e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.010000000000000002   arch lr:  0.01\n",
            "Epoch 166 :  Loss = 0.02781385407662185   ACC = 96.27354214925974\n",
            "TEST TEST  train_dataset: Epoch 167 :  Loss = 0.17894041310940878   ACC = 96.46490079564911: Epoch 167 :  Loss = 0.17894041310940878   ACC = 96.46490079564911 Class wise = [ 95.675       93.95329441  99.16550765  98.37587007  99.6131528\n",
            "  99.67741935 100.          96.3963964  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 167 :  Loss = 1.6151697408676147   ACC = 75.58: Epoch 167 :  Loss = 1.6151697408676147   ACC = 75.58 Class wise = [91.  91.4 82.4 70.7 74.  58.  74.4 67.7 70.9 75.3]\n",
            "TEST TEST  test_dataset: Epoch 167 :  Loss = 1.8145577032089233   ACC = 75.92: Epoch 167 :  Loss = 1.8145577032089233   ACC = 75.92 Class wise = [89.8 89.9 80.  66.7 77.5 59.2 75.5 66.2 74.9 79.5]\n",
            "tensor([-0.4895, -0.4107, -0.5171, -0.2969, -0.3488, -0.3209, -0.2082,  1.0032],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 7.4786e-01, -2.0224e-01, -2.7504e-01, -1.3986e-01, -1.7173e-01,\n",
            "        -1.6125e-01, -9.3419e-02, -5.0843e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.010000000000000002   arch lr:  0.01\n",
            "Epoch 167 :  Loss = 0.026552557003142095   ACC = 96.28361365696445\n",
            "TEST TEST  train_dataset: Epoch 168 :  Loss = 0.1288614271740351   ACC = 97.19004935038775: Epoch 168 :  Loss = 0.1288614271740351   ACC = 97.19004935038775 Class wise = [ 96.9         95.16263553  98.3310153   98.95591647  99.41972921\n",
            " 100.         100.          97.2972973  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 168 :  Loss = 1.6467314741134644   ACC = 75.46000000000001: Epoch 168 :  Loss = 1.6467314741134644   ACC = 75.46000000000001 Class wise = [91.3 92.5 79.4 71.5 72.2 61.1 76.3 69.9 67.3 73.1]\n",
            "TEST TEST  test_dataset: Epoch 168 :  Loss = 1.8054982719421386   ACC = 76.0: Epoch 168 :  Loss = 1.8054982719421386   ACC = 76.0 Class wise = [89.9 90.6 76.3 70.8 76.7 59.9 78.1 69.  70.3 78.4]\n",
            "tensor([-0.4965, -0.4161, -0.5252, -0.3003, -0.3536, -0.3261, -0.2102,  0.9999],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 7.4541e-01, -2.0409e-01, -2.7784e-01, -1.4103e-01, -1.7329e-01,\n",
            "        -1.6276e-01, -9.4091e-02, -5.1695e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.010000000000000002   arch lr:  0.01\n",
            "Epoch 168 :  Loss = 0.025550319761133877   ACC = 96.36418571860207\n",
            "TEST TEST  train_dataset: Epoch 169 :  Loss = 0.17079944443251346   ACC = 96.4246147648303: Epoch 169 :  Loss = 0.17079944443251346   ACC = 96.4246147648303 Class wise = [ 95.875       93.32777314  98.8178025   99.53596288  99.22630561\n",
            "  99.67741935 100.          96.3963964  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 169 :  Loss = 1.6438234867095947   ACC = 75.96000000000001: Epoch 169 :  Loss = 1.6438234867095947   ACC = 75.96000000000001 Class wise = [91.6 91.  81.9 73.9 75.2 57.1 72.7 71.3 70.3 74.6]\n",
            "TEST TEST  test_dataset: Epoch 169 :  Loss = 1.8388179725646974   ACC = 76.27000000000001: Epoch 169 :  Loss = 1.8388179725646974   ACC = 76.27000000000001 Class wise = [88.7 90.  78.5 72.2 78.5 57.9 73.3 70.6 71.8 81.2]\n",
            "tensor([-0.5033, -0.4212, -0.5330, -0.3036, -0.3583, -0.3311, -0.2120,  0.9965],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 7.4315e-01, -2.0577e-01, -2.8047e-01, -1.4208e-01, -1.7471e-01,\n",
            "        -1.6415e-01, -9.4690e-02, -5.2588e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.010000000000000002   arch lr:  0.01\n",
            "Epoch 169 :  Loss = 0.025847404817041765   ACC = 96.02175445664216\n",
            "TEST TEST  train_dataset: Epoch 170 :  Loss = 0.16719489070564295   ACC = 96.68647396515259: Epoch 170 :  Loss = 0.16719489070564295   ACC = 96.68647396515259 Class wise = [ 96.1         94.49541284  98.88734353  97.79582367  99.6131528\n",
            " 100.         100.          96.3963964  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 170 :  Loss = 1.6405186176300048   ACC = 75.82: Epoch 170 :  Loss = 1.6405186176300048   ACC = 75.82 Class wise = [90.  92.3 79.7 68.9 75.4 65.7 74.6 67.8 68.5 75.3]\n",
            "TEST TEST  test_dataset: Epoch 170 :  Loss = 1.8394720922470094   ACC = 76.14: Epoch 170 :  Loss = 1.8394720922470094   ACC = 76.14 Class wise = [88.3 91.3 77.4 65.6 78.4 65.5 74.3 68.  72.1 80.5]\n",
            "tensor([-0.5096, -0.4259, -0.5402, -0.3065, -0.3625, -0.3356, -0.2136,  0.9938],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 7.4093e-01, -2.0740e-01, -2.8301e-01, -1.4307e-01, -1.7608e-01,\n",
            "        -1.6549e-01, -9.5224e-02, -5.3773e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.010000000000000002   arch lr:  0.01\n",
            "Epoch 170 :  Loss = 0.02278417119881468   ACC = 95.97139691811864\n",
            "TEST TEST  train_dataset: Epoch 171 :  Loss = 0.24667819503119967   ACC = 95.68939470238695: Epoch 171 :  Loss = 0.24667819503119967   ACC = 95.68939470238695 Class wise = [ 96.          90.86738949  98.3310153   97.91183295  99.6131528\n",
            " 100.         100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 171 :  Loss = 1.6222948278903961   ACC = 76.02: Epoch 171 :  Loss = 1.6222948278903961   ACC = 76.02 Class wise = [89.6 88.1 80.1 70.5 74.1 65.1 77.8 64.4 69.7 80.8]\n",
            "TEST TEST  test_dataset: Epoch 171 :  Loss = 1.8810896697998047   ACC = 75.76: Epoch 171 :  Loss = 1.8810896697998047   ACC = 75.76 Class wise = [88.5 87.4 77.8 66.2 75.  65.3 78.  64.  71.4 84. ]\n",
            "tensor([-0.5153, -0.4302, -0.5467, -0.3093, -0.3664, -0.3396, -0.2153,  0.9916],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 7.3881e-01, -2.0899e-01, -2.8545e-01, -1.4407e-01, -1.7742e-01,\n",
            "        -1.6679e-01, -9.5822e-02, -5.4745e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.010000000000000002   arch lr:  0.01\n",
            "Epoch 171 :  Loss = 0.023375995415901175   ACC = 96.29368516466916\n",
            "TEST TEST  train_dataset: Epoch 172 :  Loss = 0.19725806582291147   ACC = 96.4246147648303: Epoch 172 :  Loss = 0.19725806582291147   ACC = 96.4246147648303 Class wise = [ 96.65        91.99332777  99.09596662  98.83990719  99.6131528\n",
            " 100.         100.          96.3963964  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 172 :  Loss = 1.6577470439910889   ACC = 76.09: Epoch 172 :  Loss = 1.6577470439910889   ACC = 76.09 Class wise = [90.8 88.2 81.5 73.3 74.4 60.3 74.4 70.2 70.2 77.6]\n",
            "TEST TEST  test_dataset: Epoch 172 :  Loss = 1.884765950012207   ACC = 76.34: Epoch 172 :  Loss = 1.884765950012207   ACC = 76.34 Class wise = [89.7 87.8 79.2 69.2 78.3 60.9 75.5 68.7 72.1 82. ]\n",
            "tensor([-0.5217, -0.4351, -0.5541, -0.3124, -0.3708, -0.3444, -0.2171,  0.9887],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 7.3648e-01, -2.1076e-01, -2.8807e-01, -1.4521e-01, -1.7892e-01,\n",
            "        -1.6823e-01, -9.6503e-02, -5.5857e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.010000000000000002   arch lr:  0.01\n",
            "Epoch 172 :  Loss = 0.021640263255454824   ACC = 96.06204048746098\n",
            "TEST TEST  train_dataset: Epoch 173 :  Loss = 0.19193876337427448   ACC = 96.36418571860207: Epoch 173 :  Loss = 0.19193876337427448   ACC = 96.36418571860207 Class wise = [ 96.425       92.53544621  99.02642559  98.60788863  99.22630561\n",
            "  98.70967742 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 173 :  Loss = 1.6496013271331786   ACC = 75.92: Epoch 173 :  Loss = 1.6496013271331786   ACC = 75.92 Class wise = [90.8 89.9 81.6 70.  73.2 60.2 78.8 68.2 70.7 75.8]\n",
            "TEST TEST  test_dataset: Epoch 173 :  Loss = 1.889215636062622   ACC = 75.79: Epoch 173 :  Loss = 1.889215636062622   ACC = 75.79 Class wise = [89.5 88.9 78.6 67.7 75.8 59.7 77.3 67.  72.4 81. ]\n",
            "tensor([-0.5287, -0.4407, -0.5620, -0.3163, -0.3759, -0.3497, -0.2196,  0.9851],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 7.3416e-01, -2.1254e-01, -2.9073e-01, -1.4638e-01, -1.8043e-01,\n",
            "        -1.6968e-01, -9.7227e-02, -5.7108e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.010000000000000002   arch lr:  0.01\n",
            "Epoch 173 :  Loss = 0.02320126165445567   ACC = 95.99153993352805\n",
            "TEST TEST  train_dataset: Epoch 174 :  Loss = 0.2447638948721506   ACC = 95.61889414845403: Epoch 174 :  Loss = 0.2447638948721506   ACC = 95.61889414845403 Class wise = [ 95.075       91.49291076  99.09596662  99.07192575  99.22630561\n",
            "  98.70967742 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 174 :  Loss = 1.687648296546936   ACC = 75.89: Epoch 174 :  Loss = 1.687648296546936   ACC = 75.89 Class wise = [89.7 89.3 80.3 72.4 74.1 58.4 73.7 68.2 73.8 79. ]\n",
            "TEST TEST  test_dataset: Epoch 174 :  Loss = 1.9280529861450195   ACC = 76.06: Epoch 174 :  Loss = 1.9280529861450195   ACC = 76.06 Class wise = [88.3 88.5 77.7 69.2 76.8 59.6 74.9 67.7 74.9 83. ]\n",
            "tensor([-0.5350, -0.4454, -0.5691, -0.3193, -0.3802, -0.3543, -0.2213,  0.9822],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 7.3204e-01, -2.1414e-01, -2.9315e-01, -1.4739e-01, -1.8178e-01,\n",
            "        -1.7098e-01, -9.7807e-02, -5.8162e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.010000000000000002   arch lr:  0.01\n",
            "Epoch 174 :  Loss = 0.020454505991810867   ACC = 96.31382818007856\n",
            "TEST TEST  train_dataset: Epoch 175 :  Loss = 0.25954285464251103   ACC = 95.48796454829288: Epoch 175 :  Loss = 0.25954285464251103   ACC = 95.48796454829288 Class wise = [ 95.2         91.15929942  98.40055633  99.07192575  99.03288201\n",
            "  99.03225806 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 175 :  Loss = 1.7185127681732177   ACC = 76.02: Epoch 175 :  Loss = 1.7185127681732177   ACC = 76.02 Class wise = [89.2 90.5 80.  74.2 71.1 61.1 77.  67.1 69.3 80.7]\n",
            "TEST TEST  test_dataset: Epoch 175 :  Loss = 1.958006315612793   ACC = 75.85: Epoch 175 :  Loss = 1.958006315612793   ACC = 75.85 Class wise = [87.5 87.8 76.6 71.  74.2 60.1 77.3 67.  72.1 84.9]\n",
            "tensor([-0.5406, -0.4496, -0.5756, -0.3219, -0.3840, -0.3584, -0.2227,  0.9796],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 7.3007e-01, -2.1561e-01, -2.9541e-01, -1.4829e-01, -1.8301e-01,\n",
            "        -1.7219e-01, -9.8291e-02, -5.9350e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.010000000000000002   arch lr:  0.01\n",
            "Epoch 175 :  Loss = 0.021102987825255198   ACC = 95.94118239500453\n",
            "TEST TEST  train_dataset: Epoch 176 :  Loss = 0.1699276065811378   ACC = 96.68647396515259: Epoch 176 :  Loss = 0.1699276065811378   ACC = 96.68647396515259 Class wise = [ 96.375       93.4528774   99.30458971  98.95591647  99.41972921\n",
            "  99.67741935 100.          96.3963964  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 176 :  Loss = 1.69411600856781   ACC = 76.51: Epoch 176 :  Loss = 1.69411600856781   ACC = 76.51 Class wise = [90.1 90.6 82.1 72.8 74.5 60.4 76.8 68.  72.1 77.7]\n",
            "TEST TEST  test_dataset: Epoch 176 :  Loss = 1.9337928497314454   ACC = 76.14999999999999: Epoch 176 :  Loss = 1.9337928497314454   ACC = 76.14999999999999 Class wise = [89.1 88.9 79.6 69.6 77.3 59.2 76.4 66.1 74.2 81.1]\n",
            "tensor([-0.5460, -0.4536, -0.5819, -0.3244, -0.3876, -0.3623, -0.2240,  0.9772],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 7.2806e-01, -2.1711e-01, -2.9770e-01, -1.4922e-01, -1.8428e-01,\n",
            "        -1.7342e-01, -9.8818e-02, -6.0422e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.010000000000000002   arch lr:  0.01\n",
            "Epoch 176 :  Loss = 0.01791068400764816   ACC = 96.4145432571256\n",
            "TEST TEST  train_dataset: Epoch 177 :  Loss = 0.18712136535823243   ACC = 96.4548292879444: Epoch 177 :  Loss = 0.18712136535823243   ACC = 96.4548292879444 Class wise = [ 95.65        94.37030859  98.60917942  98.49187935  99.41972921\n",
            "  99.35483871 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 177 :  Loss = 1.7118659606933593   ACC = 76.03: Epoch 177 :  Loss = 1.7118659606933593   ACC = 76.03 Class wise = [90.6 92.  80.4 68.2 73.7 58.7 77.  68.6 74.4 76.7]\n",
            "TEST TEST  test_dataset: Epoch 177 :  Loss = 1.954794654083252   ACC = 76.27000000000001: Epoch 177 :  Loss = 1.954794654083252   ACC = 76.27000000000001 Class wise = [88.1 90.2 77.8 66.3 76.8 60.7 77.7 69.  74.7 81.4]\n",
            "tensor([-0.5520, -0.4582, -0.5887, -0.3275, -0.3918, -0.3668, -0.2259,  0.9744],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 7.2604e-01, -2.1864e-01, -3.0001e-01, -1.5019e-01, -1.8557e-01,\n",
            "        -1.7466e-01, -9.9398e-02, -6.1517e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.010000000000000002   arch lr:  0.01\n",
            "Epoch 177 :  Loss = 0.019182443825880895   ACC = 96.1426125490986\n",
            "TEST TEST  train_dataset: Epoch 178 :  Loss = 0.16999781243795395   ACC = 96.80733205760902: Epoch 178 :  Loss = 0.16999781243795395   ACC = 96.80733205760902 Class wise = [ 96.325       94.07839867  99.30458971  98.83990719  99.6131528\n",
            "  99.67741935 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 178 :  Loss = 1.729805667769909   ACC = 75.88000000000001: Epoch 178 :  Loss = 1.729805667769909   ACC = 75.88000000000001 Class wise = [90.4 91.1 83.1 69.  71.4 63.5 75.2 66.8 72.3 76. ]\n",
            "TEST TEST  test_dataset: Epoch 178 :  Loss = 1.980909160232544   ACC = 75.97: Epoch 178 :  Loss = 1.980909160232544   ACC = 75.97 Class wise = [88.9 89.6 79.7 66.  75.6 62.2 76.4 66.6 74.3 80.4]\n",
            "tensor([-0.5573, -0.4623, -0.5949, -0.3300, -0.3954, -0.3707, -0.2273,  0.9720],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 7.2410e-01, -2.2008e-01, -3.0224e-01, -1.5109e-01, -1.8678e-01,\n",
            "        -1.7585e-01, -9.9896e-02, -6.2655e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.010000000000000002   arch lr:  0.01\n",
            "Epoch 178 :  Loss = 0.020788756594915792   ACC = 95.91096787189042\n",
            "TEST TEST  train_dataset: Epoch 179 :  Loss = 0.1768209563894129   ACC = 96.51525833417263: Epoch 179 :  Loss = 0.1768209563894129   ACC = 96.51525833417263 Class wise = [ 96.2         93.49457882  98.74826147  98.25986079  99.41972921\n",
            " 100.         100.          98.1981982  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 179 :  Loss = 1.7206838598251344   ACC = 76.32: Epoch 179 :  Loss = 1.7206838598251344   ACC = 76.32 Class wise = [91.4 90.2 81.2 67.8 74.5 61.7 77.5 72.4 73.5 73. ]\n",
            "TEST TEST  test_dataset: Epoch 179 :  Loss = 1.9860139579772949   ACC = 76.32: Epoch 179 :  Loss = 1.9860139579772949   ACC = 76.32 Class wise = [89.1 87.9 79.6 64.1 78.  62.8 77.3 71.7 75.  77.7]\n",
            "tensor([-0.5627, -0.4661, -0.6013, -0.3324, -0.3990, -0.3746, -0.2285,  0.9690],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 7.2227e-01, -2.2142e-01, -3.0438e-01, -1.5190e-01, -1.8791e-01,\n",
            "        -1.7695e-01, -1.0034e-01, -6.3706e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.010000000000000002   arch lr:  0.01\n",
            "Epoch 179 :  Loss = 0.019040099962058535   ACC = 95.57860811763521\n",
            "TEST TEST  train_dataset: Epoch 180 :  Loss = 0.22568790132970648   ACC = 96.11239802598449: Epoch 180 :  Loss = 0.22568790132970648   ACC = 96.11239802598449 Class wise = [ 95.3         92.82735613  99.09596662  99.30394432  99.6131528\n",
            "  99.67741935 100.          96.3963964  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 180 :  Loss = 1.7585605222702025   ACC = 76.1: Epoch 180 :  Loss = 1.7585605222702025   ACC = 76.1 Class wise = [89.5 90.3 80.7 71.1 74.2 61.6 73.7 68.9 73.2 77.8]\n",
            "TEST TEST  test_dataset: Epoch 180 :  Loss = 1.9998142120361329   ACC = 76.1: Epoch 180 :  Loss = 1.9998142120361329   ACC = 76.1 Class wise = [88.5 89.5 78.9 67.1 76.4 60.9 74.5 68.4 74.9 81.9]\n",
            "tensor([-0.5684, -0.4704, -0.6078, -0.3350, -0.4028, -0.3788, -0.2299,  0.9663],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 7.2027e-01, -2.2290e-01, -3.0669e-01, -1.5280e-01, -1.8915e-01,\n",
            "        -1.7817e-01, -1.0083e-01, -6.4977e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 180 :  Loss = 0.01982151299001425   ACC = 96.04189747205156\n",
            "dy tensor([ 0.8231,  0.5186,  0.3146,  0.1083, -0.1136, -0.3609, -0.6459, -0.9890,\n",
            "        -1.4304, -2.0588], device='cuda:0', grad_fn=<MvBackward>)\n",
            "ly tensor([-0.0656, -0.1056, -0.0944, -0.0836, -0.0797, -0.0874, -0.1124, -0.1639,\n",
            "        -0.2598, -0.4398], device='cuda:0', grad_fn=<MvBackward>)\n",
            "TEST TEST  train_dataset: Epoch 181 :  Loss = 0.25618354759365075   ACC = 95.67932319468224: Epoch 181 :  Loss = 0.25618354759365075   ACC = 95.67932319468224 Class wise = [ 95.15        91.78482068  98.74826147  99.07192575  99.22630561\n",
            "  99.35483871 100.          94.59459459 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 181 :  Loss = 1.7616363669872284   ACC = 75.76: Epoch 181 :  Loss = 1.7616363669872284   ACC = 75.76 Class wise = [90.2 89.9 79.6 70.6 72.8 60.9 74.5 65.8 73.5 79.8]\n",
            "TEST TEST  test_dataset: Epoch 181 :  Loss = 2.0204831314086915   ACC = 75.83: Epoch 181 :  Loss = 2.0204831314086915   ACC = 75.83 Class wise = [89.2 88.6 76.5 68.5 74.6 61.4 75.2 66.3 74.4 83.6]\n",
            "tensor([-0.5741, -0.4748, -0.6143, -0.3378, -0.4068, -0.3831, -0.2314,  0.9634],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 7.1833e-01, -2.2438e-01, -3.0885e-01, -1.5374e-01, -1.9040e-01,\n",
            "        -1.7937e-01, -1.0137e-01, -6.5989e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 181 :  Loss = 0.018515649319643557   ACC = 96.08218350287038\n",
            "TEST TEST  train_dataset: Epoch 182 :  Loss = 0.2669810337715274   ACC = 95.43760700976937: Epoch 182 :  Loss = 0.2669810337715274   ACC = 95.43760700976937 Class wise = [ 94.4         92.16013344  98.53963839  98.72389791  99.6131528\n",
            "  99.03225806 100.          96.3963964  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 182 :  Loss = 1.7020617820739745   ACC = 76.44: Epoch 182 :  Loss = 1.7020617820739745   ACC = 76.44 Class wise = [89.6 89.6 80.1 68.2 72.8 60.6 79.  71.5 73.3 79.7]\n",
            "TEST TEST  test_dataset: Epoch 182 :  Loss = 1.9689477912902833   ACC = 76.25999999999999: Epoch 182 :  Loss = 1.9689477912902833   ACC = 76.25999999999999 Class wise = [86.5 88.4 77.2 66.3 76.5 62.2 77.4 70.7 72.7 84.7]\n",
            "tensor([-0.5798, -0.4791, -0.6208, -0.3404, -0.4107, -0.3872, -0.2329,  0.9608],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 7.1622e-01, -2.2598e-01, -3.1125e-01, -1.5474e-01, -1.9174e-01,\n",
            "        -1.8067e-01, -1.0194e-01, -6.7419e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 182 :  Loss = 0.018643148822725112   ACC = 95.8505388256622\n",
            "TEST TEST  train_dataset: Epoch 183 :  Loss = 0.18223949565845615   ACC = 96.56561587269614: Epoch 183 :  Loss = 0.18223949565845615   ACC = 96.56561587269614 Class wise = [ 95.15        94.66221852  99.30458971  99.53596288  99.6131528\n",
            " 100.         100.          97.2972973  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 183 :  Loss = 1.7188293876647949   ACC = 76.19: Epoch 183 :  Loss = 1.7188293876647949   ACC = 76.19 Class wise = [88.7 92.  83.  73.  74.5 59.6 73.9 69.4 72.9 74.9]\n",
            "TEST TEST  test_dataset: Epoch 183 :  Loss = 1.9735300054550171   ACC = 75.97: Epoch 183 :  Loss = 1.9735300054550171   ACC = 75.97 Class wise = [87.7 90.5 80.1 68.9 77.4 59.7 73.7 67.5 74.4 79.8]\n",
            "tensor([-0.5849, -0.4829, -0.6266, -0.3429, -0.4141, -0.3909, -0.2343,  0.9586],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 7.1432e-01, -2.2743e-01, -3.1341e-01, -1.5567e-01, -1.9297e-01,\n",
            "        -1.8185e-01, -1.0250e-01, -6.8419e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 183 :  Loss = 0.020401477084345705   ACC = 95.93111088729984\n",
            "TEST TEST  train_dataset: Epoch 184 :  Loss = 0.2738719042221869   ACC = 95.43760700976937: Epoch 184 :  Loss = 0.2738719042221869   ACC = 95.43760700976937 Class wise = [ 94.4         91.8265221   99.09596662  99.18793503  98.83945841\n",
            "  99.03225806 100.          96.3963964  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 184 :  Loss = 1.7388475163459778   ACC = 76.67: Epoch 184 :  Loss = 1.7388475163459778   ACC = 76.67 Class wise = [88.5 90.6 82.8 72.6 70.5 59.7 79.1 69.6 72.8 80.5]\n",
            "TEST TEST  test_dataset: Epoch 184 :  Loss = 2.004175051498413   ACC = 76.07000000000001: Epoch 184 :  Loss = 2.004175051498413   ACC = 76.07000000000001 Class wise = [86.3 88.2 78.8 70.9 73.1 59.3 76.8 69.5 73.4 84.4]\n",
            "tensor([-0.5901, -0.4869, -0.6326, -0.3454, -0.4177, -0.3948, -0.2357,  0.9561],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 7.1242e-01, -2.2886e-01, -3.1557e-01, -1.5656e-01, -1.9417e-01,\n",
            "        -1.8302e-01, -1.0301e-01, -6.9542e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 184 :  Loss = 0.018540381480288633   ACC = 96.1224695336892\n",
            "TEST TEST  train_dataset: Epoch 185 :  Loss = 0.16444755212470696   ACC = 96.79726054990432: Epoch 185 :  Loss = 0.16444755212470696   ACC = 96.79726054990432 Class wise = [ 96.275       94.53711426  98.40055633  98.83990719  99.6131528\n",
            "  99.67741935 100.          98.1981982  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 185 :  Loss = 1.7388398406982422   ACC = 76.0: Epoch 185 :  Loss = 1.7388398406982422   ACC = 76.0 Class wise = [90.3 92.  78.5 71.7 72.6 57.9 78.3 71.9 71.1 75.7]\n",
            "TEST TEST  test_dataset: Epoch 185 :  Loss = 1.962909410095215   ACC = 76.19: Epoch 185 :  Loss = 1.962909410095215   ACC = 76.19 Class wise = [88.7 90.5 75.4 69.5 76.4 59.2 78.7 70.6 72.8 80.1]\n",
            "tensor([-0.5960, -0.4914, -0.6393, -0.3483, -0.4218, -0.3992, -0.2372,  0.9531],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 7.1045e-01, -2.3035e-01, -3.1781e-01, -1.5748e-01, -1.9542e-01,\n",
            "        -1.8424e-01, -1.0350e-01, -7.0700e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 185 :  Loss = 0.019853922462764132   ACC = 95.69946621009166\n",
            "TEST TEST  train_dataset: Epoch 186 :  Loss = 0.24346334151510374   ACC = 95.68939470238695: Epoch 186 :  Loss = 0.24346334151510374   ACC = 95.68939470238695 Class wise = [ 94.95        92.07673061  98.8178025   98.95591647  99.6131528\n",
            "  99.03225806 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 186 :  Loss = 1.727693271255493   ACC = 76.0: Epoch 186 :  Loss = 1.727693271255493   ACC = 76.0 Class wise = [88.  89.8 79.8 70.6 74.9 58.8 77.4 69.  72.3 79.4]\n",
            "TEST TEST  test_dataset: Epoch 186 :  Loss = 1.9766247957229615   ACC = 76.17: Epoch 186 :  Loss = 1.9766247957229615   ACC = 76.17 Class wise = [87.6 88.6 77.5 67.5 77.5 59.3 76.9 69.  75.  82.8]\n",
            "tensor([-0.6018, -0.4959, -0.6458, -0.3512, -0.4259, -0.4035, -0.2389,  0.9504],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 7.0839e-01, -2.3196e-01, -3.2010e-01, -1.5853e-01, -1.9677e-01,\n",
            "        -1.8553e-01, -1.0412e-01, -7.1966e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 186 :  Loss = 0.017695344692631326   ACC = 95.63903716386342\n",
            "TEST TEST  train_dataset: Epoch 187 :  Loss = 0.27062578389582737   ACC = 95.36710645583643: Epoch 187 :  Loss = 0.27062578389582737   ACC = 95.36710645583643 Class wise = [ 94.65        91.49291076  98.60917942  98.83990719  99.03288201\n",
            "  99.35483871 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 187 :  Loss = 1.7292369567394257   ACC = 76.25: Epoch 187 :  Loss = 1.7292369567394257   ACC = 76.25 Class wise = [88.7 89.  80.  72.  70.9 62.9 77.1 68.9 73.2 79.8]\n",
            "TEST TEST  test_dataset: Epoch 187 :  Loss = 1.9933662553787233   ACC = 76.18: Epoch 187 :  Loss = 1.9933662553787233   ACC = 76.18 Class wise = [87.3 88.2 77.1 68.8 73.6 62.9 75.9 69.1 74.6 84.3]\n",
            "tensor([-0.6070, -0.4997, -0.6518, -0.3535, -0.4293, -0.4072, -0.2401,  0.9482],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 7.0639e-01, -2.3344e-01, -3.2238e-01, -1.5944e-01, -1.9802e-01,\n",
            "        -1.8674e-01, -1.0462e-01, -7.2937e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 187 :  Loss = 0.019674204978016956   ACC = 95.60882264074932\n",
            "TEST TEST  train_dataset: Epoch 188 :  Loss = 0.24815003341603326   ACC = 95.72968073320575: Epoch 188 :  Loss = 0.24815003341603326   ACC = 95.72968073320575 Class wise = [ 94.85        92.41034195  99.16550765  98.60788863  99.22630561\n",
            "  98.70967742 100.          96.3963964  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 188 :  Loss = 1.742064991569519   ACC = 76.57000000000001: Epoch 188 :  Loss = 1.742064991569519   ACC = 76.57000000000001 Class wise = [88.1 90.4 82.6 69.6 72.2 59.1 78.3 73.9 70.5 81. ]\n",
            "TEST TEST  test_dataset: Epoch 188 :  Loss = 1.992847282409668   ACC = 76.3: Epoch 188 :  Loss = 1.992847282409668   ACC = 76.3 Class wise = [87.6 89.2 79.3 64.7 74.8 60.6 76.8 72.4 73.7 83.9]\n",
            "tensor([-0.6118, -0.5032, -0.6575, -0.3556, -0.4324, -0.4106, -0.2412,  0.9461],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 7.0456e-01, -2.3479e-01, -3.2448e-01, -1.6026e-01, -1.9916e-01,\n",
            "        -1.8786e-01, -1.0508e-01, -7.3895e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 188 :  Loss = 0.020258471323407024   ACC = 95.88075334877631\n",
            "TEST TEST  train_dataset: Epoch 189 :  Loss = 0.24298595461437963   ACC = 95.73975224091046: Epoch 189 :  Loss = 0.24298595461437963   ACC = 95.73975224091046 Class wise = [ 95.675       91.117598    98.74826147  98.72389791  99.6131528\n",
            "  99.35483871 100.          96.3963964  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 189 :  Loss = 1.71997156124115   ACC = 76.55: Epoch 189 :  Loss = 1.71997156124115   ACC = 76.55 Class wise = [90.2 88.3 78.9 69.  74.2 63.7 76.3 72.2 73.1 79.6]\n",
            "TEST TEST  test_dataset: Epoch 189 :  Loss = 1.975506077194214   ACC = 76.31: Epoch 189 :  Loss = 1.975506077194214   ACC = 76.31 Class wise = [89.6 88.3 76.  66.2 76.6 63.7 74.8 70.  75.  82.9]\n",
            "tensor([-0.6175, -0.5076, -0.6640, -0.3585, -0.4364, -0.4148, -0.2429,  0.9434],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 7.0250e-01, -2.3637e-01, -3.2680e-01, -1.6129e-01, -2.0049e-01,\n",
            "        -1.8914e-01, -1.0569e-01, -7.4914e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 189 :  Loss = 0.019783801630383978   ACC = 95.71960922550106\n",
            "TEST TEST  train_dataset: Epoch 190 :  Loss = 0.22268160683569083   ACC = 95.99153993352805: Epoch 190 :  Loss = 0.22268160683569083   ACC = 95.99153993352805 Class wise = [ 95.6         92.70225188  98.60917942  97.79582367  99.6131528\n",
            "  99.35483871 100.          96.3963964  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 190 :  Loss = 1.7635388175964355   ACC = 76.46: Epoch 190 :  Loss = 1.7635388175964355   ACC = 76.46 Class wise = [88.6 88.7 81.7 67.1 77.  61.3 79.9 71.4 71.1 77.8]\n",
            "TEST TEST  test_dataset: Epoch 190 :  Loss = 2.000093939971924   ACC = 76.42999999999999: Epoch 190 :  Loss = 2.000093939971924   ACC = 76.42999999999999 Class wise = [87.8 88.9 78.9 63.  78.5 61.8 80.2 71.1 71.9 82.2]\n",
            "tensor([-0.6224, -0.5112, -0.6697, -0.3607, -0.4397, -0.4184, -0.2441,  0.9411],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 7.0064e-01, -2.3778e-01, -3.2890e-01, -1.6217e-01, -2.0168e-01,\n",
            "        -1.9029e-01, -1.0620e-01, -7.6012e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 190 :  Loss = 0.01819287409567139   ACC = 96.03182596434687\n",
            "TEST TEST  train_dataset: Epoch 191 :  Loss = 0.21430961164927304   ACC = 96.23325611844093: Epoch 191 :  Loss = 0.21430961164927304   ACC = 96.23325611844093 Class wise = [ 95.75        93.16096747  99.02642559  98.60788863  98.64603482\n",
            "  99.35483871 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 191 :  Loss = 1.7417364393234254   ACC = 76.55: Epoch 191 :  Loss = 1.7417364393234254   ACC = 76.55 Class wise = [90.6 91.3 80.5 71.4 70.5 64.4 75.1 72.3 70.6 78.8]\n",
            "TEST TEST  test_dataset: Epoch 191 :  Loss = 1.9835466897964478   ACC = 76.09: Epoch 191 :  Loss = 1.9835466897964478   ACC = 76.09 Class wise = [88.4 89.8 77.3 68.4 72.3 63.4 76.2 70.6 71.9 82.6]\n",
            "tensor([-0.6272, -0.5148, -0.6752, -0.3629, -0.4429, -0.4219, -0.2452,  0.9388],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.9878e-01, -2.3920e-01, -3.3097e-01, -1.6305e-01, -2.0287e-01,\n",
            "        -1.9144e-01, -1.0668e-01, -7.7290e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 191 :  Loss = 0.019471013657947553   ACC = 95.8505388256622\n",
            "TEST TEST  train_dataset: Epoch 192 :  Loss = 0.1977568371623372   ACC = 96.27354214925974: Epoch 192 :  Loss = 0.1977568371623372   ACC = 96.27354214925974 Class wise = [ 95.775       92.9941618   99.37413074  98.37587007  99.22630561\n",
            "  99.35483871 100.          96.3963964  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 192 :  Loss = 1.6944518920898437   ACC = 76.39: Epoch 192 :  Loss = 1.6944518920898437   ACC = 76.39 Class wise = [89.4 90.4 83.9 66.1 72.7 63.  76.8 72.4 72.1 77.1]\n",
            "TEST TEST  test_dataset: Epoch 192 :  Loss = 1.9641018306732179   ACC = 76.34: Epoch 192 :  Loss = 1.9641018306732179   ACC = 76.34 Class wise = [88.5 88.7 82.  63.4 75.1 62.4 77.4 71.  73.5 81.4]\n",
            "tensor([-0.6327, -0.5188, -0.6815, -0.3654, -0.4466, -0.4259, -0.2465,  0.9361],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.9665e-01, -2.4080e-01, -3.3336e-01, -1.6404e-01, -2.0421e-01,\n",
            "        -1.9274e-01, -1.0723e-01, -7.8486e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 192 :  Loss = 0.02037010705444625   ACC = 95.75989525631987\n",
            "TEST TEST  train_dataset: Epoch 193 :  Loss = 0.26178331858240883   ACC = 95.39732097895055: Epoch 193 :  Loss = 0.26178331858240883   ACC = 95.39732097895055 Class wise = [ 95.25        90.45037531  98.60917942  99.07192575  99.41972921\n",
            "  99.35483871 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 193 :  Loss = 1.7382283168315888   ACC = 76.35: Epoch 193 :  Loss = 1.7382283168315888   ACC = 76.35 Class wise = [88.4 89.  79.6 71.7 74.1 60.5 78.4 68.7 72.6 80.5]\n",
            "TEST TEST  test_dataset: Epoch 193 :  Loss = 1.9958209609985351   ACC = 76.25: Epoch 193 :  Loss = 1.9958209609985351   ACC = 76.25 Class wise = [88.  86.8 77.5 69.5 78.  59.6 77.1 68.6 73.8 83.6]\n",
            "tensor([-0.6381, -0.5229, -0.6879, -0.3679, -0.4503, -0.4299, -0.2478,  0.9334],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.9463e-01, -2.4232e-01, -3.3570e-01, -1.6499e-01, -2.0549e-01,\n",
            "        -1.9399e-01, -1.0777e-01, -7.9435e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 193 :  Loss = 0.02141471505331123   ACC = 95.33689193272232\n",
            "TEST TEST  train_dataset: Epoch 194 :  Loss = 0.2811566506464389   ACC = 95.2764628864941: Epoch 194 :  Loss = 0.2811566506464389   ACC = 95.2764628864941 Class wise = [ 94.325       91.65971643  98.53963839  98.83990719  99.6131528\n",
            "  98.70967742 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 194 :  Loss = 1.7210161083221436   ACC = 76.44: Epoch 194 :  Loss = 1.7210161083221436   ACC = 76.44 Class wise = [89.1 88.2 81.4 69.8 73.9 61.6 77.2 69.4 72.9 80.9]\n",
            "TEST TEST  test_dataset: Epoch 194 :  Loss = 1.9980341243743895   ACC = 76.18: Epoch 194 :  Loss = 1.9980341243743895   ACC = 76.18 Class wise = [86.9 88.2 77.7 66.9 76.8 61.3 75.9 69.3 75.  83.8]\n",
            "tensor([-0.6432, -0.5267, -0.6937, -0.3703, -0.4537, -0.4336, -0.2491,  0.9311],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.9268e-01, -2.4375e-01, -3.3792e-01, -1.6587e-01, -2.0670e-01,\n",
            "        -1.9517e-01, -1.0825e-01, -8.0358e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 194 :  Loss = 0.021636903254510922   ACC = 95.45775002517877\n",
            "TEST TEST  train_dataset: Epoch 195 :  Loss = 0.28677034414923586   ACC = 95.28653439419881: Epoch 195 :  Loss = 0.28677034414923586   ACC = 95.28653439419881 Class wise = [ 94.9         91.24270225  98.74826147  97.33178654  98.83945841\n",
            "  99.35483871 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 195 :  Loss = 1.7930536163330077   ACC = 76.27000000000001: Epoch 195 :  Loss = 1.7930536163330077   ACC = 76.27000000000001 Class wise = [88.7 89.  79.9 66.7 71.2 64.1 80.1 72.5 70.5 80. ]\n",
            "TEST TEST  test_dataset: Epoch 195 :  Loss = 2.020222280693054   ACC = 76.49000000000001: Epoch 195 :  Loss = 2.020222280693054   ACC = 76.49000000000001 Class wise = [87.5 87.6 77.4 63.8 73.8 64.5 79.5 72.3 74.  84.5]\n",
            "tensor([-0.6485, -0.5306, -0.6999, -0.3726, -0.4572, -0.4374, -0.2503,  0.9288],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.9050e-01, -2.4538e-01, -3.4044e-01, -1.6688e-01, -2.0807e-01,\n",
            "        -1.9650e-01, -1.0881e-01, -8.1329e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 195 :  Loss = 0.021182628326239555   ACC = 95.36710645583643\n",
            "TEST TEST  train_dataset: Epoch 196 :  Loss = 0.27132551923566667   ACC = 95.39732097895055: Epoch 196 :  Loss = 0.27132551923566667   ACC = 95.39732097895055 Class wise = [ 94.85        91.57631359  98.40055633  98.02784223  99.6131528\n",
            "  99.35483871 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 196 :  Loss = 1.7177900994300843   ACC = 76.44999999999999: Epoch 196 :  Loss = 1.7177900994300843   ACC = 76.44999999999999 Class wise = [89.3 88.1 79.6 68.4 72.4 65.3 78.5 67.8 74.9 80.2]\n",
            "TEST TEST  test_dataset: Epoch 196 :  Loss = 1.9813716136932373   ACC = 76.6: Epoch 196 :  Loss = 1.9813716136932373   ACC = 76.6 Class wise = [88.4 88.  76.8 64.8 75.9 64.8 78.7 68.8 76.5 83.3]\n",
            "tensor([-0.6536, -0.5342, -0.7058, -0.3747, -0.4605, -0.4411, -0.2513,  0.9262],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.8864e-01, -2.4671e-01, -3.4259e-01, -1.6764e-01, -2.0918e-01,\n",
            "        -1.9761e-01, -1.0917e-01, -8.2274e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 196 :  Loss = 0.021528169100036527   ACC = 95.49803605599759\n",
            "TEST TEST  train_dataset: Epoch 197 :  Loss = 0.24564657894425324   ACC = 95.62896565615873: Epoch 197 :  Loss = 0.24564657894425324   ACC = 95.62896565615873 Class wise = [ 95.35        91.74311927  98.26147427  98.72389791  98.83945841\n",
            "  98.70967742 100.          96.3963964  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 197 :  Loss = 1.753294096469879   ACC = 76.86: Epoch 197 :  Loss = 1.753294096469879   ACC = 76.86 Class wise = [89.7 89.7 80.2 70.  73.9 62.9 76.3 74.4 71.7 79.8]\n",
            "TEST TEST  test_dataset: Epoch 197 :  Loss = 2.016356185722351   ACC = 76.49000000000001: Epoch 197 :  Loss = 2.016356185722351   ACC = 76.49000000000001 Class wise = [87.9 88.5 76.8 66.2 77.2 62.4 75.6 74.  73.2 83.1]\n",
            "tensor([-0.6589, -0.5382, -0.7119, -0.3772, -0.4641, -0.4449, -0.2526,  0.9238],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.8651e-01, -2.4834e-01, -3.4498e-01, -1.6867e-01, -2.1056e-01,\n",
            "        -1.9893e-01, -1.0977e-01, -8.3114e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 197 :  Loss = 0.0233655653365676   ACC = 95.08510424010474\n",
            "TEST TEST  train_dataset: Epoch 198 :  Loss = 0.29376819850335933   ACC = 95.05488971699063: Epoch 198 :  Loss = 0.29376819850335933   ACC = 95.05488971699063 Class wise = [ 94.175       91.65971643  98.60917942  97.33178654  99.6131528\n",
            "  98.06451613 100.          93.69369369 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 198 :  Loss = 1.6958183479309081   ACC = 76.67: Epoch 198 :  Loss = 1.6958183479309081   ACC = 76.67 Class wise = [89.5 90.1 81.3 68.7 74.  59.  81.1 67.1 77.1 78.8]\n",
            "TEST TEST  test_dataset: Epoch 198 :  Loss = 1.9928977090835571   ACC = 76.0: Epoch 198 :  Loss = 1.9928977090835571   ACC = 76.0 Class wise = [87.2 88.5 77.8 62.8 76.7 59.7 79.8 65.9 78.  83.6]\n",
            "tensor([-0.6642, -0.5421, -0.7180, -0.3796, -0.4676, -0.4488, -0.2538,  0.9213],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.8435e-01, -2.4997e-01, -3.4739e-01, -1.6966e-01, -2.1192e-01,\n",
            "        -2.0025e-01, -1.1029e-01, -8.4046e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 198 :  Loss = 0.02160337776987199   ACC = 95.18581931715178\n",
            "TEST TEST  train_dataset: Epoch 199 :  Loss = 0.290507814112392   ACC = 95.14553328633296: Epoch 199 :  Loss = 0.290507814112392   ACC = 95.14553328633296 Class wise = [ 94.6         91.53461218  98.05285118  97.5638051   99.22630561\n",
            "  98.38709677 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 199 :  Loss = 1.7118430736541748   ACC = 76.53999999999999: Epoch 199 :  Loss = 1.7118430736541748   ACC = 76.53999999999999 Class wise = [89.  89.2 78.9 67.4 73.3 65.1 79.1 71.2 72.4 79.8]\n",
            "TEST TEST  test_dataset: Epoch 199 :  Loss = 1.9908844278335571   ACC = 76.46: Epoch 199 :  Loss = 1.9908844278335571   ACC = 76.46 Class wise = [87.7 88.4 74.4 64.9 76.4 65.  77.9 70.1 75.3 84.5]\n",
            "tensor([-0.6693, -0.5459, -0.7240, -0.3819, -0.4711, -0.4525, -0.2550,  0.9188],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.8226e-01, -2.5154e-01, -3.4978e-01, -1.7063e-01, -2.1324e-01,\n",
            "        -2.0154e-01, -1.1082e-01, -8.5022e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 199 :  Loss = 0.025267153563009237   ACC = 94.9441031322389\n",
            "TEST TEST  train_dataset: Epoch 200 :  Loss = 0.29183365048915083   ACC = 95.10524725551414: Epoch 200 :  Loss = 0.29183365048915083   ACC = 95.10524725551414 Class wise = [ 93.45        92.70225188  98.19193324  98.37587007  99.6131528\n",
            "  99.35483871 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 200 :  Loss = 1.7212131494522094   ACC = 76.61: Epoch 200 :  Loss = 1.7212131494522094   ACC = 76.61 Class wise = [86.8 90.3 78.6 68.3 76.5 63.6 79.2 70.2 75.5 77.1]\n",
            "TEST TEST  test_dataset: Epoch 200 :  Loss = 1.9691917524337768   ACC = 76.41: Epoch 200 :  Loss = 1.9691917524337768   ACC = 76.41 Class wise = [85.1 88.9 75.4 65.9 77.7 62.4 78.2 69.5 78.7 82.3]\n",
            "tensor([-0.6743, -0.5496, -0.7296, -0.3842, -0.4744, -0.4561, -0.2562,  0.9167],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.8018e-01, -2.5311e-01, -3.5210e-01, -1.7161e-01, -2.1455e-01,\n",
            "        -2.0282e-01, -1.1138e-01, -8.6049e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 200 :  Loss = 0.023048386600846665   ACC = 94.92396011682949\n",
            "TEST TEST  train_dataset: Epoch 201 :  Loss = 0.26605318689192387   ACC = 95.39732097895055: Epoch 201 :  Loss = 0.26605318689192387   ACC = 95.39732097895055 Class wise = [ 94.175       92.66055046  98.40055633  98.25986079  99.41972921\n",
            "  99.35483871 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 201 :  Loss = 1.7604768177986145   ACC = 76.72: Epoch 201 :  Loss = 1.7604768177986145   ACC = 76.72 Class wise = [88.7 90.  80.8 68.6 72.5 62.1 80.8 71.1 74.2 78.4]\n",
            "TEST TEST  test_dataset: Epoch 201 :  Loss = 1.989306017303467   ACC = 76.58: Epoch 201 :  Loss = 1.989306017303467   ACC = 76.58 Class wise = [86.6 88.6 77.3 66.1 75.  62.9 81.  70.3 75.4 82.6]\n",
            "tensor([-0.6791, -0.5531, -0.7352, -0.3863, -0.4776, -0.4595, -0.2574,  0.9146],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.7814e-01, -2.5465e-01, -3.5439e-01, -1.7258e-01, -2.1585e-01,\n",
            "        -2.0407e-01, -1.1195e-01, -8.7007e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 201 :  Loss = 0.02223092647976044   ACC = 94.89374559371538\n",
            "TEST TEST  train_dataset: Epoch 202 :  Loss = 0.38054811191152654   ACC = 94.08802497733912: Epoch 202 :  Loss = 0.38054811191152654   ACC = 94.08802497733912 Class wise = [ 92.825       90.20016681  97.77468707  97.91183295  99.41972921\n",
            "  98.06451613 100.          94.59459459 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 202 :  Loss = 1.7436291290283203   ACC = 76.9: Epoch 202 :  Loss = 1.7436291290283203   ACC = 76.9 Class wise = [87.4 88.6 77.8 67.8 75.6 63.7 78.8 71.4 73.9 84. ]\n",
            "TEST TEST  test_dataset: Epoch 202 :  Loss = 2.0426694190979005   ACC = 76.11: Epoch 202 :  Loss = 2.0426694190979005   ACC = 76.11 Class wise = [85.4 87.1 74.7 63.7 77.8 63.  78.1 69.4 76.  85.9]\n",
            "tensor([-0.6840, -0.5567, -0.7408, -0.3884, -0.4808, -0.4630, -0.2584,  0.9123],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.7606e-01, -2.5621e-01, -3.5671e-01, -1.7353e-01, -2.1716e-01,\n",
            "        -2.0535e-01, -1.1246e-01, -8.7678e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 202 :  Loss = 0.022581923371076777   ACC = 94.9642461476483\n",
            "TEST TEST  train_dataset: Epoch 203 :  Loss = 0.33256488690656116   ACC = 94.53117131634605: Epoch 203 :  Loss = 0.33256488690656116   ACC = 94.53117131634605 Class wise = [ 93.275       90.86738949  98.8178025   97.5638051   98.83945841\n",
            "  98.06451613 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 203 :  Loss = 1.764897540473938   ACC = 76.8: Epoch 203 :  Loss = 1.764897540473938   ACC = 76.8 Class wise = [86.8 88.9 81.3 66.2 73.1 64.8 79.5 71.6 75.3 80.5]\n",
            "TEST TEST  test_dataset: Epoch 203 :  Loss = 2.0076559150695803   ACC = 76.64999999999999: Epoch 203 :  Loss = 2.0076559150695803   ACC = 76.64999999999999 Class wise = [85.7 87.6 79.3 63.4 75.1 62.  80.2 71.6 77.1 84.5]\n",
            "tensor([-0.6884, -0.5598, -0.7459, -0.3903, -0.4836, -0.4661, -0.2593,  0.9103],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.7424e-01, -2.5755e-01, -3.5880e-01, -1.7433e-01, -2.1828e-01,\n",
            "        -2.0645e-01, -1.1289e-01, -8.8878e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 203 :  Loss = 0.023327607965673316   ACC = 94.9541746399436\n",
            "TEST TEST  train_dataset: Epoch 204 :  Loss = 0.291148859713873   ACC = 95.12539027092356: Epoch 204 :  Loss = 0.291148859713873   ACC = 95.12539027092356 Class wise = [ 94.25        91.90992494  98.19193324  97.79582367  99.41972921\n",
            "  98.06451613 100.          94.59459459 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 204 :  Loss = 1.6919110105514525   ACC = 76.66: Epoch 204 :  Loss = 1.6919110105514525   ACC = 76.66 Class wise = [89.6 89.9 80.  70.3 70.9 61.4 80.2 70.4 74.1 79.8]\n",
            "TEST TEST  test_dataset: Epoch 204 :  Loss = 1.981870510482788   ACC = 76.41: Epoch 204 :  Loss = 1.981870510482788   ACC = 76.41 Class wise = [86.8 88.7 76.5 65.7 75.  62.1 79.9 68.9 75.9 84.6]\n",
            "tensor([-0.6929, -0.5631, -0.7513, -0.3922, -0.4865, -0.4693, -0.2601,  0.9086],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.7224e-01, -2.5901e-01, -3.6111e-01, -1.7521e-01, -2.1951e-01,\n",
            "        -2.0766e-01, -1.1334e-01, -8.9628e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 204 :  Loss = 0.023015704350758923   ACC = 94.6419579010978\n",
            "TEST TEST  train_dataset: Epoch 205 :  Loss = 0.3481750768644699   ACC = 94.58152885486957: Epoch 205 :  Loss = 0.3481750768644699   ACC = 94.58152885486957 Class wise = [ 94.05        90.49207673  97.98331015  96.9837587   99.22630561\n",
            "  98.06451613 100.          93.69369369 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 205 :  Loss = 1.7431943824768066   ACC = 76.64999999999999: Epoch 205 :  Loss = 1.7431943824768066   ACC = 76.64999999999999 Class wise = [89.3 89.3 79.5 66.5 74.  62.9 77.8 71.1 75.2 80.9]\n",
            "TEST TEST  test_dataset: Epoch 205 :  Loss = 2.028042957305908   ACC = 76.28: Epoch 205 :  Loss = 2.028042957305908   ACC = 76.28 Class wise = [87.4 87.5 74.8 60.1 78.2 64.  78.8 70.3 76.2 85.5]\n",
            "tensor([-0.6968, -0.5658, -0.7559, -0.3937, -0.4889, -0.4719, -0.2609,  0.9072],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.7045e-01, -2.6030e-01, -3.6323e-01, -1.7596e-01, -2.2059e-01,\n",
            "        -2.0873e-01, -1.1373e-01, -9.0852e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 205 :  Loss = 0.02140055038935379   ACC = 95.16567630174238\n",
            "TEST TEST  train_dataset: Epoch 206 :  Loss = 0.2747315325140258   ACC = 95.2361768556753: Epoch 206 :  Loss = 0.2747315325140258   ACC = 95.2361768556753 Class wise = [ 94.075       92.45204337  97.91376912  98.25986079  99.6131528\n",
            "  99.35483871 100.          94.59459459 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 206 :  Loss = 1.7693142597198486   ACC = 76.33: Epoch 206 :  Loss = 1.7693142597198486   ACC = 76.33 Class wise = [87.8 90.5 78.2 70.1 74.4 63.4 78.5 67.3 75.  78.1]\n",
            "TEST TEST  test_dataset: Epoch 206 :  Loss = 2.0312850914001466   ACC = 76.09: Epoch 206 :  Loss = 2.0312850914001466   ACC = 76.09 Class wise = [86.1 89.2 75.2 67.5 78.8 63.7 78.4 62.8 76.4 82.8]\n",
            "tensor([-0.7013, -0.5691, -0.7612, -0.3956, -0.4918, -0.4751, -0.2618,  0.9052],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.6849e-01, -2.6177e-01, -3.6543e-01, -1.7686e-01, -2.2182e-01,\n",
            "        -2.0993e-01, -1.1421e-01, -9.1692e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 206 :  Loss = 0.022893103941014774   ACC = 94.72252996273542\n",
            "TEST TEST  train_dataset: Epoch 207 :  Loss = 0.333620318062728   ACC = 94.3901702084802: Epoch 207 :  Loss = 0.333620318062728   ACC = 94.3901702084802 Class wise = [ 93.025       90.82568807  98.19193324  98.14385151  98.83945841\n",
            "  98.38709677 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 207 :  Loss = 1.774467347574234   ACC = 76.57000000000001: Epoch 207 :  Loss = 1.774467347574234   ACC = 76.57000000000001 Class wise = [87.  89.  78.4 71.2 70.6 59.8 82.1 71.5 77.3 78.8]\n",
            "TEST TEST  test_dataset: Epoch 207 :  Loss = 2.01309309425354   ACC = 76.63: Epoch 207 :  Loss = 2.01309309425354   ACC = 76.63 Class wise = [84.6 87.3 76.6 67.1 75.  60.7 81.9 71.7 78.5 82.9]\n",
            "tensor([-0.7058, -0.5723, -0.7666, -0.3975, -0.4947, -0.4783, -0.2627,  0.9033],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.6648e-01, -2.6323e-01, -3.6777e-01, -1.7774e-01, -2.2305e-01,\n",
            "        -2.1114e-01, -1.1468e-01, -9.2550e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 207 :  Loss = 0.02439377629717307   ACC = 94.55131433175546\n",
            "TEST TEST  train_dataset: Epoch 208 :  Loss = 0.32771597564509936   ACC = 94.17866854668145: Epoch 208 :  Loss = 0.32771597564509936   ACC = 94.17866854668145 Class wise = [ 92.2         91.61801501  98.26147427  96.86774942  98.83945841\n",
            "  99.35483871 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 208 :  Loss = 1.759993004989624   ACC = 76.27000000000001: Epoch 208 :  Loss = 1.759993004989624   ACC = 76.27000000000001 Class wise = [85.3 89.3 79.7 67.7 72.1 63.3 81.9 69.1 75.6 78.7]\n",
            "TEST TEST  test_dataset: Epoch 208 :  Loss = 1.97412265625   ACC = 76.99000000000001: Epoch 208 :  Loss = 1.97412265625   ACC = 76.99000000000001 Class wise = [83.  88.1 78.2 65.3 74.9 64.9 82.8 71.3 78.  83.4]\n",
            "tensor([-0.7097, -0.5750, -0.7711, -0.3991, -0.4971, -0.4809, -0.2635,  0.9020],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.6466e-01, -2.6456e-01, -3.6987e-01, -1.7854e-01, -2.2417e-01,\n",
            "        -2.1224e-01, -1.1512e-01, -9.3356e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 208 :  Loss = 0.024043588413670172   ACC = 94.48081377782253\n",
            "TEST TEST  train_dataset: Epoch 209 :  Loss = 0.26709602073608857   ACC = 95.22610534797059: Epoch 209 :  Loss = 0.26709602073608857   ACC = 95.22610534797059 Class wise = [ 94.225       93.32777314  96.73157163  97.5638051   98.64603482\n",
            "  99.03225806 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 209 :  Loss = 1.7968400195121765   ACC = 76.88000000000001: Epoch 209 :  Loss = 1.7968400195121765   ACC = 76.88000000000001 Class wise = [87.4 89.9 78.4 71.7 74.5 61.5 83.3 70.7 71.5 79.9]\n",
            "TEST TEST  test_dataset: Epoch 209 :  Loss = 2.050255270195007   ACC = 76.25: Epoch 209 :  Loss = 2.050255270195007   ACC = 76.25 Class wise = [86.  89.2 75.  66.5 74.5 62.1 83.5 69.8 72.7 83.2]\n",
            "tensor([-0.7136, -0.5779, -0.7756, -0.4008, -0.4997, -0.4836, -0.2643,  0.9006],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.6289e-01, -2.6589e-01, -3.7188e-01, -1.7937e-01, -2.2529e-01,\n",
            "        -2.1333e-01, -1.1558e-01, -9.4071e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 209 :  Loss = 0.02339235986842287   ACC = 94.83331654748716\n",
            "TEST TEST  train_dataset: Epoch 210 :  Loss = 0.3460768965219862   ACC = 94.27938362372848: Epoch 210 :  Loss = 0.3460768965219862   ACC = 94.27938362372848 Class wise = [ 93.225       90.57547957  97.63560501  97.44779582  99.22630561\n",
            "  98.06451613 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 210 :  Loss = 1.7438349855422974   ACC = 76.59: Epoch 210 :  Loss = 1.7438349855422974   ACC = 76.59 Class wise = [87.5 87.5 78.6 69.3 73.6 62.7 80.4 70.3 75.8 80.2]\n",
            "TEST TEST  test_dataset: Epoch 210 :  Loss = 2.014528381729126   ACC = 76.51: Epoch 210 :  Loss = 2.014528381729126   ACC = 76.51 Class wise = [85.3 87.5 76.  65.8 76.1 62.  81.5 69.4 77.  84.5]\n",
            "tensor([-0.7181, -0.5812, -0.7809, -0.4027, -0.5026, -0.4869, -0.2652,  0.8986],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.6090e-01, -2.6739e-01, -3.7410e-01, -1.8027e-01, -2.2654e-01,\n",
            "        -2.1455e-01, -1.1605e-01, -9.5024e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 210 :  Loss = 0.025225872043901032   ACC = 94.3901702084802\n",
            "dy tensor([ 0.7187,  0.3311,  0.0731, -0.1869, -0.4656, -0.7753, -1.1307, -1.5561,\n",
            "        -2.0991, -2.8633], device='cuda:0', grad_fn=<MvBackward>)\n",
            "ly tensor([-0.0788, -0.1513, -0.1611, -0.1712, -0.1895, -0.2215, -0.2739, -0.3576,\n",
            "        -0.4936, -0.7276], device='cuda:0', grad_fn=<MvBackward>)\n",
            "TEST TEST  train_dataset: Epoch 211 :  Loss = 0.3886756040495203   ACC = 93.87652331554034: Epoch 211 :  Loss = 0.3886756040495203   ACC = 93.87652331554034 Class wise = [ 92.525       89.90825688  97.35744089  98.60788863  98.83945841\n",
            "  98.06451613 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 211 :  Loss = 1.7503852893829346   ACC = 76.62: Epoch 211 :  Loss = 1.7503852893829346   ACC = 76.62 Class wise = [85.2 87.4 77.2 72.5 71.2 62.2 81.3 71.4 76.3 81.5]\n",
            "TEST TEST  test_dataset: Epoch 211 :  Loss = 2.0338687704086302   ACC = 76.13: Epoch 211 :  Loss = 2.0338687704086302   ACC = 76.13 Class wise = [84.1 86.8 72.8 69.5 73.8 61.7 80.3 69.6 77.8 84.9]\n",
            "tensor([-0.7227, -0.5844, -0.7865, -0.4045, -0.5055, -0.4901, -0.2660,  0.8964],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.5887e-01, -2.6886e-01, -3.7647e-01, -1.8114e-01, -2.2778e-01,\n",
            "        -2.1576e-01, -1.1649e-01, -9.6007e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 211 :  Loss = 0.023305000109611736   ACC = 94.63188639339309\n",
            "TEST TEST  train_dataset: Epoch 212 :  Loss = 0.4409744318549125   ACC = 93.27223285325813: Epoch 212 :  Loss = 0.4409744318549125   ACC = 93.27223285325813 Class wise = [ 91.8         88.99082569  97.07927677  98.14385151  98.83945841\n",
            "  97.74193548 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 212 :  Loss = 1.8040863967895509   ACC = 76.62: Epoch 212 :  Loss = 1.8040863967895509   ACC = 76.62 Class wise = [85.3 86.9 76.8 67.6 73.4 62.  80.9 72.4 78.  82.9]\n",
            "TEST TEST  test_dataset: Epoch 212 :  Loss = 2.073199885559082   ACC = 76.35: Epoch 212 :  Loss = 2.073199885559082   ACC = 76.35 Class wise = [83.2 85.8 73.2 65.4 75.  62.9 81.  72.6 78.7 85.7]\n",
            "tensor([-0.7269, -0.5874, -0.7915, -0.4063, -0.5083, -0.4931, -0.2670,  0.8946],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.5698e-01, -2.7025e-01, -3.7864e-01, -1.8199e-01, -2.2894e-01,\n",
            "        -2.1691e-01, -1.1695e-01, -9.7068e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 212 :  Loss = 0.023269047253963174   ACC = 94.32974116225199\n",
            "TEST TEST  train_dataset: Epoch 213 :  Loss = 0.381212041239206   ACC = 93.97723839258737: Epoch 213 :  Loss = 0.381212041239206   ACC = 93.97723839258737 Class wise = [ 92.6         90.03336113  98.26147427  97.44779582  99.41972921\n",
            "  98.06451613 100.          93.69369369 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 213 :  Loss = 1.748142866897583   ACC = 76.78: Epoch 213 :  Loss = 1.748142866897583   ACC = 76.78 Class wise = [87.7 89.5 80.3 66.7 73.2 62.1 78.6 71.7 77.3 80.7]\n",
            "TEST TEST  test_dataset: Epoch 213 :  Loss = 2.050267420578003   ACC = 76.25: Epoch 213 :  Loss = 2.050267420578003   ACC = 76.25 Class wise = [84.9 86.8 76.2 63.5 76.1 62.6 78.5 69.8 79.7 84.4]\n",
            "tensor([-0.7313, -0.5905, -0.7967, -0.4081, -0.5110, -0.4962, -0.2678,  0.8927],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.5495e-01, -2.7170e-01, -3.8101e-01, -1.8283e-01, -2.3016e-01,\n",
            "        -2.1812e-01, -1.1736e-01, -9.8010e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 213 :  Loss = 0.023272014698877543   ACC = 94.18874005438614\n",
            "TEST TEST  train_dataset: Epoch 214 :  Loss = 0.3418106889713419   ACC = 94.44052774700373: Epoch 214 :  Loss = 0.3418106889713419   ACC = 94.44052774700373 Class wise = [ 92.7         91.99332777  97.70514604  97.33178654  99.03288201\n",
            "  99.35483871 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 214 :  Loss = 1.734950905227661   ACC = 76.99000000000001: Epoch 214 :  Loss = 1.734950905227661   ACC = 76.99000000000001 Class wise = [84.7 90.7 78.2 68.4 74.1 67.1 78.7 71.5 76.9 79.6]\n",
            "TEST TEST  test_dataset: Epoch 214 :  Loss = 2.0141252338409426   ACC = 76.61: Epoch 214 :  Loss = 2.0141252338409426   ACC = 76.61 Class wise = [84.1 88.4 74.4 64.6 75.1 67.4 79.1 70.7 78.3 84. ]\n",
            "tensor([-0.7354, -0.5934, -0.8015, -0.4098, -0.5136, -0.4990, -0.2686,  0.8912],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.5297e-01, -2.7317e-01, -3.8328e-01, -1.8373e-01, -2.3140e-01,\n",
            "        -2.1933e-01, -1.1784e-01, -9.8891e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 214 :  Loss = 0.025730072539151525   ACC = 94.45059925470844\n",
            "TEST TEST  train_dataset: Epoch 215 :  Loss = 0.33031797882368735   ACC = 94.54124282405077: Epoch 215 :  Loss = 0.33031797882368735   ACC = 94.54124282405077 Class wise = [ 93.05        91.78482068  97.84422809  97.5638051   98.83945841\n",
            "  98.70967742 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 215 :  Loss = 1.774103719329834   ACC = 76.9: Epoch 215 :  Loss = 1.774103719329834   ACC = 76.9 Class wise = [87.7 89.8 80.  68.8 71.3 63.1 81.9 70.2 77.3 78.9]\n",
            "TEST TEST  test_dataset: Epoch 215 :  Loss = 2.0376429014205932   ACC = 76.59: Epoch 215 :  Loss = 2.0376429014205932   ACC = 76.59 Class wise = [85.1 88.4 75.8 65.8 74.  63.7 81.5 69.5 78.7 83.4]\n",
            "tensor([-0.7392, -0.5961, -0.8060, -0.4114, -0.5160, -0.5015, -0.2694,  0.8899],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.5108e-01, -2.7456e-01, -3.8543e-01, -1.8458e-01, -2.3257e-01,\n",
            "        -2.2048e-01, -1.1833e-01, -9.9827e-07], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 215 :  Loss = 0.026517903508273485   ACC = 94.20888306979555\n",
            "TEST TEST  train_dataset: Epoch 216 :  Loss = 0.3822916289209388   ACC = 93.94702386947326: Epoch 216 :  Loss = 0.3822916289209388   ACC = 93.94702386947326 Class wise = [ 92.925       89.78315263  97.63560501  97.09976798  98.83945841\n",
            "  99.03225806 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 216 :  Loss = 1.7595320056915282   ACC = 76.64: Epoch 216 :  Loss = 1.7595320056915282   ACC = 76.64 Class wise = [87.3 87.3 76.7 68.3 73.9 66.4 78.8 69.9 75.9 81.9]\n",
            "TEST TEST  test_dataset: Epoch 216 :  Loss = 2.014839804458618   ACC = 76.44: Epoch 216 :  Loss = 2.014839804458618   ACC = 76.44 Class wise = [85.1 86.1 74.5 63.9 75.6 66.3 78.8 71.3 78.5 84.3]\n",
            "tensor([-0.7429, -0.5987, -0.8105, -0.4129, -0.5184, -0.5041, -0.2701,  0.8886],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.4932e-01, -2.7583e-01, -3.8748e-01, -1.8535e-01, -2.3364e-01,\n",
            "        -2.2153e-01, -1.1873e-01, -1.0060e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 216 :  Loss = 0.026924581067993607   ACC = 94.01752442340619\n",
            "TEST TEST  train_dataset: Epoch 217 :  Loss = 0.4236030437224417   ACC = 93.52402054587571: Epoch 217 :  Loss = 0.4236030437224417   ACC = 93.52402054587571 Class wise = [ 92.175       90.24186822  96.94019471  96.63573086  98.06576402\n",
            "  97.74193548 100.          94.59459459 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 217 :  Loss = 1.7884397647857666   ACC = 76.5: Epoch 217 :  Loss = 1.7884397647857666   ACC = 76.5 Class wise = [86.4 88.4 77.3 66.  70.6 63.9 79.9 73.  76.9 82.6]\n",
            "TEST TEST  test_dataset: Epoch 217 :  Loss = 2.09017126789093   ACC = 76.22: Epoch 217 :  Loss = 2.09017126789093   ACC = 76.22 Class wise = [83.6 87.4 73.3 63.1 73.6 64.6 79.9 72.5 78.9 85.3]\n",
            "tensor([-0.7464, -0.6011, -0.8147, -0.4143, -0.5205, -0.5064, -0.2708,  0.8874],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.4756e-01, -2.7712e-01, -3.8951e-01, -1.8613e-01, -2.3473e-01,\n",
            "        -2.2260e-01, -1.1918e-01, -1.0149e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 217 :  Loss = 0.025800776499712717   ACC = 93.80602276160741\n",
            "TEST TEST  train_dataset: Epoch 218 :  Loss = 0.3644451400151713   ACC = 93.96716688488267: Epoch 218 :  Loss = 0.3644451400151713   ACC = 93.96716688488267 Class wise = [ 92.825       91.07589658  96.38386648  96.75174014  98.83945841\n",
            "  97.74193548 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 218 :  Loss = 1.7608422191619872   ACC = 76.46: Epoch 218 :  Loss = 1.7608422191619872   ACC = 76.46 Class wise = [87.1 89.  78.4 67.7 73.4 61.9 82.  70.  75.1 80. ]\n",
            "TEST TEST  test_dataset: Epoch 218 :  Loss = 2.0407621696472167   ACC = 76.39: Epoch 218 :  Loss = 2.0407621696472167   ACC = 76.39 Class wise = [84.  87.7 74.6 63.6 75.9 63.6 83.3 69.6 76.9 84.7]\n",
            "tensor([-0.7502, -0.6037, -0.8192, -0.4157, -0.5228, -0.5089, -0.2714,  0.8863],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.4565e-01, -2.7848e-01, -3.9174e-01, -1.8692e-01, -2.3587e-01,\n",
            "        -2.2374e-01, -1.1956e-01, -1.0256e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 218 :  Loss = 0.025249660667191462   ACC = 94.0477389465203\n",
            "TEST TEST  train_dataset: Epoch 219 :  Loss = 0.36630659467576343   ACC = 93.80602276160741: Epoch 219 :  Loss = 0.36630659467576343   ACC = 93.80602276160741 Class wise = [ 92.225       91.20100083  97.00973574  96.4037123   98.45261122\n",
            "  98.06451613 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 219 :  Loss = 1.782577894973755   ACC = 76.97: Epoch 219 :  Loss = 1.782577894973755   ACC = 76.97 Class wise = [83.8 88.9 79.6 66.4 73.2 63.2 84.  74.2 75.4 81. ]\n",
            "TEST TEST  test_dataset: Epoch 219 :  Loss = 2.0640538871765135   ACC = 76.72: Epoch 219 :  Loss = 2.0640538871765135   ACC = 76.72 Class wise = [82.7 87.3 77.7 61.7 74.6 63.7 83.5 74.4 77.4 84.2]\n",
            "tensor([-0.7542, -0.6065, -0.8239, -0.4171, -0.5252, -0.5116, -0.2720,  0.8847],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.4377e-01, -2.7983e-01, -3.9387e-01, -1.8768e-01, -2.3699e-01,\n",
            "        -2.2485e-01, -1.1991e-01, -1.0341e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 219 :  Loss = 0.02546343151192937   ACC = 94.00745291570148\n",
            "TEST TEST  train_dataset: Epoch 220 :  Loss = 0.3440031283759622   ACC = 94.53117131634605: Epoch 220 :  Loss = 0.3440031283759622   ACC = 94.53117131634605 Class wise = [ 93.725       90.49207673  98.26147427  97.44779582  98.83945841\n",
            "  98.38709677 100.          94.59459459 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 220 :  Loss = 1.7937938426971436   ACC = 76.67: Epoch 220 :  Loss = 1.7937938426971436   ACC = 76.67 Class wise = [88.  88.5 78.3 68.2 73.7 65.  77.2 71.6 74.6 81.6]\n",
            "TEST TEST  test_dataset: Epoch 220 :  Loss = 2.0478746643066406   ACC = 76.22: Epoch 220 :  Loss = 2.0478746643066406   ACC = 76.22 Class wise = [86.  87.5 76.2 63.3 75.5 65.4 76.8 70.6 75.9 85. ]\n",
            "tensor([-0.7578, -0.6090, -0.8282, -0.4185, -0.5274, -0.5140, -0.2724,  0.8837],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.4197e-01, -2.8113e-01, -3.9595e-01, -1.8841e-01, -2.3807e-01,\n",
            "        -2.2593e-01, -1.2024e-01, -1.0424e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 220 :  Loss = 0.024923748781054578   ACC = 94.09809648504381\n",
            "TEST TEST  train_dataset: Epoch 221 :  Loss = 0.3847213882827573   ACC = 94.15852553127203: Epoch 221 :  Loss = 0.3847213882827573   ACC = 94.15852553127203 Class wise = [ 92.875       90.32527106  97.98331015  98.49187935  98.64603482\n",
            "  97.74193548 100.          93.69369369 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 221 :  Loss = 1.805419660949707   ACC = 76.31: Epoch 221 :  Loss = 1.805419660949707   ACC = 76.31 Class wise = [86.9 88.8 78.2 69.6 71.3 64.  75.3 71.5 75.8 81.7]\n",
            "TEST TEST  test_dataset: Epoch 221 :  Loss = 2.081458053779602   ACC = 76.06: Epoch 221 :  Loss = 2.081458053779602   ACC = 76.06 Class wise = [85.  87.6 75.9 66.1 75.1 62.1 75.9 69.9 78.6 84.4]\n",
            "tensor([-0.7614, -0.6115, -0.8324, -0.4199, -0.5296, -0.5164, -0.2731,  0.8826],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.4010e-01, -2.8251e-01, -3.9807e-01, -1.8924e-01, -2.3923e-01,\n",
            "        -2.2706e-01, -1.2070e-01, -1.0513e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 221 :  Loss = 0.026190275017024648   ACC = 94.00745291570148\n",
            "TEST TEST  train_dataset: Epoch 222 :  Loss = 0.4164085531750453   ACC = 93.53409205358042: Epoch 222 :  Loss = 0.4164085531750453   ACC = 93.53409205358042 Class wise = [ 91.9         89.99165972  97.63560501  97.79582367  97.67891683\n",
            "  97.74193548  99.46236559  95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 222 :  Loss = 1.792504474067688   ACC = 76.62: Epoch 222 :  Loss = 1.792504474067688   ACC = 76.62 Class wise = [85.4 89.3 76.3 69.9 71.6 64.5 73.5 75.6 78.6 81.5]\n",
            "TEST TEST  test_dataset: Epoch 222 :  Loss = 2.0581332515716553   ACC = 76.28: Epoch 222 :  Loss = 2.0581332515716553   ACC = 76.28 Class wise = [83.5 87.5 73.1 66.3 73.4 65.4 74.6 73.9 79.7 85.4]\n",
            "tensor([-0.7652, -0.6143, -0.8367, -0.4215, -0.5320, -0.5189, -0.2738,  0.8817],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.3816e-01, -2.8395e-01, -4.0023e-01, -1.9009e-01, -2.4043e-01,\n",
            "        -2.2824e-01, -1.2112e-01, -1.0577e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 222 :  Loss = 0.025311972102870128   ACC = 93.58444959210394\n",
            "TEST TEST  train_dataset: Epoch 223 :  Loss = 0.3531995066994653   ACC = 94.25924060831906: Epoch 223 :  Loss = 0.3531995066994653   ACC = 94.25924060831906 Class wise = [ 92.3         91.8265221   97.91376912  97.33178654  99.03288201\n",
            "  99.03225806 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 223 :  Loss = 1.7572543441772461   ACC = 76.58: Epoch 223 :  Loss = 1.7572543441772461   ACC = 76.58 Class wise = [84.3 89.6 80.2 65.9 72.9 65.1 81.2 69.9 77.  79.7]\n",
            "TEST TEST  test_dataset: Epoch 223 :  Loss = 2.0309248836517333   ACC = 76.55: Epoch 223 :  Loss = 2.0309248836517333   ACC = 76.55 Class wise = [82.7 88.1 77.1 64.5 75.8 65.2 81.1 68.9 79.6 82.5]\n",
            "tensor([-0.7685, -0.6165, -0.8406, -0.4227, -0.5340, -0.5210, -0.2744,  0.8811],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.3636e-01, -2.8526e-01, -4.0231e-01, -1.9087e-01, -2.4153e-01,\n",
            "        -2.2933e-01, -1.2155e-01, -1.0656e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 223 :  Loss = 0.025823591134617584   ACC = 94.10816799274852\n",
            "TEST TEST  train_dataset: Epoch 224 :  Loss = 0.35764850156964373   ACC = 94.3901702084802: Epoch 224 :  Loss = 0.35764850156964373   ACC = 94.3901702084802 Class wise = [ 92.925       91.07589658  98.05285118  98.02784223  99.03288201\n",
            "  98.38709677 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 224 :  Loss = 1.7985866340637207   ACC = 76.22: Epoch 224 :  Loss = 1.7985866340637207   ACC = 76.22 Class wise = [86.5 89.4 77.5 68.4 73.1 62.1 77.7 72.1 75.2 80.2]\n",
            "TEST TEST  test_dataset: Epoch 224 :  Loss = 2.03663095035553   ACC = 76.49000000000001: Epoch 224 :  Loss = 2.03663095035553   ACC = 76.49000000000001 Class wise = [84.7 88.4 75.  65.5 76.1 64.  77.5 71.6 78.  84.1]\n",
            "tensor([-0.7722, -0.6192, -0.8450, -0.4242, -0.5363, -0.5234, -0.2751,  0.8801],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.3435e-01, -2.8673e-01, -4.0459e-01, -1.9177e-01, -2.4277e-01,\n",
            "        -2.3054e-01, -1.2206e-01, -1.0756e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 224 :  Loss = 0.027490291125777506   ACC = 93.63480713062745\n",
            "TEST TEST  train_dataset: Epoch 225 :  Loss = 0.3085217479305662   ACC = 94.73260147044013: Epoch 225 :  Loss = 0.3085217479305662   ACC = 94.73260147044013 Class wise = [ 93.975       91.28440367  97.49652295  97.5638051   98.64603482\n",
            "  98.70967742 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 225 :  Loss = 1.7495949909210204   ACC = 76.84: Epoch 225 :  Loss = 1.7495949909210204   ACC = 76.84 Class wise = [87.9 88.9 78.1 68.1 72.4 64.2 80.  73.6 76.8 78.4]\n",
            "TEST TEST  test_dataset: Epoch 225 :  Loss = 2.027829182434082   ACC = 76.71: Epoch 225 :  Loss = 2.027829182434082   ACC = 76.71 Class wise = [86.9 87.  75.  65.3 74.4 65.1 79.9 72.9 77.3 83.3]\n",
            "tensor([-0.7759, -0.6217, -0.8495, -0.4255, -0.5385, -0.5259, -0.2756,  0.8788],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.3243e-01, -2.8812e-01, -4.0682e-01, -1.9256e-01, -2.4393e-01,\n",
            "        -2.3169e-01, -1.2243e-01, -1.0852e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 225 :  Loss = 0.025529399308592594   ACC = 93.97723839258737\n",
            "TEST TEST  train_dataset: Epoch 226 :  Loss = 0.46778030759527467   ACC = 92.77872897572766: Epoch 226 :  Loss = 0.46778030759527467   ACC = 92.77872897572766 Class wise = [ 91.425       88.90742285  96.52294854  96.63573086  97.09864603\n",
            "  97.74193548 100.          93.69369369 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 226 :  Loss = 1.843651244354248   ACC = 76.49000000000001: Epoch 226 :  Loss = 1.843651244354248   ACC = 76.49000000000001 Class wise = [84.4 87.3 78.1 70.  68.7 63.2 81.6 73.5 76.  82.1]\n",
            "TEST TEST  test_dataset: Epoch 226 :  Loss = 2.1460715602874756   ACC = 76.08: Epoch 226 :  Loss = 2.1460715602874756   ACC = 76.08 Class wise = [82.7 86.  74.3 65.4 69.7 64.3 83.  70.3 78.8 86.3]\n",
            "tensor([-0.7788, -0.6237, -0.8530, -0.4266, -0.5402, -0.5277, -0.2761,  0.8782],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.3079e-01, -2.8928e-01, -4.0872e-01, -1.9325e-01, -2.4490e-01,\n",
            "        -2.3267e-01, -1.2280e-01, -1.0940e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 226 :  Loss = 0.02682374703012852   ACC = 93.77580823849331\n",
            "TEST TEST  train_dataset: Epoch 227 :  Loss = 0.34090346174863567   ACC = 94.3901702084802: Epoch 227 :  Loss = 0.34090346174863567   ACC = 94.3901702084802 Class wise = [ 93.475       90.74228524  97.98331015  96.86774942  98.64603482\n",
            "  98.06451613 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 227 :  Loss = 1.7822427949905395   ACC = 76.78: Epoch 227 :  Loss = 1.7822427949905395   ACC = 76.78 Class wise = [87.8 89.2 79.5 65.8 74.1 65.5 78.4 71.5 76.9 79.1]\n",
            "TEST TEST  test_dataset: Epoch 227 :  Loss = 2.0449166931152343   ACC = 76.68: Epoch 227 :  Loss = 2.0449166931152343   ACC = 76.68 Class wise = [86.5 87.1 75.4 62.4 76.2 66.1 78.7 72.7 78.  83.7]\n",
            "tensor([-0.7822, -0.6261, -0.8570, -0.4280, -0.5423, -0.5300, -0.2767,  0.8774],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.2889e-01, -2.9069e-01, -4.1084e-01, -1.9409e-01, -2.4608e-01,\n",
            "        -2.3382e-01, -1.2325e-01, -1.1020e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 227 :  Loss = 0.029036041775766918   ACC = 93.95709537717796\n",
            "TEST TEST  train_dataset: Epoch 228 :  Loss = 0.3511880745518395   ACC = 94.26931211602377: Epoch 228 :  Loss = 0.3511880745518395   ACC = 94.26931211602377 Class wise = [ 93.05        91.15929942  97.77468707  96.75174014  98.64603482\n",
            "  97.74193548 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 228 :  Loss = 1.8014515535354614   ACC = 76.25: Epoch 228 :  Loss = 1.8014515535354614   ACC = 76.25 Class wise = [86.8 87.8 78.9 64.2 73.1 63.7 80.6 71.2 78.5 77.7]\n",
            "TEST TEST  test_dataset: Epoch 228 :  Loss = 2.056248295402527   ACC = 76.5: Epoch 228 :  Loss = 2.056248295402527   ACC = 76.5 Class wise = [85.5 87.3 77.4 61.9 74.5 64.  81.9 70.4 78.9 83.2]\n",
            "tensor([-0.7853, -0.6282, -0.8606, -0.4291, -0.5441, -0.5319, -0.2772,  0.8766],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.2714e-01, -2.9196e-01, -4.1287e-01, -1.9484e-01, -2.4715e-01,\n",
            "        -2.3487e-01, -1.2364e-01, -1.1102e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 228 :  Loss = 0.026622568367553546   ACC = 93.61466411521805\n",
            "TEST TEST  train_dataset: Epoch 229 :  Loss = 0.360142055827794   ACC = 93.94702386947326: Epoch 229 :  Loss = 0.360142055827794   ACC = 93.94702386947326 Class wise = [ 92.55        91.45120934  96.45340751  96.75174014  98.45261122\n",
            "  98.06451613 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 229 :  Loss = 1.77503362159729   ACC = 76.86: Epoch 229 :  Loss = 1.77503362159729   ACC = 76.86 Class wise = [86.6 89.1 77.8 69.4 71.8 63.  81.8 72.8 77.  79.3]\n",
            "TEST TEST  test_dataset: Epoch 229 :  Loss = 2.048652867126465   ACC = 76.78: Epoch 229 :  Loss = 2.048652867126465   ACC = 76.78 Class wise = [84.1 87.9 74.4 63.8 74.5 64.5 82.7 73.7 79.2 83. ]\n",
            "tensor([-0.7890, -0.6309, -0.8649, -0.4307, -0.5465, -0.5344, -0.2780,  0.8758],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.2496e-01, -2.9365e-01, -4.1526e-01, -1.9593e-01, -2.4857e-01,\n",
            "        -2.3624e-01, -1.2427e-01, -1.1192e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 229 :  Loss = 0.02755637632142454   ACC = 93.23194682243931\n",
            "TEST TEST  train_dataset: Epoch 230 :  Loss = 0.4281696234025404   ACC = 93.25208983784873: Epoch 230 :  Loss = 0.4281696234025404   ACC = 93.25208983784873 Class wise = [ 91.75        90.86738949  95.06258693  96.4037123   98.45261122\n",
            "  98.70967742 100.          93.69369369 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 230 :  Loss = 1.8422114667892455   ACC = 76.61: Epoch 230 :  Loss = 1.8422114667892455   ACC = 76.61 Class wise = [86.2 89.  76.2 66.5 71.9 66.2 82.4 68.7 78.4 80.6]\n",
            "TEST TEST  test_dataset: Epoch 230 :  Loss = 2.1225878835678103   ACC = 76.28: Epoch 230 :  Loss = 2.1225878835678103   ACC = 76.28 Class wise = [83.5 87.2 71.9 63.9 73.6 66.1 83.1 68.9 80.3 84.3]\n",
            "tensor([-0.7923, -0.6332, -0.8688, -0.4319, -0.5485, -0.5365, -0.2785,  0.8749],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.2313e-01, -2.9499e-01, -4.1735e-01, -1.9671e-01, -2.4968e-01,\n",
            "        -2.3734e-01, -1.2467e-01, -1.1284e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 230 :  Loss = 0.02597414326796552   ACC = 93.42330546882869\n",
            "TEST TEST  train_dataset: Epoch 231 :  Loss = 0.4640195874234847   ACC = 93.07080269916406: Epoch 231 :  Loss = 0.4640195874234847   ACC = 93.07080269916406 Class wise = [ 91.15        90.07506255  96.80111266  96.17169374  99.03288201\n",
            "  97.74193548 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 231 :  Loss = 1.8455124767303466   ACC = 77.05: Epoch 231 :  Loss = 1.8455124767303466   ACC = 77.05 Class wise = [84.  87.5 78.8 65.  74.5 66.5 82.  71.1 79.8 81.3]\n",
            "TEST TEST  test_dataset: Epoch 231 :  Loss = 2.1088755918502806   ACC = 76.53: Epoch 231 :  Loss = 2.1088755918502806   ACC = 76.53 Class wise = [81.7 86.9 75.1 60.9 77.5 65.3 82.7 70.4 80.8 84. ]\n",
            "tensor([-0.7951, -0.6352, -0.8720, -0.4331, -0.5502, -0.5382, -0.2791,  0.8748],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.2131e-01, -2.9633e-01, -4.1941e-01, -1.9752e-01, -2.5081e-01,\n",
            "        -2.3844e-01, -1.2513e-01, -1.1374e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 231 :  Loss = 0.0275684916333185   ACC = 93.70530768456038\n",
            "TEST TEST  train_dataset: Epoch 232 :  Loss = 0.43669747967484607   ACC = 93.42330546882869: Epoch 232 :  Loss = 0.43669747967484607   ACC = 93.42330546882869 Class wise = [ 91.825       90.28356964  98.12239221  94.77958237  98.25918762\n",
            "  97.74193548 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 232 :  Loss = 1.7679412510871888   ACC = 76.72: Epoch 232 :  Loss = 1.7679412510871888   ACC = 76.72 Class wise = [86.4 87.5 79.5 63.  70.2 66.9 80.4 72.6 79.  81.7]\n",
            "TEST TEST  test_dataset: Epoch 232 :  Loss = 2.084534234046936   ACC = 76.38000000000001: Epoch 232 :  Loss = 2.084534234046936   ACC = 76.38000000000001 Class wise = [83.3 87.1 78.2 58.7 73.5 65.7 80.3 71.9 81.3 83.8]\n",
            "tensor([-0.7981, -0.6373, -0.8756, -0.4342, -0.5520, -0.5402, -0.2795,  0.8740],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.1962e-01, -2.9755e-01, -4.2135e-01, -1.9824e-01, -2.5183e-01,\n",
            "        -2.3945e-01, -1.2549e-01, -1.1432e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 232 :  Loss = 0.029305689987584968   ACC = 93.1614462685064\n",
            "TEST TEST  train_dataset: Epoch 233 :  Loss = 0.357204599655503   ACC = 93.81609426931212: Epoch 233 :  Loss = 0.357204599655503   ACC = 93.81609426931212 Class wise = [ 92.125       91.8265221   96.03616134  96.75174014  98.83945841\n",
            "  97.74193548 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 233 :  Loss = 1.7925891674041747   ACC = 76.55: Epoch 233 :  Loss = 1.7925891674041747   ACC = 76.55 Class wise = [85.5 88.  76.3 68.5 74.9 62.5 81.5 72.7 78.1 77.5]\n",
            "TEST TEST  test_dataset: Epoch 233 :  Loss = 2.0576518877029417   ACC = 76.69: Epoch 233 :  Loss = 2.0576518877029417   ACC = 76.69 Class wise = [83.4 87.9 73.1 65.1 77.3 64.2 81.9 72.4 79.9 81.7]\n",
            "tensor([-0.8014, -0.6395, -0.8794, -0.4354, -0.5539, -0.5422, -0.2802,  0.8733],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.1773e-01, -2.9892e-01, -4.2350e-01, -1.9907e-01, -2.5299e-01,\n",
            "        -2.4059e-01, -1.2596e-01, -1.1528e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 233 :  Loss = 0.0277419680918887   ACC = 93.50387753046631\n",
            "TEST TEST  train_dataset: Epoch 234 :  Loss = 0.39717800628786154   ACC = 93.39309094571458: Epoch 234 :  Loss = 0.39717800628786154   ACC = 93.39309094571458 Class wise = [ 91.85        90.28356964  96.31432545  96.75174014  98.64603482\n",
            "  98.70967742 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 234 :  Loss = 1.785575050354004   ACC = 76.95: Epoch 234 :  Loss = 1.785575050354004   ACC = 76.95 Class wise = [86.2 88.1 78.  65.4 73.1 65.4 82.9 73.4 77.  80. ]\n",
            "TEST TEST  test_dataset: Epoch 234 :  Loss = 2.0697566324234007   ACC = 76.74: Epoch 234 :  Loss = 2.0697566324234007   ACC = 76.74 Class wise = [82.9 86.8 74.5 64.  74.9 66.5 82.7 72.5 78.7 83.9]\n",
            "tensor([-0.8049, -0.6421, -0.8836, -0.4369, -0.5561, -0.5446, -0.2808,  0.8723],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.1568e-01, -3.0046e-01, -4.2579e-01, -2.0000e-01, -2.5427e-01,\n",
            "        -2.4185e-01, -1.2645e-01, -1.1635e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 234 :  Loss = 0.029476728166224393   ACC = 93.20173229932522\n",
            "TEST TEST  train_dataset: Epoch 235 :  Loss = 0.4213619920887507   ACC = 93.24201833014402: Epoch 235 :  Loss = 0.4213619920887507   ACC = 93.24201833014402 Class wise = [ 91.225       91.78482068  95.20166898  96.4037123   97.87234043\n",
            "  97.74193548 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 235 :  Loss = 1.8454362539291382   ACC = 76.98: Epoch 235 :  Loss = 1.8454362539291382   ACC = 76.98 Class wise = [85.7 89.5 76.6 67.1 71.8 64.6 83.6 73.  77.9 80. ]\n",
            "TEST TEST  test_dataset: Epoch 235 :  Loss = 2.1445453544616697   ACC = 76.4: Epoch 235 :  Loss = 2.1445453544616697   ACC = 76.4 Class wise = [81.5 87.8 73.3 63.  72.7 65.8 84.4 72.  79.4 84.1]\n",
            "tensor([-0.8083, -0.6444, -0.8875, -0.4381, -0.5581, -0.5467, -0.2813,  0.8716],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.1379e-01, -3.0182e-01, -4.2796e-01, -2.0079e-01, -2.5541e-01,\n",
            "        -2.4298e-01, -1.2686e-01, -1.1713e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 235 :  Loss = 0.02644657102902258   ACC = 93.4333769765334\n",
            "TEST TEST  train_dataset: Epoch 236 :  Loss = 0.43159998509039005   ACC = 93.29237586866755: Epoch 236 :  Loss = 0.43159998509039005   ACC = 93.29237586866755 Class wise = [ 91.525       89.99165972  97.49652295  96.28770302  98.45261122\n",
            "  98.06451613 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 236 :  Loss = 1.7918391464233399   ACC = 77.09: Epoch 236 :  Loss = 1.7918391464233399   ACC = 77.09 Class wise = [84.6 87.6 77.1 66.2 74.4 64.1 81.5 73.2 80.8 81.4]\n",
            "TEST TEST  test_dataset: Epoch 236 :  Loss = 2.1008433555603028   ACC = 76.73: Epoch 236 :  Loss = 2.1008433555603028   ACC = 76.73 Class wise = [82.3 86.7 75.8 62.5 76.  64.8 81.1 74.3 80.  83.8]\n",
            "tensor([-0.8111, -0.6463, -0.8909, -0.4391, -0.5597, -0.5485, -0.2818,  0.8711],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.1209e-01, -3.0302e-01, -4.2994e-01, -2.0151e-01, -2.5643e-01,\n",
            "        -2.4399e-01, -1.2726e-01, -1.1781e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 236 :  Loss = 0.029880765257280378   ACC = 93.24201833014402\n",
            "TEST TEST  train_dataset: Epoch 237 :  Loss = 0.44721023450232583   ACC = 92.99023063752644: Epoch 237 :  Loss = 0.44721023450232583   ACC = 92.99023063752644 Class wise = [ 91.475       89.99165972  96.45340751  95.47563805  97.67891683\n",
            "  97.74193548 100.          94.59459459 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 237 :  Loss = 1.8838202331542968   ACC = 76.69: Epoch 237 :  Loss = 1.8838202331542968   ACC = 76.69 Class wise = [85.2 87.5 77.  66.4 70.6 67.3 81.4 73.8 74.6 83.1]\n",
            "TEST TEST  test_dataset: Epoch 237 :  Loss = 2.176876864051819   ACC = 76.51: Epoch 237 :  Loss = 2.176876864051819   ACC = 76.51 Class wise = [82.9 86.7 74.1 62.1 72.3 67.2 82.4 73.9 77.5 86. ]\n",
            "tensor([-0.8137, -0.6481, -0.8941, -0.4401, -0.5613, -0.5500, -0.2822,  0.8712],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.1023e-01, -3.0440e-01, -4.3206e-01, -2.0237e-01, -2.5759e-01,\n",
            "        -2.4512e-01, -1.2775e-01, -1.1881e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 237 :  Loss = 0.026952181383254534   ACC = 93.24201833014402\n",
            "TEST TEST  train_dataset: Epoch 238 :  Loss = 0.37881961908067663   ACC = 93.87652331554034: Epoch 238 :  Loss = 0.37881961908067663   ACC = 93.87652331554034 Class wise = [ 92.65        90.82568807  96.6620306   96.75174014  98.64603482\n",
            "  98.06451613 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 238 :  Loss = 1.8105019481658935   ACC = 76.77000000000001: Epoch 238 :  Loss = 1.8105019481658935   ACC = 76.77000000000001 Class wise = [86.1 87.9 78.2 66.9 72.3 64.2 83.2 72.8 77.5 78.6]\n",
            "TEST TEST  test_dataset: Epoch 238 :  Loss = 2.094124620819092   ACC = 76.69: Epoch 238 :  Loss = 2.094124620819092   ACC = 76.69 Class wise = [83.9 87.1 75.9 63.3 74.6 64.2 83.6 71.7 79.5 83.1]\n",
            "tensor([-0.8165, -0.6499, -0.8974, -0.4410, -0.5628, -0.5516, -0.2826,  0.8710],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.0846e-01, -3.0566e-01, -4.3411e-01, -2.0309e-01, -2.5864e-01,\n",
            "        -2.4617e-01, -1.2810e-01, -1.1974e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 238 :  Loss = 0.0277645085973074   ACC = 93.38301943800987\n",
            "TEST TEST  train_dataset: Epoch 239 :  Loss = 0.395186612635376   ACC = 93.76573673078859: Epoch 239 :  Loss = 0.395186612635376   ACC = 93.76573673078859 Class wise = [ 92.1         90.57547957  97.07927677  97.5638051   99.6131528\n",
            "  98.38709677 100.          93.69369369 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 239 :  Loss = 1.8143379360198975   ACC = 77.22: Epoch 239 :  Loss = 1.8143379360198975   ACC = 77.22 Class wise = [86.3 88.7 78.9 69.5 75.7 63.5 81.6 68.4 78.9 80.7]\n",
            "TEST TEST  test_dataset: Epoch 239 :  Loss = 2.094132657814026   ACC = 76.29: Epoch 239 :  Loss = 2.094132657814026   ACC = 76.29 Class wise = [83.2 87.  74.4 66.5 77.3 63.9 81.4 65.4 80.5 83.3]\n",
            "tensor([-0.8197, -0.6521, -0.9011, -0.4423, -0.5647, -0.5536, -0.2831,  0.8707],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.0646e-01, -3.0713e-01, -4.3637e-01, -2.0395e-01, -2.5987e-01,\n",
            "        -2.4738e-01, -1.2854e-01, -1.2067e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 239 :  Loss = 0.028695694612212885   ACC = 93.1513747608017\n",
            "TEST TEST  train_dataset: Epoch 240 :  Loss = 0.3712302592184722   ACC = 94.19881156209084: Epoch 240 :  Loss = 0.3712302592184722   ACC = 94.19881156209084 Class wise = [ 92.3         91.90992494  97.77468707  97.33178654  98.64603482\n",
            "  97.74193548 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 240 :  Loss = 1.7816754568099975   ACC = 76.83: Epoch 240 :  Loss = 1.7816754568099975   ACC = 76.83 Class wise = [85.6 90.2 79.  66.6 73.2 63.8 78.6 74.3 77.4 79.6]\n",
            "TEST TEST  test_dataset: Epoch 240 :  Loss = 2.0809931440353395   ACC = 76.47: Epoch 240 :  Loss = 2.0809931440353395   ACC = 76.47 Class wise = [82.5 88.3 76.  63.2 76.7 64.3 78.8 72.2 79.6 83.1]\n",
            "tensor([-0.8229, -0.6543, -0.9049, -0.4434, -0.5666, -0.5557, -0.2835,  0.8698],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.0463e-01, -3.0844e-01, -4.3843e-01, -2.0469e-01, -2.6096e-01,\n",
            "        -2.4847e-01, -1.2889e-01, -1.2129e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 240 :  Loss = 0.029429050493542313   ACC = 92.93987309900292\n",
            "dy tensor([ 0.6678,  0.2223, -0.0728, -0.3692, -0.6862, -1.0374, -1.4394, -1.9186,\n",
            "        -2.5267, -3.3758], device='cuda:0', grad_fn=<MvBackward>)\n",
            "ly tensor([-0.0910, -0.1941, -0.2238, -0.2535, -0.2924, -0.3470, -0.4249, -0.5383,\n",
            "        -0.7109, -0.9940], device='cuda:0', grad_fn=<MvBackward>)\n",
            "TEST TEST  train_dataset: Epoch 241 :  Loss = 0.44408029277181116   ACC = 93.28230436096283: Epoch 241 :  Loss = 0.44408029277181116   ACC = 93.28230436096283 Class wise = [ 92.5         89.90825688  95.20166898  96.28770302  98.06576402\n",
            "  97.74193548 100.          93.69369369 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 241 :  Loss = 1.8360505207061768   ACC = 76.48: Epoch 241 :  Loss = 1.8360505207061768   ACC = 76.48 Class wise = [85.1 87.2 75.2 66.  71.5 64.2 83.7 71.8 78.  82.1]\n",
            "TEST TEST  test_dataset: Epoch 241 :  Loss = 2.158534366607666   ACC = 76.49000000000001: Epoch 241 :  Loss = 2.158534366607666   ACC = 76.49000000000001 Class wise = [84.1 86.8 71.2 61.7 75.4 65.1 83.8 71.8 79.6 85.4]\n",
            "tensor([-0.8259, -0.6563, -0.9084, -0.4445, -0.5683, -0.5575, -0.2840,  0.8691],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.0279e-01, -3.0978e-01, -4.4051e-01, -2.0551e-01, -2.6209e-01,\n",
            "        -2.4958e-01, -1.2937e-01, -1.2212e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 241 :  Loss = 0.029283617110167855   ACC = 92.93987309900292\n",
            "TEST TEST  train_dataset: Epoch 242 :  Loss = 0.48129154424322884   ACC = 92.75858596031826: Epoch 242 :  Loss = 0.48129154424322884   ACC = 92.75858596031826 Class wise = [ 91.5         89.28273561  96.45340751  94.19953596  98.64603482\n",
            "  97.74193548 100.          93.69369369 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 242 :  Loss = 1.8429924560546875   ACC = 76.42999999999999: Epoch 242 :  Loss = 1.8429924560546875   ACC = 76.42999999999999 Class wise = [85.3 87.9 76.7 59.4 74.7 64.  83.6 71.8 78.3 82.6]\n",
            "TEST TEST  test_dataset: Epoch 242 :  Loss = 2.160060319328308   ACC = 76.38000000000001: Epoch 242 :  Loss = 2.160060319328308   ACC = 76.38000000000001 Class wise = [82.5 86.6 75.2 56.4 78.1 64.5 83.1 72.4 79.8 85.2]\n",
            "tensor([-0.8289, -0.6584, -0.9120, -0.4456, -0.5701, -0.5594, -0.2845,  0.8685],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 6.0086e-01, -3.1118e-01, -4.4270e-01, -2.0635e-01, -2.6327e-01,\n",
            "        -2.5074e-01, -1.2981e-01, -1.2301e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 242 :  Loss = 0.02924144906013895   ACC = 93.20173229932522\n",
            "TEST TEST  train_dataset: Epoch 243 :  Loss = 0.4495236780367714   ACC = 93.23194682243931: Epoch 243 :  Loss = 0.4495236780367714   ACC = 93.23194682243931 Class wise = [ 92.15        89.4912427   97.21835883  95.12761021  97.87234043\n",
            "  97.74193548 100.          94.59459459 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 243 :  Loss = 1.845879479598999   ACC = 76.74: Epoch 243 :  Loss = 1.845879479598999   ACC = 76.74 Class wise = [85.7 87.6 78.9 64.  72.  64.1 82.2 72.8 77.4 82.7]\n",
            "TEST TEST  test_dataset: Epoch 243 :  Loss = 2.1476407859802245   ACC = 76.42: Epoch 243 :  Loss = 2.1476407859802245   ACC = 76.42 Class wise = [83.4 86.4 76.4 60.  73.5 64.8 83.  72.4 78.5 85.8]\n",
            "tensor([-0.8310, -0.6598, -0.9145, -0.4464, -0.5713, -0.5606, -0.2849,  0.8687],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.9925e-01, -3.1235e-01, -4.4456e-01, -2.0706e-01, -2.6425e-01,\n",
            "        -2.5171e-01, -1.3022e-01, -1.2374e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 243 :  Loss = 0.02952927480439475   ACC = 92.84922952966059\n",
            "TEST TEST  train_dataset: Epoch 244 :  Loss = 0.5998997711925451   ACC = 91.52986202034444: Epoch 244 :  Loss = 0.5998997711925451   ACC = 91.52986202034444 Class wise = [ 90.125       87.11426188  94.64534075  96.28770302  97.29206963\n",
            "  97.74193548 100.          93.69369369 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 244 :  Loss = 1.8657541730880738   ACC = 76.64: Epoch 244 :  Loss = 1.8657541730880738   ACC = 76.64 Class wise = [83.7 86.1 74.3 67.4 71.6 64.2 81.9 73.7 80.3 83.2]\n",
            "TEST TEST  test_dataset: Epoch 244 :  Loss = 2.22019538230896   ACC = 76.14999999999999: Epoch 244 :  Loss = 2.22019538230896   ACC = 76.14999999999999 Class wise = [80.4 84.8 70.3 63.5 73.3 65.8 82.1 73.3 81.3 86.7]\n",
            "tensor([-0.8334, -0.6615, -0.9173, -0.4472, -0.5726, -0.5620, -0.2852,  0.8688],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.9760e-01, -3.1353e-01, -4.4645e-01, -2.0775e-01, -2.6524e-01,\n",
            "        -2.5269e-01, -1.3058e-01, -1.2447e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 244 :  Loss = 0.028585385338337908   ACC = 93.1815892839158\n",
            "TEST TEST  train_dataset: Epoch 245 :  Loss = 0.4512893976972913   ACC = 93.29237586866755: Epoch 245 :  Loss = 0.4512893976972913   ACC = 93.29237586866755 Class wise = [ 91.825       90.36697248  96.24478442  96.4037123   98.25918762\n",
            "  97.74193548 100.          93.69369369 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 245 :  Loss = 1.865343987941742   ACC = 76.46: Epoch 245 :  Loss = 1.865343987941742   ACC = 76.46 Class wise = [84.4 89.1 76.1 66.2 72.5 62.9 83.2 70.2 79.8 80.2]\n",
            "TEST TEST  test_dataset: Epoch 245 :  Loss = 2.1686700569152833   ACC = 75.99000000000001: Epoch 245 :  Loss = 2.1686700569152833   ACC = 75.99000000000001 Class wise = [82.7 86.6 73.1 63.1 72.4 64.7 82.4 70.  81.3 83.6]\n",
            "tensor([-0.8359, -0.6632, -0.9203, -0.4482, -0.5741, -0.5635, -0.2856,  0.8687],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.9583e-01, -3.1485e-01, -4.4845e-01, -2.0858e-01, -2.6636e-01,\n",
            "        -2.5378e-01, -1.3107e-01, -1.2520e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 245 :  Loss = 0.030633471708833685   ACC = 92.8391580219559\n",
            "TEST TEST  train_dataset: Epoch 246 :  Loss = 0.49399226121883844   ACC = 92.63772786786181: Epoch 246 :  Loss = 0.49399226121883844   ACC = 92.63772786786181 Class wise = [ 90.475       90.20016681  96.24478442  95.35962877  98.25918762\n",
            "  97.74193548 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 246 :  Loss = 1.8601641304016114   ACC = 76.85: Epoch 246 :  Loss = 1.8601641304016114   ACC = 76.85 Class wise = [82.6 88.2 78.1 66.  72.  65.2 83.3 72.9 79.1 81.1]\n",
            "TEST TEST  test_dataset: Epoch 246 :  Loss = 2.16333447265625   ACC = 76.53: Epoch 246 :  Loss = 2.16333447265625   ACC = 76.53 Class wise = [80.5 86.5 75.  60.7 74.7 65.8 83.8 73.2 80.7 84.4]\n",
            "tensor([-0.8387, -0.6649, -0.9237, -0.4490, -0.5756, -0.5651, -0.2859,  0.8681],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.9412e-01, -3.1602e-01, -4.5048e-01, -2.0924e-01, -2.6734e-01,\n",
            "        -2.5477e-01, -1.3140e-01, -1.2611e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 246 :  Loss = 0.029184314561036973   ACC = 93.05065968375466\n",
            "TEST TEST  train_dataset: Epoch 247 :  Loss = 0.4762120027762272   ACC = 92.80894349884178: Epoch 247 :  Loss = 0.4762120027762272   ACC = 92.80894349884178 Class wise = [ 91.8         89.19933278  94.85396384  96.63573086  97.67891683\n",
            "  97.74193548 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 247 :  Loss = 1.9105386673927307   ACC = 76.33: Epoch 247 :  Loss = 1.9105386673927307   ACC = 76.33 Class wise = [84.9 86.9 75.6 66.3 69.7 63.5 80.6 75.4 78.2 82.2]\n",
            "TEST TEST  test_dataset: Epoch 247 :  Loss = 2.2283888259887696   ACC = 76.44: Epoch 247 :  Loss = 2.2283888259887696   ACC = 76.44 Class wise = [82.4 86.1 72.3 64.8 73.3 64.8 82.2 74.5 78.2 85.8]\n",
            "tensor([-0.8414, -0.6667, -0.9270, -0.4499, -0.5771, -0.5668, -0.2863,  0.8676],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.9242e-01, -3.1724e-01, -4.5244e-01, -2.0995e-01, -2.6837e-01,\n",
            "        -2.5579e-01, -1.3177e-01, -1.2679e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 247 :  Loss = 0.030105508591911082   ACC = 93.02044516064055\n",
            "TEST TEST  train_dataset: Epoch 248 :  Loss = 0.48641975971484575   ACC = 92.55715580622419: Epoch 248 :  Loss = 0.48641975971484575   ACC = 92.55715580622419 Class wise = [ 91.375       89.69974979  94.92350487  94.77958237  97.09864603\n",
            "  97.74193548 100.          93.69369369 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 248 :  Loss = 1.8677164241790771   ACC = 76.25: Epoch 248 :  Loss = 1.8677164241790771   ACC = 76.25 Class wise = [83.7 88.5 75.5 65.3 69.1 64.8 84.1 75.  73.7 82.8]\n",
            "TEST TEST  test_dataset: Epoch 248 :  Loss = 2.2286225257873533   ACC = 76.11: Epoch 248 :  Loss = 2.2286225257873533   ACC = 76.11 Class wise = [82.9 86.4 73.5 60.7 73.  64.4 83.5 73.9 76.9 85.9]\n",
            "tensor([-0.8440, -0.6684, -0.9302, -0.4508, -0.5786, -0.5684, -0.2867,  0.8673],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.9061e-01, -3.1852e-01, -4.5453e-01, -2.1068e-01, -2.6944e-01,\n",
            "        -2.5686e-01, -1.3214e-01, -1.2747e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 248 :  Loss = 0.03039423573448142   ACC = 92.86937254507\n",
            "TEST TEST  train_dataset: Epoch 249 :  Loss = 0.47432586373608054   ACC = 92.86937254507: Epoch 249 :  Loss = 0.47432586373608054   ACC = 92.86937254507 Class wise = [ 91.75        89.07422852  96.17524339  95.59164733  98.06576402\n",
            "  97.74193548 100.          94.59459459 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 249 :  Loss = 1.8990706413269043   ACC = 76.9: Epoch 249 :  Loss = 1.8990706413269043   ACC = 76.9 Class wise = [84.2 86.8 78.1 65.5 72.7 67.7 82.2 72.7 77.6 81.5]\n",
            "TEST TEST  test_dataset: Epoch 249 :  Loss = 2.199828024673462   ACC = 76.49000000000001: Epoch 249 :  Loss = 2.199828024673462   ACC = 76.49000000000001 Class wise = [82.3 86.  74.5 62.1 73.3 66.8 83.1 72.3 78.7 85.8]\n",
            "tensor([-0.8462, -0.6697, -0.9331, -0.4514, -0.5797, -0.5696, -0.2868,  0.8672],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.8907e-01, -3.1952e-01, -4.5643e-01, -2.1121e-01, -2.7028e-01,\n",
            "        -2.5773e-01, -1.3238e-01, -1.2830e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 249 :  Loss = 0.02816754852040808   ACC = 93.28230436096283\n",
            "TEST TEST  train_dataset: Epoch 250 :  Loss = 0.4451755722572311   ACC = 93.20173229932522: Epoch 250 :  Loss = 0.4451755722572311   ACC = 93.20173229932522 Class wise = [ 91.175       91.15929942  97.00973574  94.89559165  97.87234043\n",
            "  97.74193548 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 250 :  Loss = 1.8271925319671631   ACC = 77.22: Epoch 250 :  Loss = 1.8271925319671631   ACC = 77.22 Class wise = [84.5 89.7 78.3 64.1 71.2 67.1 84.2 73.7 80.7 78.7]\n",
            "TEST TEST  test_dataset: Epoch 250 :  Loss = 2.113954363822937   ACC = 76.44: Epoch 250 :  Loss = 2.113954363822937   ACC = 76.44 Class wise = [81.9 87.3 76.1 59.6 73.4 66.2 82.6 72.  82.5 82.8]\n",
            "tensor([-0.8484, -0.6711, -0.9359, -0.4521, -0.5809, -0.5708, -0.2871,  0.8673],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.8744e-01, -3.2064e-01, -4.5835e-01, -2.1184e-01, -2.7122e-01,\n",
            "        -2.5868e-01, -1.3267e-01, -1.2919e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 250 :  Loss = 0.02952268678176822   ACC = 93.04058817604995\n",
            "TEST TEST  train_dataset: Epoch 251 :  Loss = 0.4125114341216752   ACC = 93.60459260751335: Epoch 251 :  Loss = 0.4125114341216752   ACC = 93.60459260751335 Class wise = [ 92.175       90.86738949  96.03616134  97.33178654  98.06576402\n",
            "  97.41935484 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 251 :  Loss = 1.8626977760314942   ACC = 76.48: Epoch 251 :  Loss = 1.8626977760314942   ACC = 76.48 Class wise = [86.1 87.9 73.7 69.8 70.8 62.7 81.6 73.9 78.3 80. ]\n",
            "TEST TEST  test_dataset: Epoch 251 :  Loss = 2.1637219173431395   ACC = 76.44: Epoch 251 :  Loss = 2.1637219173431395   ACC = 76.44 Class wise = [83.5 87.3 72.9 65.1 73.  63.3 82.6 73.7 79.6 83.4]\n",
            "tensor([-0.8509, -0.6727, -0.9387, -0.4529, -0.5822, -0.5722, -0.2874,  0.8673],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.8570e-01, -3.2192e-01, -4.6030e-01, -2.1259e-01, -2.7229e-01,\n",
            "        -2.5973e-01, -1.3306e-01, -1.3013e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 251 :  Loss = 0.028811729696296664   ACC = 92.93987309900292\n",
            "TEST TEST  train_dataset: Epoch 252 :  Loss = 0.42052029897112736   ACC = 93.48373451505691: Epoch 252 :  Loss = 0.42052029897112736   ACC = 93.48373451505691 Class wise = [ 91.375       91.78482068  96.10570236  96.51972158  98.64603482\n",
            "  97.74193548 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 252 :  Loss = 1.8615324954986572   ACC = 76.49000000000001: Epoch 252 :  Loss = 1.8615324954986572   ACC = 76.49000000000001 Class wise = [83.3 89.  75.4 66.3 73.4 64.9 82.8 71.9 79.1 78.8]\n",
            "TEST TEST  test_dataset: Epoch 252 :  Loss = 2.1317581171035767   ACC = 76.55: Epoch 252 :  Loss = 2.1317581171035767   ACC = 76.55 Class wise = [81.2 87.9 74.1 62.4 76.5 65.3 82.9 71.6 81.5 82.1]\n",
            "tensor([-0.8532, -0.6742, -0.9415, -0.4535, -0.5834, -0.5735, -0.2876,  0.8672],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.8410e-01, -3.2301e-01, -4.6218e-01, -2.1319e-01, -2.7321e-01,\n",
            "        -2.6066e-01, -1.3334e-01, -1.3098e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 252 :  Loss = 0.028759139750266508   ACC = 92.9197300835935\n",
            "TEST TEST  train_dataset: Epoch 253 :  Loss = 0.4702166455374217   ACC = 93.11108872998288: Epoch 253 :  Loss = 0.4702166455374217   ACC = 93.11108872998288 Class wise = [ 92.075       88.94912427  96.94019471  96.28770302  97.67891683\n",
            "  97.41935484 100.          94.59459459 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 253 :  Loss = 1.9184504390716552   ACC = 76.35: Epoch 253 :  Loss = 1.9184504390716552   ACC = 76.35 Class wise = [86.7 86.1 78.  65.3 69.8 61.5 81.9 75.3 78.4 80.5]\n",
            "TEST TEST  test_dataset: Epoch 253 :  Loss = 2.2232599674224853   ACC = 76.16000000000001: Epoch 253 :  Loss = 2.2232599674224853   ACC = 76.16000000000001 Class wise = [83.5 85.1 74.8 61.7 73.1 62.9 82.6 73.7 80.5 83.7]\n",
            "tensor([-0.8556, -0.6758, -0.9444, -0.4544, -0.5848, -0.5749, -0.2880,  0.8670],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.8242e-01, -3.2423e-01, -4.6409e-01, -2.1393e-01, -2.7424e-01,\n",
            "        -2.6168e-01, -1.3375e-01, -1.3172e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 253 :  Loss = 0.030908693247588694   ACC = 92.71829992949945\n",
            "TEST TEST  train_dataset: Epoch 254 :  Loss = 0.4361149670222263   ACC = 93.1916607916205: Epoch 254 :  Loss = 0.4361149670222263   ACC = 93.1916607916205 Class wise = [ 92.275       90.15846539  95.27121001  95.59164733  97.67891683\n",
            "  97.41935484 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 254 :  Loss = 1.8666574512481688   ACC = 76.79: Epoch 254 :  Loss = 1.8666574512481688   ACC = 76.79 Class wise = [85.6 87.4 74.7 65.8 72.6 63.1 83.9 75.8 76.5 82.5]\n",
            "TEST TEST  test_dataset: Epoch 254 :  Loss = 2.201385977554321   ACC = 76.4: Epoch 254 :  Loss = 2.201385977554321   ACC = 76.4 Class wise = [83.6 86.5 72.5 61.4 75.  63.  84.4 74.6 78.  85. ]\n",
            "tensor([-0.8579, -0.6773, -0.9473, -0.4551, -0.5861, -0.5763, -0.2883,  0.8667],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.8078e-01, -3.2538e-01, -4.6599e-01, -2.1459e-01, -2.7520e-01,\n",
            "        -2.6264e-01, -1.3409e-01, -1.3238e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 254 :  Loss = 0.029416869982502255   ACC = 92.78880048343237\n",
            "TEST TEST  train_dataset: Epoch 255 :  Loss = 0.4736407107058867   ACC = 92.97008762211702: Epoch 255 :  Loss = 0.4736407107058867   ACC = 92.97008762211702 Class wise = [ 91.725       90.82568807  94.92350487  94.66357309  97.67891683\n",
            "  97.74193548 100.          91.89189189 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 255 :  Loss = 1.93356796875   ACC = 76.08: Epoch 255 :  Loss = 1.93356796875   ACC = 76.08 Class wise = [86.2 88.3 74.5 62.6 72.7 63.6 83.9 71.2 76.7 81.1]\n",
            "TEST TEST  test_dataset: Epoch 255 :  Loss = 2.2414451232910158   ACC = 76.17: Epoch 255 :  Loss = 2.2414451232910158   ACC = 76.17 Class wise = [83.4 87.1 72.  58.9 75.4 65.3 84.5 70.7 79.1 85.3]\n",
            "tensor([-0.8602, -0.6787, -0.9501, -0.4559, -0.5873, -0.5776, -0.2886,  0.8665],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.7908e-01, -3.2657e-01, -4.6799e-01, -2.1530e-01, -2.7621e-01,\n",
            "        -2.6365e-01, -1.3447e-01, -1.3313e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 255 :  Loss = 0.03170140848308126   ACC = 92.76865746802297\n",
            "TEST TEST  train_dataset: Epoch 256 :  Loss = 0.5128441381757174   ACC = 92.61758485245241: Epoch 256 :  Loss = 0.5128441381757174   ACC = 92.61758485245241 Class wise = [ 91.4         89.11592994  95.68845619  95.93967517  96.90522244\n",
            "  97.74193548 100.          92.79279279 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 256 :  Loss = 1.9109230281829834   ACC = 76.38000000000001: Epoch 256 :  Loss = 1.9109230281829834   ACC = 76.38000000000001 Class wise = [83.9 87.9 75.2 66.4 66.5 65.6 83.4 73.4 79.5 82. ]\n",
            "TEST TEST  test_dataset: Epoch 256 :  Loss = 2.2527809017181397   ACC = 76.09: Epoch 256 :  Loss = 2.2527809017181397   ACC = 76.09 Class wise = [82.5 86.3 71.9 62.8 69.9 66.  82.7 72.4 80.9 85.5]\n",
            "tensor([-0.8624, -0.6801, -0.9528, -0.4566, -0.5885, -0.5789, -0.2889,  0.8664],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.7745e-01, -3.2769e-01, -4.6989e-01, -2.1594e-01, -2.7715e-01,\n",
            "        -2.6460e-01, -1.3482e-01, -1.3384e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 256 :  Loss = 0.028977556463290838   ACC = 92.73844294490885\n",
            "TEST TEST  train_dataset: Epoch 257 :  Loss = 0.5131753048716049   ACC = 92.5470842985195: Epoch 257 :  Loss = 0.5131753048716049   ACC = 92.5470842985195 Class wise = [ 90.9         89.4912427   95.68845619  95.47563805  98.06576402\n",
            "  97.74193548 100.          94.59459459 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 257 :  Loss = 1.9580199787139894   ACC = 76.64: Epoch 257 :  Loss = 1.9580199787139894   ACC = 76.64 Class wise = [83.8 87.9 76.5 65.6 71.3 64.5 84.7 72.  79.5 80.6]\n",
            "TEST TEST  test_dataset: Epoch 257 :  Loss = 2.2564887744903563   ACC = 76.29: Epoch 257 :  Loss = 2.2564887744903563   ACC = 76.29 Class wise = [81.1 85.9 74.4 61.5 73.4 65.9 84.4 70.9 80.7 84.7]\n",
            "tensor([-0.8652, -0.6818, -0.9564, -0.4575, -0.5900, -0.5805, -0.2893,  0.8659],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.7557e-01, -3.2896e-01, -4.7214e-01, -2.1667e-01, -2.7823e-01,\n",
            "        -2.6569e-01, -1.3519e-01, -1.3493e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 257 :  Loss = 0.029916594531516533   ACC = 92.6075133447477\n",
            "TEST TEST  train_dataset: Epoch 258 :  Loss = 0.47063628557744647   ACC = 92.99023063752644: Epoch 258 :  Loss = 0.47063628557744647   ACC = 92.99023063752644 Class wise = [ 91.775       89.69974979  95.68845619  95.93967517  98.45261122\n",
            "  97.74193548 100.          92.79279279 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 258 :  Loss = 1.8404813358306884   ACC = 76.74: Epoch 258 :  Loss = 1.8404813358306884   ACC = 76.74 Class wise = [85.3 89.3 75.4 63.5 74.4 63.6 83.1 72.3 78.8 81.7]\n",
            "TEST TEST  test_dataset: Epoch 258 :  Loss = 2.1890102197647097   ACC = 76.35: Epoch 258 :  Loss = 2.1890102197647097   ACC = 76.35 Class wise = [83.  86.6 71.5 61.2 77.2 65.9 83.  69.8 80.2 85.1]\n",
            "tensor([-0.8675, -0.6833, -0.9591, -0.4582, -0.5913, -0.5819, -0.2895,  0.8657],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.7399e-01, -3.3008e-01, -4.7395e-01, -2.1730e-01, -2.7916e-01,\n",
            "        -2.6662e-01, -1.3549e-01, -1.3583e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 258 :  Loss = 0.030532832773808853   ACC = 92.38594017524423\n",
            "TEST TEST  train_dataset: Epoch 259 :  Loss = 0.44213589199394265   ACC = 93.1815892839158: Epoch 259 :  Loss = 0.44213589199394265   ACC = 93.1815892839158 Class wise = [ 92.425       90.20016681  95.68845619  93.9675174   97.67891683\n",
            "  97.41935484 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 259 :  Loss = 1.9315566400915385   ACC = 76.85: Epoch 259 :  Loss = 1.9315566400915385   ACC = 76.85 Class wise = [86.3 87.2 76.4 62.1 73.7 66.9 84.  75.5 75.6 80.8]\n",
            "TEST TEST  test_dataset: Epoch 259 :  Loss = 2.234130180358887   ACC = 76.55999999999999: Epoch 259 :  Loss = 2.234130180358887   ACC = 76.55999999999999 Class wise = [84.3 86.7 74.3 57.6 75.1 65.2 84.1 75.4 78.3 84.6]\n",
            "tensor([-0.8700, -0.6850, -0.9621, -0.4591, -0.5927, -0.5834, -0.2899,  0.8654],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.7219e-01, -3.3141e-01, -4.7598e-01, -2.1811e-01, -2.8028e-01,\n",
            "        -2.6772e-01, -1.3596e-01, -1.3654e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 259 :  Loss = 0.0305450054283096   ACC = 92.8593010373653\n",
            "TEST TEST  train_dataset: Epoch 260 :  Loss = 0.4371767453933265   ACC = 93.68516466915096: Epoch 260 :  Loss = 0.4371767453933265   ACC = 93.68516466915096 Class wise = [ 92.25        90.82568807  97.07927677  96.9837587   97.48549323\n",
            "  97.41935484 100.          92.79279279 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 260 :  Loss = 1.9232769145965576   ACC = 76.31: Epoch 260 :  Loss = 1.9232769145965576   ACC = 76.31 Class wise = [85.7 88.4 77.7 66.5 73.2 60.5 79.8 72.6 78.6 80.1]\n",
            "TEST TEST  test_dataset: Epoch 260 :  Loss = 2.21658645362854   ACC = 76.02: Epoch 260 :  Loss = 2.21658645362854   ACC = 76.02 Class wise = [84.  87.2 72.1 63.4 76.3 62.3 78.6 72.4 80.3 83.6]\n",
            "tensor([-0.8723, -0.6865, -0.9648, -0.4598, -0.5939, -0.5846, -0.2901,  0.8657],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.7042e-01, -3.3267e-01, -4.7800e-01, -2.1884e-01, -2.8134e-01,\n",
            "        -2.6877e-01, -1.3633e-01, -1.3735e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 260 :  Loss = 0.029243765616659458   ACC = 92.70822842179474\n",
            "TEST TEST  train_dataset: Epoch 261 :  Loss = 0.4671289388101909   ACC = 93.09094571457346: Epoch 261 :  Loss = 0.4671289388101909   ACC = 93.09094571457346 Class wise = [ 91.225       90.74228524  95.75799722  96.86774942  97.87234043\n",
            "  97.74193548 100.          93.69369369 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 261 :  Loss = 1.9164195270538331   ACC = 76.68: Epoch 261 :  Loss = 1.9164195270538331   ACC = 76.68 Class wise = [84.6 88.8 77.9 67.3 71.5 63.  83.4 71.4 77.5 81.4]\n",
            "TEST TEST  test_dataset: Epoch 261 :  Loss = 2.232969793128967   ACC = 76.28: Epoch 261 :  Loss = 2.232969793128967   ACC = 76.28 Class wise = [81.  87.1 74.  63.6 74.5 63.2 83.6 71.7 79.3 84.8]\n",
            "tensor([-0.8747, -0.6880, -0.9677, -0.4606, -0.5952, -0.5859, -0.2904,  0.8658],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.6871e-01, -3.3390e-01, -4.7996e-01, -2.1955e-01, -2.8237e-01,\n",
            "        -2.6980e-01, -1.3669e-01, -1.3813e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 261 :  Loss = 0.02958109437434836   ACC = 92.55715580622419\n",
            "TEST TEST  train_dataset: Epoch 262 :  Loss = 0.4188947694579817   ACC = 93.64487863833216: Epoch 262 :  Loss = 0.4188947694579817   ACC = 93.64487863833216 Class wise = [ 91.975       91.24270225  97.07927677  96.51972158  97.09864603\n",
            "  97.74193548 100.          94.59459459 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 262 :  Loss = 1.9149649629592895   ACC = 76.69: Epoch 262 :  Loss = 1.9149649629592895   ACC = 76.69 Class wise = [85.1 89.  78.3 66.  69.2 65.6 82.4 75.1 76.4 79.8]\n",
            "TEST TEST  test_dataset: Epoch 262 :  Loss = 2.2236792194366455   ACC = 76.39: Epoch 262 :  Loss = 2.2236792194366455   ACC = 76.39 Class wise = [82.9 87.6 75.1 62.8 71.8 64.6 82.2 74.5 77.7 84.7]\n",
            "tensor([-0.8768, -0.6894, -0.9704, -0.4613, -0.5963, -0.5871, -0.2907,  0.8660],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.6697e-01, -3.3510e-01, -4.8206e-01, -2.2027e-01, -2.8339e-01,\n",
            "        -2.7082e-01, -1.3709e-01, -1.3912e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 262 :  Loss = 0.03033549526325705   ACC = 92.52694128311009\n",
            "TEST TEST  train_dataset: Epoch 263 :  Loss = 0.514113199253467   ACC = 92.37586866753954: Epoch 263 :  Loss = 0.514113199253467   ACC = 92.37586866753954 Class wise = [ 90.4         89.82485405  95.82753825  95.01160093  97.48549323\n",
            "  97.74193548 100.          94.59459459 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 263 :  Loss = 1.933661124420166   ACC = 76.58: Epoch 263 :  Loss = 1.933661124420166   ACC = 76.58 Class wise = [81.9 88.  77.4 62.3 71.  63.8 84.  74.5 81.1 81.8]\n",
            "TEST TEST  test_dataset: Epoch 263 :  Loss = 2.2248888303756713   ACC = 76.23: Epoch 263 :  Loss = 2.2248888303756713   ACC = 76.23 Class wise = [80.2 86.  74.2 60.1 72.3 63.8 84.6 74.6 82.8 83.7]\n",
            "tensor([-0.8794, -0.6911, -0.9737, -0.4621, -0.5978, -0.5887, -0.2910,  0.8654],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.6514e-01, -3.3640e-01, -4.8420e-01, -2.2104e-01, -2.8449e-01,\n",
            "        -2.7190e-01, -1.3749e-01, -1.4001e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 263 :  Loss = 0.031125491206043736   ACC = 92.40608319065365\n",
            "TEST TEST  train_dataset: Epoch 264 :  Loss = 0.4458221471759884   ACC = 93.33266189948635: Epoch 264 :  Loss = 0.4458221471759884   ACC = 93.33266189948635 Class wise = [ 91.775       90.45037531  97.00973574  96.17169374  97.29206963\n",
            "  97.74193548 100.          93.69369369 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 264 :  Loss = 1.9184659195899962   ACC = 76.35: Epoch 264 :  Loss = 1.9184659195899962   ACC = 76.35 Class wise = [84.6 87.2 77.7 67.1 68.8 66.2 81.3 72.2 78.3 80.1]\n",
            "TEST TEST  test_dataset: Epoch 264 :  Loss = 2.206072851753235   ACC = 76.42999999999999: Epoch 264 :  Loss = 2.206072851753235   ACC = 76.42999999999999 Class wise = [82.2 87.  75.8 63.5 71.3 67.4 81.5 71.8 79.3 84.5]\n",
            "tensor([-0.8815, -0.6924, -0.9762, -0.4628, -0.5988, -0.5897, -0.2913,  0.8660],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.6332e-01, -3.3773e-01, -4.8625e-01, -2.2187e-01, -2.8561e-01,\n",
            "        -2.7301e-01, -1.3798e-01, -1.4107e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 264 :  Loss = 0.03104345137132404   ACC = 92.40608319065365\n",
            "TEST TEST  train_dataset: Epoch 265 :  Loss = 0.5414303477197371   ACC = 91.9730083593514: Epoch 265 :  Loss = 0.5414303477197371   ACC = 91.9730083593514 Class wise = [ 90.175       89.36613845  94.71488178  95.01160093  96.90522244\n",
            "  97.74193548 100.          93.69369369 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 265 :  Loss = 1.964645724105835   ACC = 75.89: Epoch 265 :  Loss = 1.964645724105835   ACC = 75.89 Class wise = [81.9 88.5 74.5 65.6 67.5 65.1 84.5 72.3 77.7 81.3]\n",
            "TEST TEST  test_dataset: Epoch 265 :  Loss = 2.265508162879944   ACC = 76.41: Epoch 265 :  Loss = 2.265508162879944   ACC = 76.41 Class wise = [80.  86.  73.1 62.3 71.1 67.  86.2 72.5 80.7 85.2]\n",
            "tensor([-0.8837, -0.6938, -0.9789, -0.4635, -0.6000, -0.5909, -0.2916,  0.8661],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.6156e-01, -3.3897e-01, -4.8828e-01, -2.2258e-01, -2.8666e-01,\n",
            "        -2.7405e-01, -1.3835e-01, -1.4191e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 265 :  Loss = 0.03009928615302484   ACC = 92.51686977540537\n",
            "TEST TEST  train_dataset: Epoch 266 :  Loss = 0.4644824734882921   ACC = 92.68808540638534: Epoch 266 :  Loss = 0.4644824734882921   ACC = 92.68808540638534 Class wise = [ 91.4         90.03336113  94.15855355  96.05568445  97.67891683\n",
            "  97.74193548 100.          94.59459459 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 266 :  Loss = 1.9251221340179443   ACC = 76.83: Epoch 266 :  Loss = 1.9251221340179443   ACC = 76.83 Class wise = [84.8 87.5 75.  66.8 72.3 63.2 85.4 75.1 78.4 79.8]\n",
            "TEST TEST  test_dataset: Epoch 266 :  Loss = 2.246350827026367   ACC = 76.5: Epoch 266 :  Loss = 2.246350827026367   ACC = 76.5 Class wise = [81.6 86.6 71.7 62.7 74.6 64.7 86.1 73.6 80.4 83. ]\n",
            "tensor([-0.8858, -0.6951, -0.9815, -0.4641, -0.6011, -0.5921, -0.2918,  0.8659],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.5998e-01, -3.4007e-01, -4.9014e-01, -2.2321e-01, -2.8758e-01,\n",
            "        -2.7498e-01, -1.3867e-01, -1.4271e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 266 :  Loss = 0.032099727946041406   ACC = 92.06365192869373\n",
            "TEST TEST  train_dataset: Epoch 267 :  Loss = 0.4662428195454159   ACC = 92.8995870681841: Epoch 267 :  Loss = 0.4662428195454159   ACC = 92.8995870681841 Class wise = [ 90.7         91.40950792  94.85396384  96.17169374  98.64603482\n",
            "  98.06451613 100.          93.69369369 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 267 :  Loss = 1.9034323574066163   ACC = 76.67: Epoch 267 :  Loss = 1.9034323574066163   ACC = 76.67 Class wise = [84.2 89.5 75.9 66.6 73.7 66.2 83.5 69.  78.8 79.3]\n",
            "TEST TEST  test_dataset: Epoch 267 :  Loss = 2.2274489145278933   ACC = 76.12: Epoch 267 :  Loss = 2.2274489145278933   ACC = 76.12 Class wise = [81.  87.8 72.2 64.  75.9 65.1 83.  67.2 81.9 83.1]\n",
            "tensor([-0.8881, -0.6966, -0.9843, -0.4648, -0.6023, -0.5935, -0.2920,  0.8657],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.5843e-01, -3.4113e-01, -4.9196e-01, -2.2378e-01, -2.8846e-01,\n",
            "        -2.7587e-01, -1.3892e-01, -1.4351e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 267 :  Loss = 0.030325203954645222   ACC = 92.49672675999598\n",
            "TEST TEST  train_dataset: Epoch 268 :  Loss = 0.4643207200555823   ACC = 92.96001611441233: Epoch 268 :  Loss = 0.4643207200555823   ACC = 92.96001611441233 Class wise = [ 92.625       89.2410342   94.9930459   94.89559165  97.09864603\n",
            "  97.74193548 100.          92.79279279 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 268 :  Loss = 1.969784415245056   ACC = 76.64: Epoch 268 :  Loss = 1.969784415245056   ACC = 76.64 Class wise = [86.1 87.5 77.  65.5 71.5 64.6 85.  72.7 75.6 80.9]\n",
            "TEST TEST  test_dataset: Epoch 268 :  Loss = 2.2961157480239867   ACC = 76.27000000000001: Epoch 268 :  Loss = 2.2961157480239867   ACC = 76.27000000000001 Class wise = [84.6 85.8 72.6 61.7 72.8 65.2 85.5 71.4 77.4 85.7]\n",
            "tensor([-0.8902, -0.6979, -0.9870, -0.4653, -0.6034, -0.5946, -0.2921,  0.8657],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.5683e-01, -3.4224e-01, -4.9381e-01, -2.2441e-01, -2.8940e-01,\n",
            "        -2.7681e-01, -1.3925e-01, -1.4423e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 268 :  Loss = 0.03202951119822286   ACC = 92.61758485245241\n",
            "TEST TEST  train_dataset: Epoch 269 :  Loss = 0.5515273933878195   ACC = 91.6910061436197: Epoch 269 :  Loss = 0.5515273933878195   ACC = 91.6910061436197 Class wise = [ 89.175       90.11676397  94.08901252  94.89559165  97.29206963\n",
            "  97.74193548 100.          95.4954955  100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 269 :  Loss = 2.0563587869644167   ACC = 76.12: Epoch 269 :  Loss = 2.0563587869644167   ACC = 76.12 Class wise = [80.  88.  74.  64.3 70.2 67.2 85.3 74.  76.2 82. ]\n",
            "TEST TEST  test_dataset: Epoch 269 :  Loss = 2.337909348297119   ACC = 76.2: Epoch 269 :  Loss = 2.337909348297119   ACC = 76.2 Class wise = [77.8 86.8 72.3 61.2 72.7 67.2 85.9 74.3 78.4 85.4]\n",
            "tensor([-0.8922, -0.6992, -0.9892, -0.4660, -0.6045, -0.5957, -0.2924,  0.8659],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.5535e-01, -3.4330e-01, -4.9550e-01, -2.2502e-01, -2.9028e-01,\n",
            "        -2.7769e-01, -1.3954e-01, -1.4491e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 269 :  Loss = 0.03053869856848843   ACC = 92.65787088327122\n",
            "TEST TEST  train_dataset: Epoch 270 :  Loss = 0.5490498878928994   ACC = 92.06365192869373: Epoch 270 :  Loss = 0.5490498878928994   ACC = 92.06365192869373 Class wise = [ 91.3         87.82318599  94.64534075  95.01160093  97.48549323\n",
            "  97.41935484 100.          93.69369369 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 270 :  Loss = 1.9970920948028565   ACC = 76.67: Epoch 270 :  Loss = 1.9970920948028565   ACC = 76.67 Class wise = [83.6 84.8 75.3 65.7 71.3 65.1 86.1 74.7 77.1 83. ]\n",
            "TEST TEST  test_dataset: Epoch 270 :  Loss = 2.3400200006484986   ACC = 76.23: Epoch 270 :  Loss = 2.3400200006484986   ACC = 76.23 Class wise = [82.3 84.7 72.9 59.6 73.9 64.9 85.4 73.6 78.8 86.2]\n",
            "tensor([-0.8938, -0.7002, -0.9913, -0.4664, -0.6053, -0.5965, -0.2925,  0.8662],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.5393e-01, -3.4424e-01, -4.9722e-01, -2.2552e-01, -2.9107e-01,\n",
            "        -2.7851e-01, -1.3977e-01, -1.4560e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 270 :  Loss = 0.030550357684086357   ACC = 92.42622620606305\n",
            "dy tensor([ 0.6507,  0.1654, -0.1546, -0.4752, -0.8174, -1.1956, -1.6273, -2.1405,\n",
            "        -2.7890, -3.6890], device='cuda:0', grad_fn=<MvBackward>)\n",
            "ly tensor([-0.1017, -0.2327, -0.2802, -0.3275, -0.3849, -0.4596, -0.5600, -0.6997,\n",
            "        -0.9044, -1.2301], device='cuda:0', grad_fn=<MvBackward>)\n",
            "TEST TEST  train_dataset: Epoch 271 :  Loss = 0.5420498603704282   ACC = 92.51686977540537: Epoch 271 :  Loss = 0.5420498603704282   ACC = 92.51686977540537 Class wise = [ 90.5         89.65804837  96.10570236  96.51972158  97.29206963\n",
            "  97.74193548 100.          92.79279279 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 271 :  Loss = 1.9928687540054322   ACC = 76.24: Epoch 271 :  Loss = 1.9928687540054322   ACC = 76.24 Class wise = [82.9 88.  75.8 66.7 70.1 64.9 79.4 73.7 77.9 83. ]\n",
            "TEST TEST  test_dataset: Epoch 271 :  Loss = 2.3163145542144776   ACC = 75.88000000000001: Epoch 271 :  Loss = 2.3163145542144776   ACC = 75.88000000000001 Class wise = [80.9 86.5 71.6 63.5 74.1 65.1 79.2 72.  80.4 85.5]\n",
            "tensor([-0.8960, -0.7015, -0.9940, -0.4670, -0.6063, -0.5977, -0.2927,  0.8662],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.5226e-01, -3.4538e-01, -4.9916e-01, -2.2617e-01, -2.9203e-01,\n",
            "        -2.7948e-01, -1.4011e-01, -1.4623e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 271 :  Loss = 0.031066741675786807   ACC = 92.40608319065365\n",
            "TEST TEST  train_dataset: Epoch 272 :  Loss = 0.5068979450164742   ACC = 92.72837143720415: Epoch 272 :  Loss = 0.5068979450164742   ACC = 92.72837143720415 Class wise = [ 91.3         90.15846539  95.41029207  95.01160093  97.29206963\n",
            "  97.41935484 100.          93.69369369 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 272 :  Loss = 1.9687541809082032   ACC = 76.4: Epoch 272 :  Loss = 1.9687541809082032   ACC = 76.4 Class wise = [84.  88.1 77.3 62.7 72.2 64.7 82.4 74.1 78.4 80.1]\n",
            "TEST TEST  test_dataset: Epoch 272 :  Loss = 2.292031559753418   ACC = 76.41: Epoch 272 :  Loss = 2.292031559753418   ACC = 76.41 Class wise = [82.4 86.8 72.7 60.3 74.2 64.5 83.5 74.  81.  84.7]\n",
            "tensor([-0.8979, -0.7026, -0.9963, -0.4675, -0.6073, -0.5987, -0.2928,  0.8664],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.5070e-01, -3.4648e-01, -5.0100e-01, -2.2682e-01, -2.9296e-01,\n",
            "        -2.8041e-01, -1.4048e-01, -1.4718e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 272 :  Loss = 0.030966413630851147   ACC = 92.5873703293383\n",
            "TEST TEST  train_dataset: Epoch 273 :  Loss = 0.509558846240416   ACC = 92.24493906737838: Epoch 273 :  Loss = 0.509558846240416   ACC = 92.24493906737838 Class wise = [ 90.65        90.24186822  93.04589708  95.93967517  97.29206963\n",
            "  97.74193548 100.          94.59459459 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 273 :  Loss = 2.0024966245651243   ACC = 76.59: Epoch 273 :  Loss = 2.0024966245651243   ACC = 76.59 Class wise = [84.8 88.  73.3 67.3 71.5 63.7 84.6 73.7 78.4 80.6]\n",
            "TEST TEST  test_dataset: Epoch 273 :  Loss = 2.348308239555359   ACC = 76.05: Epoch 273 :  Loss = 2.348308239555359   ACC = 76.05 Class wise = [80.3 86.8 69.3 62.8 73.7 62.9 85.9 73.8 80.6 84.4]\n",
            "tensor([-0.9000, -0.7038, -0.9991, -0.4681, -0.6083, -0.5998, -0.2930,  0.8662],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.4912e-01, -3.4755e-01, -5.0289e-01, -2.2743e-01, -2.9387e-01,\n",
            "        -2.8132e-01, -1.4079e-01, -1.4779e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 273 :  Loss = 0.031787454420849806   ACC = 92.16436700574076\n",
            "TEST TEST  train_dataset: Epoch 274 :  Loss = 0.49866749367004426   ACC = 92.64779937556652: Epoch 274 :  Loss = 0.49866749367004426   ACC = 92.64779937556652 Class wise = [ 91.2         90.82568807  94.92350487  93.73549884  97.09864603\n",
            "  97.74193548 100.          91.89189189 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 274 :  Loss = 1.9891271931648253   ACC = 76.32: Epoch 274 :  Loss = 1.9891271931648253   ACC = 76.32 Class wise = [85.1 88.4 77.2 62.7 71.7 67.6 83.5 69.4 76.9 80.7]\n",
            "TEST TEST  test_dataset: Epoch 274 :  Loss = 2.3041923484802247   ACC = 76.0: Epoch 274 :  Loss = 2.3041923484802247   ACC = 76.0 Class wise = [81.8 87.5 72.  58.7 72.5 67.4 84.7 70.  80.9 84.5]\n",
            "tensor([-0.9017, -0.7050, -1.0011, -0.4686, -0.6093, -0.6007, -0.2932,  0.8665],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.4752e-01, -3.4871e-01, -5.0468e-01, -2.2811e-01, -2.9484e-01,\n",
            "        -2.8228e-01, -1.4115e-01, -1.4879e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 274 :  Loss = 0.031789182545087266   ACC = 92.38594017524423\n",
            "TEST TEST  train_dataset: Epoch 275 :  Loss = 0.504502555003018   ACC = 92.43629771376774: Epoch 275 :  Loss = 0.504502555003018   ACC = 92.43629771376774 Class wise = [ 90.025       90.99249374  94.78442281  95.82366589  97.67891683\n",
            "  97.74193548 100.          94.59459459 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 275 :  Loss = 1.9984116624832153   ACC = 76.88000000000001: Epoch 275 :  Loss = 1.9984116624832153   ACC = 76.88000000000001 Class wise = [83.3 88.7 76.4 66.9 71.8 66.2 83.5 73.1 77.6 81.3]\n",
            "TEST TEST  test_dataset: Epoch 275 :  Loss = 2.3305833570480345   ACC = 76.36: Epoch 275 :  Loss = 2.3305833570480345   ACC = 76.36 Class wise = [79.6 87.3 71.9 61.8 73.1 67.3 84.8 73.3 80.3 84.2]\n",
            "tensor([-0.9040, -0.7065, -1.0036, -0.4693, -0.6104, -0.6020, -0.2934,  0.8668],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.4585e-01, -3.4990e-01, -5.0656e-01, -2.2877e-01, -2.9583e-01,\n",
            "        -2.8327e-01, -1.4146e-01, -1.4971e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 275 :  Loss = 0.031097623541829617   ACC = 92.19458152885487\n",
            "TEST TEST  train_dataset: Epoch 276 :  Loss = 0.5978499138027815   ACC = 91.53993352804915: Epoch 276 :  Loss = 0.5978499138027815   ACC = 91.53993352804915 Class wise = [ 89.375       89.40783987  94.01947149  94.89559165  97.29206963\n",
            "  97.74193548 100.          90.99099099 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 276 :  Loss = 2.073736336565018   ACC = 76.32: Epoch 276 :  Loss = 2.073736336565018   ACC = 76.32 Class wise = [83.7 87.6 72.3 64.2 70.5 67.4 83.9 71.6 78.5 83.5]\n",
            "TEST TEST  test_dataset: Epoch 276 :  Loss = 2.3939402734756468   ACC = 75.83: Epoch 276 :  Loss = 2.3939402734756468   ACC = 75.83 Class wise = [79.5 86.3 69.6 60.6 72.1 68.9 84.5 70.8 79.7 86.3]\n",
            "tensor([-0.9061, -0.7078, -1.0063, -0.4699, -0.6115, -0.6031, -0.2936,  0.8669],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.4415e-01, -3.5107e-01, -5.0855e-01, -2.2943e-01, -2.9681e-01,\n",
            "        -2.8426e-01, -1.4179e-01, -1.5056e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 276 :  Loss = 0.02991534137541385   ACC = 92.67801389868063\n",
            "TEST TEST  train_dataset: Epoch 277 :  Loss = 0.4511565380227774   ACC = 93.12116023768759: Epoch 277 :  Loss = 0.4511565380227774   ACC = 93.12116023768759 Class wise = [ 91.125       91.117598    96.38386648  96.05568445  96.90522244\n",
            "  97.74193548 100.          94.59459459 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 277 :  Loss = 1.9932440051078797   ACC = 76.5: Epoch 277 :  Loss = 1.9932440051078797   ACC = 76.5 Class wise = [83.9 89.2 77.1 64.6 68.9 65.6 83.3 74.  77.7 80.7]\n",
            "TEST TEST  test_dataset: Epoch 277 :  Loss = 2.280809108352661   ACC = 76.39: Epoch 277 :  Loss = 2.280809108352661   ACC = 76.39 Class wise = [80.9 87.6 75.5 62.6 71.2 65.7 83.9 72.9 79.8 83.8]\n",
            "tensor([-0.9075, -0.7086, -1.0081, -0.4702, -0.6121, -0.6036, -0.2936,  0.8678],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.4266e-01, -3.5206e-01, -5.1034e-01, -2.2997e-01, -2.9764e-01,\n",
            "        -2.8512e-01, -1.4204e-01, -1.5129e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 277 :  Loss = 0.031594474512814684   ACC = 92.32551112901601\n",
            "TEST TEST  train_dataset: Epoch 278 :  Loss = 0.4794456111067888   ACC = 92.92980159129823: Epoch 278 :  Loss = 0.4794456111067888   ACC = 92.92980159129823 Class wise = [ 90.85        91.99332777  95.61891516  93.9675174   97.29206963\n",
            "  97.74193548 100.          92.79279279 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 278 :  Loss = 1.9255468244552612   ACC = 76.75999999999999: Epoch 278 :  Loss = 1.9255468244552612   ACC = 76.75999999999999 Class wise = [84.1 89.7 76.8 63.1 71.9 66.7 82.3 72.6 80.9 79.5]\n",
            "TEST TEST  test_dataset: Epoch 278 :  Loss = 2.260058600234985   ACC = 76.14999999999999: Epoch 278 :  Loss = 2.260058600234985   ACC = 76.14999999999999 Class wise = [80.  88.8 72.8 58.6 73.6 68.  83.4 71.1 81.9 83.3]\n",
            "tensor([-0.9091, -0.7095, -1.0101, -0.4707, -0.6129, -0.6044, -0.2938,  0.8682],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.4118e-01, -3.5305e-01, -5.1211e-01, -2.3054e-01, -2.9849e-01,\n",
            "        -2.8597e-01, -1.4235e-01, -1.5218e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 278 :  Loss = 0.029356608711132794   ACC = 92.12408097492195\n",
            "TEST TEST  train_dataset: Epoch 279 :  Loss = 0.4729589603017569   ACC = 92.71829992949945: Epoch 279 :  Loss = 0.4729589603017569   ACC = 92.71829992949945 Class wise = [ 90.175       92.57714762  94.85396384  94.31554524  96.71179884\n",
            "  98.06451613 100.          94.59459459 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 279 :  Loss = 1.992390433883667   ACC = 76.34: Epoch 279 :  Loss = 1.992390433883667   ACC = 76.34 Class wise = [81.3 90.7 74.8 61.8 68.3 66.8 85.8 73.8 80.9 79.2]\n",
            "TEST TEST  test_dataset: Epoch 279 :  Loss = 2.282686208343506   ACC = 76.29: Epoch 279 :  Loss = 2.282686208343506   ACC = 76.29 Class wise = [80.1 88.7 72.6 59.4 70.4 67.8 86.3 73.5 81.4 82.7]\n",
            "tensor([-0.9109, -0.7106, -1.0125, -0.4712, -0.6138, -0.6053, -0.2940,  0.8683],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.3961e-01, -3.5416e-01, -5.1393e-01, -2.3121e-01, -2.9943e-01,\n",
            "        -2.8691e-01, -1.4274e-01, -1.5307e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 279 :  Loss = 0.029447507453518266   ACC = 92.52694128311009\n",
            "TEST TEST  train_dataset: Epoch 280 :  Loss = 0.4585781813062432   ACC = 93.05065968375466: Epoch 280 :  Loss = 0.4585781813062432   ACC = 93.05065968375466 Class wise = [ 91.125       91.57631359  95.41029207  95.35962877  97.29206963\n",
            "  97.74193548 100.          94.59459459 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 280 :  Loss = 1.9532722197532655   ACC = 76.53999999999999: Epoch 280 :  Loss = 1.9532722197532655   ACC = 76.53999999999999 Class wise = [85.  88.5 75.3 63.6 70.6 66.3 83.4 73.7 79.8 79.2]\n",
            "TEST TEST  test_dataset: Epoch 280 :  Loss = 2.2664291131973267   ACC = 76.3: Epoch 280 :  Loss = 2.2664291131973267   ACC = 76.3 Class wise = [81.9 88.  72.1 61.2 73.6 66.  83.6 72.7 81.4 82.5]\n",
            "tensor([-0.9129, -0.7118, -1.0149, -0.4717, -0.6148, -0.6064, -0.2942,  0.8685],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.3797e-01, -3.5531e-01, -5.1581e-01, -2.3188e-01, -3.0039e-01,\n",
            "        -2.8787e-01, -1.4311e-01, -1.5385e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 280 :  Loss = 0.02958911289044024   ACC = 92.66794239097594\n",
            "TEST TEST  train_dataset: Epoch 281 :  Loss = 0.5002881994222846   ACC = 92.94994460670762: Epoch 281 :  Loss = 0.5002881994222846   ACC = 92.94994460670762 Class wise = [ 91.5         90.74228524  95.89707928  94.66357309  96.90522244\n",
            "  97.41935484 100.          91.89189189 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 281 :  Loss = 1.978359519958496   ACC = 76.44999999999999: Epoch 281 :  Loss = 1.978359519958496   ACC = 76.44999999999999 Class wise = [84.3 89.5 77.7 64.7 68.2 65.4 83.4 71.6 77.8 81.9]\n",
            "TEST TEST  test_dataset: Epoch 281 :  Loss = 2.3447227964401245   ACC = 75.88000000000001: Epoch 281 :  Loss = 2.3447227964401245   ACC = 75.88000000000001 Class wise = [81.9 87.5 73.1 60.4 70.2 67.4 83.4 70.  80.1 84.8]\n",
            "tensor([-0.9152, -0.7133, -1.0176, -0.4724, -0.6160, -0.6077, -0.2944,  0.8683],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.3629e-01, -3.5652e-01, -5.1774e-01, -2.3260e-01, -3.0142e-01,\n",
            "        -2.8888e-01, -1.4348e-01, -1.5456e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 281 :  Loss = 0.02915176121756826   ACC = 92.34565414442541\n",
            "TEST TEST  train_dataset: Epoch 282 :  Loss = 0.48078288597057406   ACC = 93.12116023768759: Epoch 282 :  Loss = 0.48078288597057406   ACC = 93.12116023768759 Class wise = [ 91.025       90.82568807  96.45340751  96.63573086  98.25918762\n",
            "  97.74193548 100.          92.79279279 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 282 :  Loss = 1.907874689102173   ACC = 76.78: Epoch 282 :  Loss = 1.907874689102173   ACC = 76.78 Class wise = [84.4 88.2 77.2 66.3 72.  64.1 83.3 70.2 81.  81.1]\n",
            "TEST TEST  test_dataset: Epoch 282 :  Loss = 2.264315951156616   ACC = 76.08: Epoch 282 :  Loss = 2.264315951156616   ACC = 76.08 Class wise = [81.4 87.4 74.3 62.1 74.2 63.8 83.1 69.  82.7 82.8]\n",
            "tensor([-0.9173, -0.7146, -1.0202, -0.4731, -0.6171, -0.6089, -0.2947,  0.8682],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.3466e-01, -3.5766e-01, -5.1963e-01, -2.3325e-01, -3.0237e-01,\n",
            "        -2.8984e-01, -1.4380e-01, -1.5556e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 282 :  Loss = 0.030872687960045612   ACC = 92.24493906737838\n",
            "TEST TEST  train_dataset: Epoch 283 :  Loss = 0.4838739690795242   ACC = 92.37586866753954: Epoch 283 :  Loss = 0.4838739690795242   ACC = 92.37586866753954 Class wise = [ 90.5         90.99249374  93.74130737  95.01160093  97.29206963\n",
            "  97.41935484 100.          94.59459459 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 283 :  Loss = 2.0795719097137453   ACC = 76.53999999999999: Epoch 283 :  Loss = 2.0795719097137453   ACC = 76.53999999999999 Class wise = [83.  89.4 75.9 64.1 72.9 64.8 85.9 75.5 74.  79.9]\n",
            "TEST TEST  test_dataset: Epoch 283 :  Loss = 2.3939827001571654   ACC = 76.0: Epoch 283 :  Loss = 2.3939827001571654   ACC = 76.0 Class wise = [80.1 87.3 71.8 60.  73.6 65.2 86.3 74.5 77.  84.2]\n",
            "tensor([-0.9190, -0.7156, -1.0225, -0.4736, -0.6179, -0.6097, -0.2948,  0.8684],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.3311e-01, -3.5875e-01, -5.2146e-01, -2.3391e-01, -3.0330e-01,\n",
            "        -2.9076e-01, -1.4418e-01, -1.5640e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 283 :  Loss = 0.02927875841497551   ACC = 92.53701279081479\n",
            "TEST TEST  train_dataset: Epoch 284 :  Loss = 0.6543863664073736   ACC = 90.86514251183402: Epoch 284 :  Loss = 0.6543863664073736   ACC = 90.86514251183402 Class wise = [ 89.325       86.57214345  94.36717663  95.24361949  95.93810445\n",
            "  97.41935484 100.          93.69369369 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 284 :  Loss = 2.073714949041605   ACC = 76.64999999999999: Epoch 284 :  Loss = 2.073714949041605   ACC = 76.64999999999999 Class wise = [82.8 85.4 75.1 64.7 70.1 67.  83.8 75.2 78.7 83.7]\n",
            "TEST TEST  test_dataset: Epoch 284 :  Loss = 2.4450392333984374   ACC = 75.78: Epoch 284 :  Loss = 2.4450392333984374   ACC = 75.78 Class wise = [79.  83.8 70.8 61.5 71.4 65.9 82.8 74.9 81.3 86.4]\n",
            "tensor([-0.9209, -0.7166, -1.0250, -0.4740, -0.6189, -0.6108, -0.2950,  0.8681],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.3168e-01, -3.5969e-01, -5.2317e-01, -2.3442e-01, -3.0409e-01,\n",
            "        -2.9158e-01, -1.4443e-01, -1.5709e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 284 :  Loss = 0.03165799323219897   ACC = 92.14422399033135\n",
            "TEST TEST  train_dataset: Epoch 285 :  Loss = 0.43789931156471795   ACC = 92.86937254507: Epoch 285 :  Loss = 0.43789931156471795   ACC = 92.86937254507 Class wise = [ 92.15        90.45037531  93.46314325  94.54756381  98.06576402\n",
            "  97.74193548 100.          93.69369369 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 285 :  Loss = 1.9994665193900465   ACC = 76.7: Epoch 285 :  Loss = 1.9994665193900465   ACC = 76.7 Class wise = [84.6 88.  74.7 66.1 73.  66.3 86.  73.6 73.4 81.3]\n",
            "TEST TEST  test_dataset: Epoch 285 :  Loss = 2.328048301887512   ACC = 76.4: Epoch 285 :  Loss = 2.328048301887512   ACC = 76.4 Class wise = [82.3 87.  71.9 60.3 75.5 66.9 86.4 72.7 76.6 84.4]\n",
            "tensor([-0.9224, -0.7176, -1.0268, -0.4744, -0.6196, -0.6115, -0.2951,  0.8686],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.3033e-01, -3.6058e-01, -5.2479e-01, -2.3490e-01, -3.0484e-01,\n",
            "        -2.9235e-01, -1.4464e-01, -1.5799e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 285 :  Loss = 0.029977725760785938   ACC = 92.00322288246551\n",
            "TEST TEST  train_dataset: Epoch 286 :  Loss = 0.5714579367710384   ACC = 92.15429549803605: Epoch 286 :  Loss = 0.5714579367710384   ACC = 92.15429549803605 Class wise = [ 90.475       89.36613845  94.50625869  95.59164733  97.87234043\n",
            "  97.74193548 100.          92.79279279 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 286 :  Loss = 2.0117314765930177   ACC = 76.4: Epoch 286 :  Loss = 2.0117314765930177   ACC = 76.4 Class wise = [84.2 88.4 74.8 66.5 72.4 63.4 83.3 71.3 78.4 81.3]\n",
            "TEST TEST  test_dataset: Epoch 286 :  Loss = 2.374555784988403   ACC = 76.11: Epoch 286 :  Loss = 2.374555784988403   ACC = 76.11 Class wise = [80.8 86.3 70.8 61.1 75.4 65.4 83.9 70.9 81.1 85.4]\n",
            "tensor([-0.9238, -0.7184, -1.0287, -0.4748, -0.6202, -0.6121, -0.2952,  0.8693],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.2882e-01, -3.6162e-01, -5.2659e-01, -2.3548e-01, -3.0571e-01,\n",
            "        -2.9323e-01, -1.4494e-01, -1.5880e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 286 :  Loss = 0.030501047996298547   ACC = 92.2952966059019\n",
            "TEST TEST  train_dataset: Epoch 287 :  Loss = 0.4121634857229836   ACC = 93.56430657669453: Epoch 287 :  Loss = 0.4121634857229836   ACC = 93.56430657669453 Class wise = [ 92.05        92.24353628  95.27121001  95.47563805  97.09864603\n",
            "  98.06451613 100.          93.69369369 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 287 :  Loss = 2.0214985204696654   ACC = 76.59: Epoch 287 :  Loss = 2.0214985204696654   ACC = 76.59 Class wise = [85.9 89.8 74.9 66.2 70.2 66.7 82.3 73.1 77.2 79.6]\n",
            "TEST TEST  test_dataset: Epoch 287 :  Loss = 2.301920551109314   ACC = 76.33: Epoch 287 :  Loss = 2.301920551109314   ACC = 76.33 Class wise = [82.6 88.4 72.4 62.8 71.9 67.1 84.4 71.7 79.4 82.6]\n",
            "tensor([-0.9261, -0.7198, -1.0314, -0.4754, -0.6214, -0.6133, -0.2954,  0.8693],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.2716e-01, -3.6279e-01, -5.2850e-01, -2.3615e-01, -3.0669e-01,\n",
            "        -2.9421e-01, -1.4526e-01, -1.5951e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 287 :  Loss = 0.03132535980954152   ACC = 92.07372343639842\n",
            "TEST TEST  train_dataset: Epoch 288 :  Loss = 0.5409682296741851   ACC = 92.17443851344547: Epoch 288 :  Loss = 0.5409682296741851   ACC = 92.17443851344547 Class wise = [ 91.25        89.36613845  93.25452017  95.01160093  96.32495164\n",
            "  97.74193548 100.          94.59459459 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 288 :  Loss = 2.045200724029541   ACC = 76.59: Epoch 288 :  Loss = 2.045200724029541   ACC = 76.59 Class wise = [84.7 88.2 73.1 67.7 69.1 66.  82.7 75.2 77.6 81.6]\n",
            "TEST TEST  test_dataset: Epoch 288 :  Loss = 2.3825368923187256   ACC = 76.03999999999999: Epoch 288 :  Loss = 2.3825368923187256   ACC = 76.03999999999999 Class wise = [81.1 85.8 68.3 62.3 72.3 68.3 82.3 74.8 79.9 85.3]\n",
            "tensor([-0.9273, -0.7206, -1.0330, -0.4757, -0.6219, -0.6138, -0.2955,  0.8700],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.2570e-01, -3.6381e-01, -5.3017e-01, -2.3675e-01, -3.0755e-01,\n",
            "        -2.9507e-01, -1.4560e-01, -1.6024e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 288 :  Loss = 0.030143657452162808   ACC = 92.11400946721724\n",
            "TEST TEST  train_dataset: Epoch 289 :  Loss = 0.4012842141846914   ACC = 93.61466411521805: Epoch 289 :  Loss = 0.4012842141846914   ACC = 93.61466411521805 Class wise = [ 92.375       92.20183486  95.27121001  94.54756381  97.29206963\n",
            "  97.74193548 100.          94.59459459 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 289 :  Loss = 1.9753118587493896   ACC = 76.39: Epoch 289 :  Loss = 1.9753118587493896   ACC = 76.39 Class wise = [85.  89.6 76.6 62.  70.6 67.9 80.9 75.4 75.4 80.5]\n",
            "TEST TEST  test_dataset: Epoch 289 :  Loss = 2.2890823572158814   ACC = 76.37: Epoch 289 :  Loss = 2.2890823572158814   ACC = 76.37 Class wise = [83.8 87.8 72.5 60.1 74.  67.  82.2 75.5 76.6 84.2]\n",
            "tensor([-0.9290, -0.7216, -1.0351, -0.4762, -0.6228, -0.6146, -0.2957,  0.8705],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.2412e-01, -3.6495e-01, -5.3198e-01, -2.3744e-01, -3.0852e-01,\n",
            "        -2.9602e-01, -1.4600e-01, -1.6115e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 289 :  Loss = 0.0313961573397413   ACC = 91.96293685164669\n",
            "TEST TEST  train_dataset: Epoch 290 :  Loss = 0.49294837632965305   ACC = 92.82908651425117: Epoch 290 :  Loss = 0.49294837632965305   ACC = 92.82908651425117 Class wise = [ 91.1         90.90909091  95.34075104  95.47563805  96.51837524\n",
            "  97.74193548 100.          93.69369369 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 290 :  Loss = 1.9690184135079385   ACC = 76.8: Epoch 290 :  Loss = 1.9690184135079385   ACC = 76.8 Class wise = [84.9 88.4 77.6 66.3 69.8 66.1 83.6 72.8 78.9 79.6]\n",
            "TEST TEST  test_dataset: Epoch 290 :  Loss = 2.320592000389099   ACC = 76.07000000000001: Epoch 290 :  Loss = 2.320592000389099   ACC = 76.07000000000001 Class wise = [81.4 87.1 72.3 62.1 70.8 66.3 83.2 72.7 80.7 84.1]\n",
            "tensor([-0.9305, -0.7226, -1.0369, -0.4767, -0.6235, -0.6153, -0.2959,  0.8711],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.2269e-01, -3.6595e-01, -5.3362e-01, -2.3802e-01, -3.0936e-01,\n",
            "        -2.9686e-01, -1.4631e-01, -1.6203e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 290 :  Loss = 0.03016026304533499   ACC = 92.06365192869373\n",
            "TEST TEST  train_dataset: Epoch 291 :  Loss = 0.5802150107307668   ACC = 91.88236479000906: Epoch 291 :  Loss = 0.5802150107307668   ACC = 91.88236479000906 Class wise = [ 89.55        89.40783987  95.54937413  96.05568445  96.13152805\n",
            "  97.41935484 100.          92.79279279 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 291 :  Loss = 2.0872036979675292   ACC = 76.42999999999999: Epoch 291 :  Loss = 2.0872036979675292   ACC = 76.42999999999999 Class wise = [81.7 87.9 76.  66.6 70.2 64.9 82.9 74.4 78.3 81.4]\n",
            "TEST TEST  test_dataset: Epoch 291 :  Loss = 2.3822838571548464   ACC = 76.07000000000001: Epoch 291 :  Loss = 2.3822838571548464   ACC = 76.07000000000001 Class wise = [79.1 86.1 73.5 63.5 70.5 64.6 82.8 74.  80.7 85.9]\n",
            "tensor([-0.9322, -0.7236, -1.0389, -0.4771, -0.6243, -0.6161, -0.2960,  0.8714],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.2137e-01, -3.6684e-01, -5.3515e-01, -2.3850e-01, -3.1011e-01,\n",
            "        -2.9762e-01, -1.4653e-01, -1.6296e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 291 :  Loss = 0.030482747446363312   ACC = 92.11400946721724\n",
            "TEST TEST  train_dataset: Epoch 292 :  Loss = 0.5469843634378658   ACC = 92.2852250981972: Epoch 292 :  Loss = 0.5469843634378658   ACC = 92.2852250981972 Class wise = [ 90.3         90.28356964  94.9930459   95.35962877  97.09864603\n",
            "  96.77419355 100.          92.79279279 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 292 :  Loss = 2.07430620803833   ACC = 76.3: Epoch 292 :  Loss = 2.07430620803833   ACC = 76.3 Class wise = [83.8 87.2 74.4 65.2 72.2 61.8 84.1 73.8 79.1 81.4]\n",
            "TEST TEST  test_dataset: Epoch 292 :  Loss = 2.397211074256897   ACC = 76.0: Epoch 292 :  Loss = 2.397211074256897   ACC = 76.0 Class wise = [80.4 87.1 72.  61.  74.3 62.7 84.6 72.3 80.7 84.9]\n",
            "tensor([-0.9339, -0.7247, -1.0408, -0.4777, -0.6252, -0.6170, -0.2962,  0.8721],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.1980e-01, -3.6796e-01, -5.3693e-01, -2.3914e-01, -3.1104e-01,\n",
            "        -2.9855e-01, -1.4685e-01, -1.6372e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 292 :  Loss = 0.030862487931363904   ACC = 92.14422399033135\n",
            "TEST TEST  train_dataset: Epoch 293 :  Loss = 0.5923912656476695   ACC = 91.48957598952563: Epoch 293 :  Loss = 0.5923912656476695   ACC = 91.48957598952563 Class wise = [ 89.525       89.11592994  94.01947149  94.43155452  96.90522244\n",
            "  97.74193548 100.          92.79279279 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 293 :  Loss = 2.0775160026550292   ACC = 76.39: Epoch 293 :  Loss = 2.0775160026550292   ACC = 76.39 Class wise = [82.2 87.4 74.7 63.6 67.9 69.  83.6 74.5 77.4 83.6]\n",
            "TEST TEST  test_dataset: Epoch 293 :  Loss = 2.427035285758972   ACC = 76.01: Epoch 293 :  Loss = 2.427035285758972   ACC = 76.01 Class wise = [78.4 85.7 71.1 60.2 72.1 69.  84.8 73.3 79.7 85.8]\n",
            "tensor([-0.9354, -0.7257, -1.0427, -0.4781, -0.6259, -0.6176, -0.2962,  0.8728],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.1829e-01, -3.6900e-01, -5.3870e-01, -2.3972e-01, -3.1191e-01,\n",
            "        -2.9944e-01, -1.4712e-01, -1.6468e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 293 :  Loss = 0.030255119649169788   ACC = 91.93272232853258\n",
            "TEST TEST  train_dataset: Epoch 294 :  Loss = 0.5396809873632591   ACC = 92.07372343639842: Epoch 294 :  Loss = 0.5396809873632591   ACC = 92.07372343639842 Class wise = [ 89.925       89.90825688  94.71488178  95.24361949  97.87234043\n",
            "  97.74193548 100.          93.69369369 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 294 :  Loss = 2.022237288093567   ACC = 76.52: Epoch 294 :  Loss = 2.022237288093567   ACC = 76.52 Class wise = [82.6 87.8 76.6 63.7 72.5 62.9 84.3 75.4 78.3 81.1]\n",
            "TEST TEST  test_dataset: Epoch 294 :  Loss = 2.367155669403076   ACC = 76.14: Epoch 294 :  Loss = 2.367155669403076   ACC = 76.14 Class wise = [79.8 86.5 72.2 59.9 76.7 63.5 84.7 73.  80.9 84.2]\n",
            "tensor([-0.9371, -0.7266, -1.0448, -0.4785, -0.6266, -0.6184, -0.2964,  0.8731],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.1685e-01, -3.6997e-01, -5.4040e-01, -2.4025e-01, -3.1273e-01,\n",
            "        -3.0027e-01, -1.4737e-01, -1.6560e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 294 :  Loss = 0.03163508891380978   ACC = 92.15429549803605\n",
            "TEST TEST  train_dataset: Epoch 295 :  Loss = 0.5546990830371944   ACC = 92.30536811360662: Epoch 295 :  Loss = 0.5546990830371944   ACC = 92.30536811360662 Class wise = [ 89.95        90.15846539  96.38386648  95.93967517  95.35783366\n",
            "  97.74193548 100.          92.79279279 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 295 :  Loss = 2.0466912227630614   ACC = 76.55: Epoch 295 :  Loss = 2.0466912227630614   ACC = 76.55 Class wise = [83.1 88.  76.6 65.1 67.4 64.7 82.5 74.3 81.3 82.5]\n",
            "TEST TEST  test_dataset: Epoch 295 :  Loss = 2.3833061056137086   ACC = 76.18: Epoch 295 :  Loss = 2.3833061056137086   ACC = 76.18 Class wise = [80.2 86.8 74.2 62.2 69.8 65.3 82.6 73.9 82.1 84.7]\n",
            "tensor([-0.9388, -0.7278, -1.0468, -0.4790, -0.6275, -0.6192, -0.2965,  0.8737],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.1519e-01, -3.7117e-01, -5.4228e-01, -2.4096e-01, -3.1373e-01,\n",
            "        -3.0126e-01, -1.4775e-01, -1.6640e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 295 :  Loss = 0.029510106505695362   ACC = 91.91257931312317\n",
            "TEST TEST  train_dataset: Epoch 296 :  Loss = 0.6758824775828562   ACC = 90.98600060429047: Epoch 296 :  Loss = 0.6758824775828562   ACC = 90.98600060429047 Class wise = [ 88.9         87.03085905  94.9930459   95.82366589  97.09864603\n",
            "  97.74193548 100.          90.99099099 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 296 :  Loss = 2.047731251144409   ACC = 76.35: Epoch 296 :  Loss = 2.047731251144409   ACC = 76.35 Class wise = [83.1 86.5 74.3 66.8 69.2 67.2 81.9 70.4 81.7 82.4]\n",
            "TEST TEST  test_dataset: Epoch 296 :  Loss = 2.442386191177368   ACC = 75.57000000000001: Epoch 296 :  Loss = 2.442386191177368   ACC = 75.57000000000001 Class wise = [79.8 84.9 70.4 62.6 71.2 66.4 82.3 69.2 83.6 85.3]\n",
            "tensor([-0.9403, -0.7287, -1.0488, -0.4795, -0.6283, -0.6200, -0.2967,  0.8739],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.1369e-01, -3.7222e-01, -5.4405e-01, -2.4159e-01, -3.1463e-01,\n",
            "        -3.0215e-01, -1.4809e-01, -1.6734e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 296 :  Loss = 0.03226597937680717   ACC = 91.91257931312317\n",
            "TEST TEST  train_dataset: Epoch 297 :  Loss = 0.5860924770937769   ACC = 91.65072011280088: Epoch 297 :  Loss = 0.5860924770937769   ACC = 91.65072011280088 Class wise = [ 89.7         89.99165972  93.94993046  93.387471    96.71179884\n",
            "  97.74193548 100.          91.89189189 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 297 :  Loss = 2.067868073272705   ACC = 76.24: Epoch 297 :  Loss = 2.067868073272705   ACC = 76.24 Class wise = [81.5 88.  75.4 61.9 69.6 66.5 85.6 72.5 77.8 83.6]\n",
            "TEST TEST  test_dataset: Epoch 297 :  Loss = 2.460520308113098   ACC = 75.86: Epoch 297 :  Loss = 2.460520308113098   ACC = 75.86 Class wise = [79.8 86.7 72.5 57.8 71.5 66.4 86.5 72.  80.5 84.9]\n",
            "tensor([-0.9418, -0.7295, -1.0506, -0.4799, -0.6290, -0.6207, -0.2969,  0.8743],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.1225e-01, -3.7323e-01, -5.4573e-01, -2.4219e-01, -3.1548e-01,\n",
            "        -3.0300e-01, -1.4842e-01, -1.6829e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 297 :  Loss = 0.03030758403989769   ACC = 92.35572565213013\n",
            "TEST TEST  train_dataset: Epoch 298 :  Loss = 0.7002011238059775   ACC = 90.60328331151173: Epoch 298 :  Loss = 0.7002011238059775   ACC = 90.60328331151173 Class wise = [ 88.575       87.98999166  94.57579972  93.15545244  93.03675048\n",
            "  97.74193548 100.          92.79279279 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 298 :  Loss = 2.164201426124573   ACC = 75.83: Epoch 298 :  Loss = 2.164201426124573   ACC = 75.83 Class wise = [81.9 86.  75.6 62.3 64.5 67.2 84.4 74.1 78.1 84.2]\n",
            "TEST TEST  test_dataset: Epoch 298 :  Loss = 2.570210478401184   ACC = 75.28: Epoch 298 :  Loss = 2.570210478401184   ACC = 75.28 Class wise = [78.2 85.2 73.  58.8 66.9 66.2 84.5 72.1 80.9 87. ]\n",
            "tensor([-0.9434, -0.7305, -1.0527, -0.4803, -0.6297, -0.6215, -0.2970,  0.8748],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.1072e-01, -3.7430e-01, -5.4750e-01, -2.4281e-01, -3.1638e-01,\n",
            "        -3.0391e-01, -1.4875e-01, -1.6911e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 298 :  Loss = 0.03066039617524273   ACC = 91.90250780541848\n",
            "TEST TEST  train_dataset: Epoch 299 :  Loss = 0.5549733220846844   ACC = 91.89243629771376: Epoch 299 :  Loss = 0.5549733220846844   ACC = 91.89243629771376 Class wise = [ 89.75        89.74145121  93.88038943  96.75174014  96.51837524\n",
            "  97.74193548 100.          92.79279279 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 299 :  Loss = 2.110809680175781   ACC = 76.11: Epoch 299 :  Loss = 2.110809680175781   ACC = 76.11 Class wise = [80.9 86.7 73.9 67.4 70.7 65.4 83.  74.  77.1 82. ]\n",
            "TEST TEST  test_dataset: Epoch 299 :  Loss = 2.432463531303406   ACC = 76.0: Epoch 299 :  Loss = 2.432463531303406   ACC = 76.0 Class wise = [78.6 86.5 69.8 64.7 72.7 65.8 82.5 74.7 79.  85.7]\n",
            "tensor([-0.9449, -0.7313, -1.0546, -0.4806, -0.6304, -0.6221, -0.2971,  0.8753],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.0932e-01, -3.7521e-01, -5.4917e-01, -2.4329e-01, -3.1715e-01,\n",
            "        -3.0470e-01, -1.4896e-01, -1.7002e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 299 :  Loss = 0.03183910813152952   ACC = 91.60036257427737\n",
            "TEST TEST  train_dataset: Epoch 300 :  Loss = 0.5445143038830514   ACC = 92.24493906737838: Epoch 300 :  Loss = 0.5445143038830514   ACC = 92.24493906737838 Class wise = [ 91.45        89.07422852  93.46314325  95.12761021  97.09864603\n",
            "  97.74193548 100.          92.79279279 100.         100.        ]\n",
            "TEST TEST  val_dataset: Epoch 300 :  Loss = 2.0444747703552246   ACC = 76.35: Epoch 300 :  Loss = 2.0444747703552246   ACC = 76.35 Class wise = [85.2 85.7 74.6 64.4 69.1 66.3 85.2 72.6 78.6 81.8]\n",
            "TEST TEST  test_dataset: Epoch 300 :  Loss = 2.433469948577881   ACC = 75.97: Epoch 300 :  Loss = 2.433469948577881   ACC = 75.97 Class wise = [81.9 85.2 70.1 62.  71.2 66.9 86.  71.6 79.8 85. ]\n",
            "tensor([-0.9462, -0.7320, -1.0563, -0.4809, -0.6309, -0.6226, -0.2971,  0.8760],\n",
            "       device='cuda:0', requires_grad=True) tensor([ 5.0795e-01, -3.7615e-01, -5.5078e-01, -2.4383e-01, -3.1794e-01,\n",
            "        -3.0550e-01, -1.4925e-01, -1.7088e-06], device='cuda:0',\n",
            "       requires_grad=True) \n",
            "\n",
            "lr:  0.0010000000000000002   arch lr:  0.01\n",
            "Epoch 300 :  Loss = 0.031092341715387977   ACC = 91.93272232853258\n",
            "dy tensor([ 0.6517,  0.1369, -0.2012, -0.5393, -0.8994, -1.2967, -1.7494, -2.2862,\n",
            "        -2.9621, -3.8963], device='cuda:0', grad_fn=<MvBackward>)\n",
            "ly tensor([-0.1113, -0.2677, -0.3314, -0.3946, -0.4687, -0.5615, -0.6823, -0.8455,\n",
            "        -1.0791, -1.4430], device='cuda:0', grad_fn=<MvBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfuuolsMl-iL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "139e92d8-943e-450b-e042-7f4452414791"
      },
      "source": [
        "dy_w"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.9478, -0.7330, -1.0583, -0.4813, -0.6317, -0.6234, -0.2972,  0.8763],\n",
              "       device='cuda:0', requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CfJTvaxtaoz",
        "outputId": "df2fc4f5-cc46-4055-f91b-891a29a1a4dd"
      },
      "source": [
        "ly_w"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 5.0637e-01, -3.7727e-01, -5.5261e-01, -2.4450e-01, -3.1889e-01,\n",
              "        -3.0644e-01, -1.4962e-01, -1.7176e-06], device='cuda:0',\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7mpgGRVtcXI"
      },
      "source": [
        "dy_final = dy_w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHW5CRPitf0C"
      },
      "source": [
        "ly_final = ly_w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29etL-vCtjPK"
      },
      "source": [
        "dyy =torch.matmul(torch.tensor(np.array(dic).T,dtype=torch.float32,device=device),dy_final)\n",
        "lyy =torch.matmul(torch.tensor(np.array(dic).T,dtype=torch.float32,device=device),ly_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FX-zq0Z1qY9",
        "outputId": "525506c4-8397-4277-916a-48704fc3a5be"
      },
      "source": [
        "dyy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.6517,  0.1369, -0.2012, -0.5393, -0.8994, -1.2967, -1.7494, -2.2862,\n",
              "        -2.9621, -3.8963], device='cuda:0', grad_fn=<MvBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e1SOiVF1r0r",
        "outputId": "d8758237-b461-4b0e-c220-aab5af7aeb7f"
      },
      "source": [
        "lyy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.1113, -0.2677, -0.3314, -0.3946, -0.4687, -0.5615, -0.6823, -0.8455,\n",
              "        -1.0791, -1.4430], device='cuda:0', grad_fn=<MvBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzKt3_itqs-S",
        "outputId": "8ee3a7f9-7a32-4b37-aea7-fc52067aedee"
      },
      "source": [
        "test_acc_max"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "76.99000000000001"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    }
  ]
}